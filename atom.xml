<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Rian Ng</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2019-07-28T06:24:59.809Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>Rian Ng</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>MachineLearning Chapter-4 K-Nearest Neighbor</title>
    <link href="http://yoursite.com/2019/07/28/MachineLearning-Chapter-4-K-Nearest-Neighbor/"/>
    <id>http://yoursite.com/2019/07/28/MachineLearning-Chapter-4-K-Nearest-Neighbor/</id>
    <published>2019-07-28T04:12:07.000Z</published>
    <updated>2019-07-28T06:24:59.809Z</updated>
    
    <content type="html"><![CDATA[<h1 id="æ¦‚è¿°">æ¦‚è¿°</h1><p>kè¿‘é‚»æ³•(k-Nearest Neighbor, kNN)æ˜¯æœºå™¨å­¦ä¹ æ‰€æœ‰ç®—æ³•ä¸­ç†è®ºæœ€ç®€å•ï¼Œæœ€å¥½ç†è§£çš„ç®—æ³•ã€‚å®ƒæ˜¯ä¸€ç§åŸºæœ¬çš„åˆ†ç±»ä¸å›å½’æ–¹æ³•ï¼Œå®ƒçš„è¾“å…¥ä¸ºå®ä¾‹çš„ç‰¹å¾å‘é‡ï¼Œé€šè¿‡è®¡ç®—æ–°æ•°æ®ä¸è®­ç»ƒæ•°æ®ç‰¹å¾å€¼ä¹‹é—´çš„è·ç¦»ï¼Œç„¶åé€‰å–<span class="math inline">\(K(Kâ‰¥1)\)</span>ä¸ªè·ç¦»æœ€è¿‘çš„é‚»å±…è¿›è¡Œåˆ†ç±»åˆ¤æ–­(æŠ•ç¥¨æ³•)æˆ–è€…å›å½’ã€‚å¦‚æœ<span class="math inline">\(K=1\)</span>ï¼Œé‚£ä¹ˆæ–°æ•°æ®è¢«ç®€å•åœ°åˆ†é…ç»™å…¶è¿‘é‚»çš„ç±»ã€‚</p><p>å¯¹äºåˆ†ç±»é—®é¢˜ï¼šè¾“å‡ºä¸ºå®ä¾‹çš„ç±»åˆ«ã€‚åˆ†ç±»æ—¶ï¼Œå¯¹äºæ–°çš„å®ä¾‹ï¼Œæ ¹æ®å…¶<span class="math inline">\(k\)</span>ä¸ªæœ€è¿‘é‚»çš„è®­ç»ƒå®ä¾‹çš„ç±»åˆ«ï¼Œé€šè¿‡å¤šæ•°è¡¨å†³ç­‰æ–¹å¼è¿›è¡Œé¢„æµ‹ã€‚</p><p>å¯¹äºå›å½’é—®é¢˜ï¼šè¾“å‡ºä¸ºå®ä¾‹çš„å€¼ã€‚å›å½’æ—¶ï¼Œå¯¹äºæ–°çš„å®ä¾‹ï¼Œå–å…¶<span class="math inline">\(k\)</span>ä¸ªæœ€è¿‘é‚»çš„è®­ç»ƒå®ä¾‹çš„å¹³å‡å€¼ä¸ºé¢„æµ‹å€¼ã€‚</p><p>kè¿‘é‚»æ³•åˆ†ç±»çš„ç›´è§‚ç†è§£ï¼šç»™å®šä¸€ä¸ªè®­ç»ƒæ•°æ®é›†ï¼Œå¯¹äºæ–°çš„è¾“å…¥å®ä¾‹ï¼Œåœ¨è®­ç»ƒé›†ä¸­æ‰¾åˆ°ä¸è¯¥å®ä¾‹æœ€é‚»è¿‘çš„<span class="math inline">\(k\)</span>ä¸ªå®ä¾‹ã€‚è¿™<span class="math inline">\(k\)</span>ä¸ªå®ä¾‹çš„å¤šæ•°å±äºæŸä¸ªç±»åˆ«ï¼Œåˆ™è¯¥è¾“å…¥å®ä¾‹å°±åˆ’åˆ†ä¸ºè¿™ä¸ªç±»åˆ«ã€‚</p><p>kè¿‘é‚»æ³•ä¸å…·æœ‰æ˜¾å¼çš„å­¦ä¹ è¿‡ç¨‹ï¼Œå®ƒæ˜¯ç›´æ¥é¢„æµ‹ã€‚å®é™…ä¸Šå®ƒæ˜¯åˆ©ç”¨è®­ç»ƒæ•°æ®é›†å¯¹ç‰¹å¾å‘é‡ç©ºé—´è¿›è¡Œåˆ’åˆ†ï¼Œå¹¶ä¸”ä½œä¸ºå…¶åˆ†ç±»çš„â€œæ¨¡å‹â€ã€‚</p><a id="more"></a><h1 id="ç®—æ³•">ç®—æ³•</h1><h2 id="knnä¸‰è¦ç´ ">KNNä¸‰è¦ç´ </h2><p>kè¿‘é‚»æ³•çš„ä¸‰è¦ç´ ï¼š<span class="math inline">\(k\)</span>å€¼é€‰æ‹©ã€è·ç¦»åº¦é‡å’Œåˆ†ç±»å†³ç­–è§„åˆ™(å³å‡å€¼çš„å†³ç­–è§„åˆ™)ã€‚</p><h3 id="kå€¼é€‰æ‹©">kå€¼é€‰æ‹©</h3><p>å½“<span class="math inline">\(k=1\)</span>æ—¶çš„kè¿‘é‚»ç®—æ³•ç§°ä¸ºæœ€è¿‘é‚»ç®—æ³•ã€‚æ­¤æ—¶å°†è®­ç»ƒé›†ä¸­ä¸<span class="math inline">\(\vec{x}\)</span>æœ€è¿‘çš„ç‚¹ç‚¹ç±»åˆ«ä½œä¸º<span class="math inline">\(\vec{x}\)</span>çš„åˆ†ç±»ã€‚</p><p><span class="math inline">\(k\)</span>å€¼çš„é€‰æ‹©ä¼šå¯¹kè¿‘é‚»æ³•çš„ç»“æœäº§ç”Ÿé‡å¤§å½±å“ã€‚</p><ul><li>è‹¥<span class="math inline">\(k\)</span>å€¼è¾ƒå°ï¼Œåˆ™ç›¸å½“äºç”¨è¾ƒå°çš„é‚»åŸŸä¸­çš„è®­ç»ƒå®ä¾‹è¿›è¡Œé¢„æµ‹ï¼Œå­¦ä¹ çš„è¿‘ä¼¼è¯¯å·®å‡å°ã€‚<ul><li>ä¼˜ç‚¹ï¼šåªæœ‰ä¸è¾“å…¥å®ä¾‹è¾ƒè¿‘çš„è®­ç»ƒå®ä¾‹æ‰ä¼šå¯¹é¢„æµ‹èµ·ä½œç”¨ã€‚</li><li>ç¼ºç‚¹ï¼šå­¦ä¹ çš„ä¼°è®¡è¯¯å·®ä¼šå¢å¤§ï¼Œé¢„æµ‹ç»“æœä¼šå¯¹è¿‘é‚»çš„å®ä¾‹ç‚¹éå¸¸æ•æ„Ÿã€‚è‹¥è¿‘é‚»çš„è®­ç»ƒå®ä¾‹ç‚¹åˆšå¥½æ˜¯å™ªå£°ï¼Œåˆ™é¢„æµ‹ä¼šå‡ºé”™ã€‚å³<span class="math inline">\(k\)</span>å€¼çš„å‡å°æ„å‘³ç€æ¨¡å‹æ•´ä½“å˜å¤æ‚ï¼Œæ˜“å‘ç”Ÿè¿‡æ‹Ÿåˆã€‚</li></ul></li><li>è‹¥<span class="math inline">\(k\)</span>å€¼è¾ƒå¤§ï¼Œåˆ™ç›¸å½“äºç”¨è¾ƒå¤§çš„é‚»åŸŸä¸­çš„è®­ç»ƒå®ä¾‹è¿›è¡Œé¢„æµ‹ã€‚<ul><li>ä¼˜ç‚¹ï¼šå‡å°‘å­¦ä¹ çš„ä¼°è®¡è¯¯å·®ã€‚</li><li>ç¼ºç‚¹ï¼šå­¦ä¹ çš„è¿‘ä¼¼è¯¯å·®ä¼šå¢å¤§ã€‚è¿™æ—¶è¾“å…¥å®ä¾‹è¾ƒè¿œçš„è®­ç»ƒå®ä¾‹ä¹Ÿä¼šå¯¹é¢„æµ‹èµ·ä½œç”¨ï¼Œä½¿é¢„æµ‹å‘ç”Ÿé”™è¯¯ï¼Œå³<span class="math inline">\(k\)</span>å€¼å¢å¤§æ„å‘³ç€æ¨¡å‹çš„æ•´ä½“å˜ç®€å•ã€‚å½“<span class="math inline">\(k=N\)</span>æ—¶ï¼Œæ— è®ºè¾“å…¥å®ä¾‹æ˜¯ä»€ä¹ˆï¼Œéƒ½å°†å®ƒé¢„æµ‹ä¸ºè®­ç»ƒå®ä¾‹ä¸­æœ€å¤šçš„ç±»ï¼ˆå³é¢„æµ‹ç»“æœæ˜¯ä¸€ä¸ªå¸¸é‡ï¼‰ã€‚æ­¤æ—¶æ¨¡å‹è¿‡äºç®€å•ï¼Œå®Œå…¨å¿½ç•¥äº†è®­ç»ƒå®ä¾‹ä¸­å¤§é‡æœ‰ç”¨çš„ä¿¡æ¯ã€‚</li></ul></li></ul><p>åº”ç”¨ä¸­ï¼Œ<span class="math inline">\(k\)</span>å€¼ä¸€èˆ¬å–ä¸€ä¸ªè¾ƒå°çš„æ•°å€¼ã€‚é€šå¸¸é‡‡ç”¨äº¤å‰éªŒè¯æ³•æ¥é€‰å–æœ€ä¼˜çš„<span class="math inline">\(k\)</span>å€¼ï¼Œå°±æ˜¯æ¯”è¾ƒä¸åŒ<span class="math inline">\(k\)</span>å€¼æ—¶çš„äº¤å‰éªŒè¯å¹³å‡è¯¯å·®ç‡ï¼Œé€‰æ‹©è¯¯å·®ç‡æœ€å°çš„é‚£ä¸ª<span class="math inline">\(k\)</span>å€¼ã€‚</p><h3 id="è·ç¦»åº¦é‡">è·ç¦»åº¦é‡</h3><p>kNNç®—æ³•è¦æ±‚æ•°æ®çš„æ‰€æœ‰ç‰¹å¾éƒ½å¯ä»¥åšå¯æ¯”è¾ƒçš„é‡åŒ–ã€‚è‹¥åœ¨æ•°æ®ç‰¹å¾ä¸­å­˜åœ¨éæ•°å€¼çš„ç±»å‹ï¼Œå¿…é¡»é‡‡å–æ‰‹æ®µå°†å…¶é‡åŒ–ä¸ºæ•°å€¼ã€‚æ¯”å¦‚ï¼Œå¦‚æœæ ·æœ¬ç‰¹å¾ä¸­åŒ…å«é¢œè‰²(çº¢ã€é»‘ã€è“)ä¸€é¡¹ï¼Œé¢œè‰²ä¹‹é—´æ˜¯æ²¡æœ‰è·ç¦»å¯è¨€çš„ï¼Œå¯é€šè¿‡å°†é¢œè‰²è½¬æ¢ä¸ºç°åº¦å€¼æ¥å®ç°è·ç¦»è®¡ç®—ã€‚å¦å¤–ï¼Œæ ·æœ¬æœ‰å¤šä¸ªå‚æ•°ï¼Œæ¯ä¸€ä¸ªå‚æ•°éƒ½æœ‰è‡ªå·±çš„å®šä¹‰åŸŸå’Œå–å€¼èŒƒå›´ï¼Œå®ƒä»¬å¯¹è·ç¦»è®¡ç®—çš„å½±å“ä¹Ÿå°±ä¸ä¸€æ ·ï¼Œå¦‚å–å€¼è¾ƒå¤§çš„å½±å“åŠ›ä¼šç›–è¿‡å–å€¼è¾ƒå°çš„å‚æ•°ã€‚ä¸ºäº†å…¬å¹³ï¼Œæ ·æœ¬å‚æ•°å¿…é¡»åšä¸€äº›å½’ä¸€åŒ–å¤„ç†ï¼Œæœ€ç®€å•çš„æ–¹å¼å°±æ˜¯æ‰€æœ‰ç‰¹å¾çš„æ•°å€¼éƒ½é‡‡å–å½’ä¸€åŒ–å¤„ç½®ã€‚</p><p>ç‰¹å¾ç©ºé—´ä¸­ä¸¤ä¸ªå®ä¾‹ç‚¹çš„è·ç¦»æ˜¯ä¸¤ä¸ªå®ä¾‹ç‚¹ç›¸ä¼¼ç¨‹åº¦çš„åæ˜ ã€‚kè¿‘é‚»æ¨¡å‹çš„ç‰¹å¾ç©ºé—´ä¸€èˆ¬æ˜¯<span class="math inline">\(n\)</span>ç»´å®æ•°å‘é‡ç©ºé—´<span class="math inline">\(R^n\)</span>ã€‚kè¿‘é‚»æ¨¡å‹çš„ç‰¹å¾ç©ºé—´çš„è·ç¦»ä¸€èˆ¬ä¸ºæ¬§æ°è·ç¦»ï¼Œä¹Ÿå¯ä»¥æ˜¯ä¸€èˆ¬<span class="math inline">\(L_p\)</span>è·ç¦»ï¼š</p><p><span class="math display">\[L_p(\vec{x}_i,\vec{x}_j)=(\sum_{l=1}^n|x_i^{(l)}-x_j^{(l)}|^p)^{1/p} \\ \vec{x}_i,\vec{x}_j\in ğ’³=R^n \\ \vec{x}_i=(x_i^{(1)},x_i^{(2)},â€¦,x_i^{(n)})^T \\ \vec{x}_j=(x_j^{(1)},x_j^{(2)},â€¦,x_j^{(n)})^T \\ pâ‰¥1\]</span></p><ul><li>å½“<span class="math inline">\(p=2\)</span>æ—¶ï¼Œä¸ºæ¬§æ°è·ç¦»ï¼š<span class="math inline">\(L_2(\vec{x}_i,\vec{x}_j)=(\sum_{l=1}^n|x_i^{(l)}-x_j^{(l)}|^2)^{1/2}\)</span></li><li>å½“<span class="math inline">\(p=1\)</span>æ—¶ï¼Œä¸ºæ›¼å“ˆé¡¿è·ç¦»ï¼š<span class="math inline">\(L_1(\vec{x}_i,\vec{x}_j)=\sum_{l=1}^n|x_i^{(l)}-x_j^{(l)}|\)</span></li><li>å½“<span class="math inline">\(p=âˆ\)</span>æ—¶ï¼Œä¸ºå„ç»´åº¦è·ç¦»ä¸­çš„æœ€å¤§å€¼ï¼š<span class="math inline">\(L_âˆ(\vec{x}_i,\vec{x}_j)=\max_l|x_i^{(l)}-x_j^{(l)}|\)</span></li></ul><p>ä¸åŒçš„è·ç¦»åº¦é‡æ‰€ç¡®å®šçš„æœ€è¿‘é‚»ç‚¹æ˜¯ä¸åŒçš„ã€‚ä¸€èˆ¬æƒ…å†µä¸‹ï¼Œé€‰æ¬§æ°è·ç¦»ä½œä¸ºè·ç¦»åº¦é‡ï¼Œä½†è¿™åªé€‚ç”¨äºè¿ç»­å˜é‡ã€‚åœ¨æ–‡æœ¬åˆ†ç±»è¿™ç§éè¿ç»­å˜é‡æƒ…å†µä¸‹ï¼Œæ±‰æ˜è·ç¦»å¯ä»¥ç”¨æ¥ä½œä¸ºåº¦é‡ã€‚é€šå¸¸æƒ…å†µä¸‹ï¼Œå¦‚æœè¿ç”¨ä¸€äº›ç‰¹æ®Šçš„ç®—æ³•æ¥è®¡ç®—åº¦é‡çš„è¯ï¼ŒKè¿‘é‚»åˆ†ç±»çš„ç²¾åº¦å¯æ˜¾è‘—æé«˜ï¼Œå¦‚è¿ç”¨å¤§è¾¹ç¼˜æœ€è¿‘é‚»æ³•æˆ–è€…è¿‘é‚»æˆåˆ†åˆ†ææ³•ã€‚</p><h3 id="åˆ†ç±»å†³ç­–è§„åˆ™">åˆ†ç±»å†³ç­–è§„åˆ™</h3><p>åˆ†ç±»å†³ç­–é€šå¸¸é‡‡ç”¨å¤šæ•°è¡¨å†³ã€‚ä¹Ÿå¯ä»¥åŸºäºè·ç¦»çš„è¿œè¿‘è¿›è¡ŒåŠ æƒæŠ•ç¥¨ï¼Œè·ç¦»è¶Šè¿‘çš„æ ·æœ¬æƒé‡è¶Šå¤§ã€‚</p><p>å¤šæ•°è¡¨å†³è§„åˆ™ç­‰ä»·äºç»éªŒé£é™©æœ€å°åŒ–ã€‚è®¾åˆ†ç±»çš„æŸå¤±å‡½æ•°ä¸º0-1æŸå¤±å‡½æ•°ï¼Œåˆ†ç±»å‡½æ•°ä¸º<span class="math inline">\(f\)</span>ï¼š<span class="math inline">\(R^n\to \{c_1,c_2,â€¦,c_K\}\)</span>ï¼Œè¯¯åˆ†ç±»æ¦‚ç‡ä¸ºï¼š<span class="math inline">\(P(Yâ‰ f(X))=1-P(Y=f(X))\)</span>ã€‚</p><p>ç»™å®šå®ä¾‹<span class="math inline">\(\vec{x}\in ğ’³\)</span>ï¼Œå…¶æœ€é‚»è¿‘çš„<span class="math inline">\(k\)</span>ä¸ªè®­ç»ƒç‚¹æ„æˆé›†åˆ<span class="math inline">\(N_k(\vec{x})\)</span>ã€‚è®¾æ¶µç›–<span class="math inline">\(N_k(\vec{x})\)</span>åŒºåŸŸç‚¹ç±»åˆ«ä¸º<span class="math inline">\(c_j\)</span>ï¼ˆè¿™æ˜¯ä¸ªå¾…æ±‚çš„æœªçŸ¥é‡ï¼Œä½†å®ƒè‚¯å®šæ˜¯<span class="math inline">\(c_1,c_2,â€¦,c_K\)</span>ä¹‹ä¸€ï¼‰ï¼Œåˆ™è¯¯åˆ†ç±»ç‡ä¸ºï¼š</p><p><span class="math display">\[\frac{1}{k}\sum_{\vec{x}_i\in N_k(\vec{x})}I(y_iâ‰ c_j)=1-\frac{1}{k}\sum_{\vec{x}_i\in N_k(\vec{x})}I(y_i=c_j)\]</span></p><p>è¯¯åˆ†ç±»ç‡å°±æ˜¯è®­ç»ƒæ•°æ®çš„ç»éªŒé£é™©ã€‚è¦ä½¿è¯¯åˆ†ç±»ç‡æœ€å°ï¼Œå³ç»éªŒé£é™©æœ€å°ï¼Œå°±è¦ä½¿å¾—<span class="math inline">\(\sum_{\vec{x}_i\in N_k(\vec{x})}I(y_i=c_j)\)</span>æœ€å¤§ã€‚å³å¤šæ•°è¡¨å†³ï¼š</p><p><span class="math display">\[c_j=\arg \max_{c_j}\sum_{\vec{x}_i\in N_k(\vec{x})}I(y_i=c_j)\]</span></p><h2 id="kè¿‘é‚»ç®—æ³•">kè¿‘é‚»ç®—æ³•</h2><p>kè¿‘é‚»ç®—æ³•çš„åˆ†ç±»ç®—æ³•æè¿°å¦‚ä¸‹ï¼š</p><p>è¾“å…¥ï¼šè®­ç»ƒæ•°æ®é›†<span class="math inline">\(T=\{(\vec{x}_1,y_1),(\vec{x}_2,y_2),â€¦,(\vec{x}_N,y_N)\}\)</span>, <span class="math inline">\(\vec{x}_i\in ğ’³ \subseteq R^n\)</span>ä¸ºå®ä¾‹çš„ç‰¹å¾å‘é‡ï¼Œ<span class="math inline">\(y_i\in ğ’´ =\{c_1,c_2,â€¦,c_K\}\)</span>ä¸ºå®ä¾‹çš„ç±»åˆ«ï¼Œ<span class="math inline">\(i=1,2,â€¦,N\)</span>ã€‚ç»™å®šå®ä¾‹ç‰¹å¾å‘é‡<span class="math inline">\(\vec{x}\)</span>ã€‚</p><p>è¾“å‡ºï¼šå®ä¾‹<span class="math inline">\(\vec{x}\)</span>æ‰€å±çš„ç±»åˆ«<span class="math inline">\(y\)</span>ã€‚</p><p>æ­¥éª¤ï¼š</p><ul><li>æ ¹æ®ç»™å®šçš„è·ç¦»åº¦é‡ï¼Œåœ¨<span class="math inline">\(T\)</span>ä¸­å¯»æ‰¾ä¸<span class="math inline">\(\vec{x}\)</span>æœ€è¿‘é‚»çš„<span class="math inline">\(k\)</span>ä¸ªç‚¹ã€‚å®šä¹‰æ¶µç›–è¿™<span class="math inline">\(k\)</span>ä¸ªç‚¹çš„<span class="math inline">\(\vec{x}\)</span>çš„é‚»åŸŸè®°ä½œ<span class="math inline">\(N_k(\vec{x})\)</span>ã€‚</li><li>ä»<span class="math inline">\(N_k(\vec{x})\)</span>ä¸­ï¼Œæ ¹æ®åˆ†ç±»å†³ç­–è§„åˆ™ï¼ˆå¦‚å¤šæ•°è¡¨å†³ï¼‰å†³å®š<span class="math inline">\(\vec{x}\)</span>çš„ç±»åˆ«<span class="math inline">\(y\)</span>ï¼š<span class="math display">\[y=\arg \max_{c_j}\sum_{\vec{x}_i\in N_k(\vec{x})}I(y_i=c_j),i=1,2,â€¦,N;j=1,2,â€¦,K\]</span>å…¶ä¸­<span class="math inline">\(I\)</span>ä¸ºæŒ‡ç¤ºå‡½æ•°ï¼š<span class="math inline">\(I(true)=1,I(false)=0\)</span>ã€‚ä¸Šå¼ä¸­ï¼Œå¯¹äº<span class="math inline">\(y_i,i=1,2,â€¦,N\)</span>åªæœ‰<span class="math inline">\(\vec{x}_i\in N_k(\vec{x})\)</span>ä¸­çš„æ ·æœ¬ç‚¹æ‰è€ƒè™‘ã€‚</li></ul><p>kè¿‘é‚»æ³•çš„å­¦ä¹ æœ‰ä¸€ä¸ªæ˜æ˜¾çš„ç‰¹ç‚¹ï¼šå®ƒæ²¡æœ‰æ˜¾å¼çš„è®­ç»ƒè¿‡ç¨‹ã€‚å®ƒåœ¨è®­ç»ƒé˜¶æ®µä»…ä»…å°†æ ·æœ¬ä¿å­˜èµ·æ¥ï¼Œè®­ç»ƒæ—¶é—´å¼€é”€ä¸ºé›¶ï¼Œç­‰åˆ°æ”¶åˆ°æµ‹è¯•æ ·æœ¬åå†è¿›è¡Œå¤„ç†ã€‚</p><h2 id="kdæ ‘">kdæ ‘</h2><p>kè¿‘é‚»æ³•ä¸­å¦‚ä½•å¯¹è®­ç»ƒæ•°æ®è¿›è¡Œå¿«é€Ÿkè¿‘é‚»æœç´¢æ˜¯ä¸ªé—®é¢˜ã€‚æœ€ç®€å•ç²—æš´çš„åŠæ³•æ˜¯ï¼šçº¿æ€§æ‰«æã€‚é€šè¿‡è®¡ç®—è¾“å…¥æ ·æœ¬ä¸æ¯ä¸ªè®­ç»ƒæ ·æœ¬çš„è·ç¦»ï¼Œæ¥æ‰¾å‡ºæœ€è¿‘é‚»çš„<span class="math inline">\(k\)</span>ä¸ªè®­ç»ƒæ ·æœ¬ã€‚å½“è®­ç»ƒé›†å¾ˆå¤§æ—¶ï¼Œè®¡ç®—éå¸¸è€—æ—¶ã€‚å¸¸ç”¨çš„è§£å†³æ–¹æ³•æ˜¯ä½¿ç”¨kdæ ‘ï¼Œå®ƒå¯ä»¥å¤§å¹…æé«˜<span class="math inline">\(k\)</span>è¿‘é‚»æœç´¢çš„æ•ˆç‡ã€‚</p><p>kdæ ‘æ˜¯äºŒå‰æ ‘ï¼Œè¡¨ç¤ºå¯¹<span class="math inline">\(k\)</span>ç»´ç©ºé—´çš„ä¸€ä¸ªåˆ’åˆ†ã€‚æ„é€ å¹³è¡¡kdæ ‘çš„ç®—æ³•å¦‚ä¸‹ï¼š</p><ul><li>è¾“å…¥ï¼š<span class="math inline">\(k\)</span>ç»´ç©ºé—´æ•°æ®é›†<span class="math inline">\(T=\{\vec{x}_1,\vec{x}_2,â€¦,\vec{x}_N\},\vec{x}_i\in ğ’³ \subseteq R^k\)</span></li><li>è¾“å‡ºï¼škdæ ‘</li><li>ç®—æ³•æ­¥éª¤ï¼š<ul><li>å¼€å§‹ï¼šæ„é€ æ ¹èŠ‚ç‚¹ã€‚é€‰æ‹©<span class="math inline">\(x^{(1)}\)</span>ä¸ºè½´ï¼Œä»¥<span class="math inline">\(T\)</span>ä¸­æ‰€æœ‰æ ·æœ¬çš„<span class="math inline">\(x^{(1)}\)</span>åæ ‡çš„ä¸­ä½æ•°<span class="math inline">\(x^{(1)*}\)</span>ä½œä¸ºåˆ‡åˆ†ç‚¹ï¼Œå°†æ ¹èŠ‚ç‚¹çš„è¶…çŸ©å½¢åˆ‡åˆ†æˆä¸¤ä¸ªå­åŒºåŸŸï¼ˆåˆ‡åˆ†è¶…å¹³é¢<span class="math inline">\(x^{(1)}=x^{(1)*}\)</span>ï¼‰ã€‚æœ¬æ¬¡åˆ‡åˆ†äº§ç”Ÿæ·±åº¦ä¸º1çš„å·¦ã€å³å­èŠ‚ç‚¹ã€‚å·¦å­èŠ‚ç‚¹å¯¹åº”äºåæ ‡<span class="math inline">\(x^{(1)}&lt;x^{(1)*}\)</span>çš„å­åŒºåŸŸï¼›å³å­èŠ‚ç‚¹å¯¹åº”äºåæ ‡<span class="math inline">\(x^{(1)}&gt;x^{(1)*}\)</span>çš„å­åŒºåŸŸï¼›è½åœ¨åˆ‡åˆ†è¶…å¹³é¢ä¸Šçš„ç‚¹ï¼ˆ<span class="math inline">\(x^{(1)}=x^{(1)*}\)</span>ï¼‰ä¿å­˜åœ¨æ ¹èŠ‚ç‚¹ã€‚</li><li>é‡å¤ï¼šå¯¹æ·±åº¦ä¸º<span class="math inline">\(j\)</span>çš„å­èŠ‚ç‚¹ï¼Œé€‰æ‹©<span class="math inline">\(x^{(l)}\)</span>ä¸ºåˆ‡åˆ†çš„åæ ‡è½´ï¼Œ<span class="math inline">\(l=j(\mod k)+1\)</span>ã€‚æœ¬æ¬¡åˆ‡åˆ†ä¹‹åï¼Œæ ‘çš„æ·±åº¦ä¸º<span class="math inline">\(j+1\)</span>ã€‚è¿™é‡Œå–æ¨¡ï¼Œè€Œä¸æ˜¯<span class="math inline">\(l=j+1\)</span>ï¼Œæ˜¯å› ä¸ºæ ‘çš„æ·±åº¦å¯ä»¥è¶…è¿‡ç»´åº¦<span class="math inline">\(k\)</span>ï¼Œæ­¤æ—¶åˆ‡åˆ†è½´åˆé‡å¤å›åˆ°<span class="math inline">\(x^{(1)}\)</span>ï¼Œè½®è½¬åæ ‡è½´è¿›è¡Œåˆ‡åˆ†ã€‚</li><li>ç»“æŸï¼šç›´åˆ°æ‰€æœ‰èŠ‚ç‚¹çš„ä¸¤ä¸ªå­åŸŸä¸­æ²¡æœ‰æ ·æœ¬å­˜åœ¨æ—¶ï¼Œåˆ‡åˆ†åœæ­¢ã€‚æ­¤æ—¶å¾—åˆ°kdæ ‘ã€‚</li></ul></li></ul><p>ä½¿ç”¨kdæ ‘çš„ç®—æ³•ç›¸å¯¹å¤æ‚ã€‚ç”¨kdæ ‘çš„æœ€è¿‘é‚»æœç´¢ç®—æ³•(kè¿‘é‚»æœç´¢ä¾æ¬¡ç±»æ¨)å¦‚ä¸‹ï¼š</p><ul><li>è¾“å…¥ï¼š<ul><li>kdæ ‘</li><li>æ ·æœ¬<span class="math inline">\(\vec{x}\)</span></li></ul></li><li>è¾“å‡ºï¼šæ ·æœ¬<span class="math inline">\(\vec{x}\)</span>çš„æœ€è¿‘é‚»ç‚¹</li><li>æ­¥éª¤ï¼š<ul><li>åœ¨kdæ ‘ä¸­æ‰¾åˆ°åŒ…å«æµ‹è¯•ç‚¹<span class="math inline">\(\vec{x}\)</span>çš„å¶èŠ‚ç‚¹ã€‚æ–¹æ³•æ˜¯ï¼šä»æ ¹èŠ‚ç‚¹å‡ºå‘ï¼Œé€’å½’å‘ä¸‹è®¿é—®kdæ ‘ï¼š<ul><li>è‹¥æµ‹è¯•ç‚¹<span class="math inline">\(\vec{x}\)</span>å½“å‰ç»´åº¦çš„åæ ‡å°äºåˆ‡åˆ†ç‚¹çš„åæ ‡ï¼Œåˆ™æŸ¥æ‰¾å½“å‰èŠ‚ç‚¹çš„å·¦å­èŠ‚ç‚¹</li><li>è‹¥æµ‹è¯•ç‚¹<span class="math inline">\(\vec{x}\)</span>å½“å‰ç»´åº¦çš„åæ ‡å¤§äºåˆ‡åˆ†ç‚¹çš„åæ ‡ï¼Œåˆ™æŸ¥æ‰¾å½“å‰èŠ‚ç‚¹çš„å³å­èŠ‚ç‚¹ï¼Œåœ¨è®¿é—®è¿‡ç¨‹ä¸­è®°å½•ä¸‹è®¿é—®çš„å„èŠ‚ç‚¹çš„é¡ºåºï¼ˆä»¥ä¾¿äºåé¢çš„å›é€€ï¼‰</li></ul></li><li>ä»¥æ­¤å¶èŠ‚ç‚¹ä¸ºâ€œå½“å‰æœ€è¿‘â€<span class="math inline">\(\vec{x}_{nst}\)</span>ã€‚çœŸå®æœ€è¿‘ç‚¹ä¸€å®šåœ¨<span class="math inline">\(\vec{x}\)</span>ä¸â€œå½“å‰æœ€è¿‘ç‚¹â€æ„æˆçš„è¶…çƒä½“å†…ã€‚<span class="math inline">\(\vec{x}\)</span>ä¸ºçƒå¿ƒã€‚</li><li>è®¾å½“å‰è€ƒå¯Ÿçš„èŠ‚ç‚¹ä¸º<span class="math inline">\(\vec{x}_i\)</span>ï¼Œé€’å½’å‘ä¸Šå›é€€ï¼Œè®¾å›é€€å¼¹å‡ºçš„èŠ‚ç‚¹ä¸º<span class="math inline">\(\vec{x}_{inew}\)</span>ï¼ˆæ¯æ¬¡å›é€€éƒ½æ˜¯é€€åˆ°kdæ ‘çš„çˆ¶èŠ‚ç‚¹ï¼‰ï¼Œè€ƒå¯ŸèŠ‚ç‚¹<span class="math inline">\(\vec{x}_{inew}\)</span>æ‰€åœ¨çš„è¶…å¹³é¢ä¸ä»¥<span class="math inline">\(\vec{x}\)</span>ä¸ºçƒå¿ƒã€ä»¥<span class="math inline">\(\vec{x}\)</span>åˆ°å½“å‰æœ€è¿‘ç‚¹<span class="math inline">\(\vec{x}_{nst}\)</span>çš„è·ç¦»ä¸ºåŠå¾„çš„è¶…çƒä½“æ˜¯å¦ç›¸äº¤ï¼š<ul><li>è‹¥ç›¸äº¤<ul><li>è‹¥<span class="math inline">\(\vec{x}\)</span>æ˜¯<span class="math inline">\(\vec{x}_{inew}\)</span>çš„å·¦å­èŠ‚ç‚¹ï¼Œåˆ™è¿›å…¥<span class="math inline">\(\vec{x}_{inew}\)</span>çš„å³å­èŠ‚ç‚¹ï¼Œç„¶åå…ˆè¿›è¡Œå‘ä¸‹æœç´¢ï¼Œå†ç„¶åå‘ä¸Šå›é€€ã€‚</li><li>è‹¥<span class="math inline">\(\vec{x}\)</span>æ˜¯<span class="math inline">\(\vec{x}_{inew}\)</span>çš„å³å­èŠ‚ç‚¹ï¼Œåˆ™è¿›å…¥<span class="math inline">\(\vec{x}_{inew}\)</span>çš„å·¦å­èŠ‚ç‚¹ï¼Œç„¶åå…ˆè¿›è¡Œå‘ä¸‹æœç´¢ï¼Œå†ç„¶åå‘ä¸Šå›é€€ã€‚</li></ul></li><li>è‹¥ä¸ç›¸äº¤ï¼Œåˆ™ç›´æ¥å›é€€</li></ul></li><li>å½“å›é€€åˆ°æ ¹èŠ‚ç‚¹æ—¶ï¼Œæœç´¢ç»“æŸã€‚æœ€åçš„â€œå½“å‰æœ€è¿‘ç‚¹â€å³ä¸º<span class="math inline">\(\vec{x}\)</span>çš„æœ€è¿‘é‚»ç‚¹ã€‚</li></ul></li></ul><p>kdæ ‘æœç´¢çš„å¹³å‡è®¡ç®—å¤æ‚åº¦ä¸º<span class="math inline">\(O(\log N)\)</span>ï¼Œ<span class="math inline">\(N\)</span>ä¸ºè®­ç»ƒé›†å¤§å°ã€‚kdæ ‘é€‚åˆ<span class="math inline">\(N\gg k\)</span>çš„æƒ…å½¢ã€‚å½“<span class="math inline">\(N\)</span>ä¸ç»´åº¦<span class="math inline">\(k\)</span>æ¥è¿‘æ—¶ï¼Œæœç´¢çš„æ•ˆç‡æ¥è¿‘çº¿æ€§æ‰«æã€‚</p><h1 id="pythonå®æˆ˜">Pythonå®æˆ˜</h1><p>é¦–å…ˆå¯¼å…¥åŒ…ï¼š</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">from sklearn import neighbors, datasets, model_selection</span><br></pre></td></tr></table></figure><p>ç„¶ååŠ è½½æ•°æ®é›†ï¼š</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">def load_classification_data():</span><br><span class="line">    digits = datasets.load_digits()</span><br><span class="line">    X_train = digits.data</span><br><span class="line">    y_train = digits.target</span><br><span class="line">    return model_selection.train_test_split(X_train, y_train, test_size=0.25, random_state=0, stratify=y_train)</span><br><span class="line"></span><br><span class="line">def create_regression_data(n):</span><br><span class="line">    X = 5 * np.random.rand(n, 1)</span><br><span class="line">    y = np.sin(X).ravel()</span><br><span class="line">    y[::5] += 1 * (0.5 - np.random.rand(int(n/5)))</span><br><span class="line">    return model_selection.train_test_split(X, y, test_size=0.25, random_state=0)</span><br></pre></td></tr></table></figure><p>å…¶ä¸­ï¼Œload_classification_dataå‡½æ•°ä½¿ç”¨çš„æ˜¯scikit-learnè‡ªå¸¦çš„æ‰‹å†™è¯†åˆ«æ•°æ®é›†DigitDatasetã€‚è¯¥æ•°æ®é›†ç”±1797å¼ æ ·æœ¬å›¾ç‰‡ç»„æˆã€‚æ¯å¼ æ ·æœ¬å›¾ç‰‡éƒ½æ˜¯ä¸€ä¸ª<span class="math inline">\(8 \times 8\)</span>å¤§å°çš„æ‰‹å†™æ•°å­—ä½å›¾ã€‚create_regression_dataå‡½æ•°æ˜¯åœ¨sin(X)åŸºç¡€ä¸Šæ·»åŠ å™ªå£°ç”Ÿæˆçš„ã€‚</p><h2 id="knnåˆ†ç±»kneighborsclassifier">KNNåˆ†ç±»(KNeighborsClassifier)</h2><p>scikit-learnä¸­æä¾›äº†ä¸€ä¸ªKNeighborsClassifierç±»æ¥å®ç°kè¿‘é‚»æ³•åˆ†ç±»æ¨¡å‹ï¼Œå…¶åŸå‹ä¸ºï¼š</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">sklearn.neighbors.KNeighborsClassifier(n_neighbors=5,</span><br><span class="line">                 weights=&apos;uniform&apos;, algorithm=&apos;auto&apos;, leaf_size=30,</span><br><span class="line">                 p=2, metric=&apos;minkowski&apos;, metric_params=None, n_jobs=None,</span><br><span class="line">                 **kwargs)</span><br></pre></td></tr></table></figure><p>å‚æ•°ï¼š</p><ul><li>n_neighborsï¼šä¸€ä¸ªæ•´æ•°ï¼ŒæŒ‡å®š<span class="math inline">\(k\)</span>å€¼ã€‚</li><li>weightsï¼šä¸€ä¸ªå­—ç¬¦ä¸²æˆ–è€…å¯è°ƒç”¨å¯¹è±¡ï¼ŒæŒ‡å®šæŠ•ç¥¨æƒé‡ç±»å‹ã€‚<ul><li>'uniform'ï¼šæœ¬èŠ‚ç‚¹çš„æ‰€æœ‰é‚»å±…èŠ‚ç‚¹çš„æŠ•ç¥¨æƒé‡éƒ½ç›¸ç­‰ã€‚</li><li>'distance'ï¼šæœ¬èŠ‚ç‚¹çš„æ‰€æœ‰é‚»å±…èŠ‚ç‚¹çš„æŠ•ç¥¨æƒé‡ä¸è·ç¦»æˆåæ¯”ã€‚</li><li>[callable]ï¼šä¸€ä¸ªå¯è°ƒç”¨å¯¹è±¡ã€‚å®ƒä¼ å…¥è·ç¦»çš„æ•°ç»„ï¼Œè¿”å›åŒæ ·å½¢çŠ¶çš„æƒé‡æ•°ç»„ã€‚</li></ul></li><li>algorithmï¼šä¸€ä¸ªå­—ç¬¦ä¸²ï¼ŒæŒ‡å®šè®¡ç®—æœ€è¿‘é‚»çš„ç®—æ³•ã€‚<ul><li>'ball_tree'ï¼šä½¿ç”¨BallTreeç®—æ³•</li><li>'kd_tree'ï¼šä½¿ç”¨KDTreeç®—æ³•</li><li>'brute'ï¼šä½¿ç”¨æš´åŠ›æœç´¢æ³•</li><li>'auto'ï¼šè‡ªåŠ¨å†³å®šæœ€åˆé€‚çš„ç®—æ³•</li></ul></li><li>leaf_sizeï¼šä¸€ä¸ªæ•´æ•°ï¼ŒæŒ‡å®šBallTreeæˆ–è€…KDTreeå¶èŠ‚ç‚¹è§„æ¨¡ã€‚å®ƒå½±å“æ ‘çš„æ„å»ºå’ŒæŸ¥è¯¢é€Ÿåº¦ã€‚</li><li>metricï¼šä¸€ä¸ªå­—ç¬¦ä¸²ï¼ŒæŒ‡å®šè·ç¦»åº¦é‡ã€‚é»˜è®¤ä¸º'minkowski'è·ç¦»ã€‚</li><li>pï¼šæ•´æ•°å€¼ï¼ŒæŒ‡å®šåœ¨'Minkowski'åº¦é‡ä¸Šçš„æŒ‡æ•°ã€‚å¦‚æœp=1ï¼Œå¯¹åº”æ›¼å“ˆé¡¿è·ç¦»ï¼›å¦‚æœp=2ï¼Œå¯¹åº”æ¬§æ‹‰è·ç¦»ã€‚</li><li>n_jobsï¼šå¹¶è¡Œæ€§ã€‚é»˜è®¤ä¸º-1ï¼Œè¡¨ç¤ºæ´¾å‘ä»»åŠ¡åˆ°æ‰€æœ‰è®¡ç®—æœºçš„CPUä¸Šã€‚</li></ul><p>æ–¹æ³•ï¼š</p><ul><li>fit(X, y): è®­ç»ƒæ¨¡å‹</li><li>predict(X): ç”¨æ¨¡å‹è¿›è¡Œé¢„æµ‹ï¼Œè¿”å›å¾…é¢„æµ‹æ ·æœ¬çš„æ ‡è®°</li><li>score(X, y): è¿”å›åœ¨(X, y)ä¸Šé¢„æµ‹çš„å‡†ç¡®ç‡</li><li>predict_proba(X): è¿”å›æ ·æœ¬ä¸ºæ¯ç§æ ‡è®°çš„æ¦‚ç‡</li><li>kneighbors([X, n_neighbors, return_distance]): è¿”å›æ ·æœ¬ç‚¹çš„<span class="math inline">\(k\)</span>è¿‘é‚»ç‚¹ã€‚å¦‚æœ<code>return_distance=True</code>ï¼ŒåŒæ—¶è¿˜è¿”å›åˆ°è¿™äº›è¿‘é‚»ç‚¹çš„è·ç¦»ã€‚</li><li>kneighbors_graph([X, n_neighbors, mode]): è¿”å›æ ·æœ¬ç‚¹çš„è¿æ¥å›¾</li></ul><p>é¦–å…ˆä½¿ç”¨KNeighborsClassifierï¼š</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">def demo_KNeighborsClassifier(*data):</span><br><span class="line">    X_train, X_test, y_train, y_test = data</span><br><span class="line">    clf = neighbors.KNeighborsClassifier()</span><br><span class="line">    clf.fit(X_train, y_train)</span><br><span class="line">    print(&quot;Training score: %f&quot; % clf.score(X_train, y_train))</span><br><span class="line">    print(&quot;Testing score: %f&quot; % clf.score(X_test, y_test))</span><br></pre></td></tr></table></figure><p>è°ƒç”¨ï¼š</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">X_train, X_test, y_train, y_test = load_classification_data()</span><br><span class="line">demo_KNeighborsClassifier(X_train, X_test, y_train, y_test)</span><br></pre></td></tr></table></figure><p>ç»“æœå¦‚ä¸‹ï¼š</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Training score: 0.991091</span><br><span class="line">Testing score: 0.980000</span><br></pre></td></tr></table></figure><p>å¯ä»¥çœ‹åˆ°kè¿‘é‚»æ³•å¯¹äºæµ‹è¯•é›†çš„æ•°æ®é¢„æµ‹å‡†ç¡®ç‡é«˜è¾¾98%ï¼Œå¯¹äºè®­ç»ƒé›†çš„æ‹Ÿåˆå‡†ç¡®ç‡é«˜è¾¾99%ã€‚</p><p>ç„¶åè€ƒå¯Ÿ<span class="math inline">\(k\)</span>å€¼ä»¥åŠæŠ•ç¥¨ç­–ç•¥å¯¹äºé¢„æµ‹æ€§èƒ½çš„å½±å“ï¼š</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">def demo_KNeighborsClassifier_k_w(*data):</span><br><span class="line">    X_train, X_test, y_train, y_test = data</span><br><span class="line">    Ks = np.linspace(1, y_train.size, num=100, endpoint=False, dtype=&apos;int&apos;)</span><br><span class="line">    weights = [&apos;uniform&apos;, &apos;distance&apos;]</span><br><span class="line">    fig = plt.figure()</span><br><span class="line">    ax = fig.add_subplot(1, 1, 1)</span><br><span class="line">    for weight in weights:</span><br><span class="line">        training_scores = []</span><br><span class="line">        testing_scores = []</span><br><span class="line">        for K in Ks:</span><br><span class="line">            clf = neighbors.KNeighborsClassifier(weight=weight, n_neighbors=K)</span><br><span class="line">            clf.fit(X_train, y_train)</span><br><span class="line">            training_scores.append(clf.score(X_train, y_train))</span><br><span class="line">            testing_scores.append(clf.score(X_test, y_test))</span><br><span class="line">        ax.plot(Ks, testing_scores, label=&quot;testing score: weight=%s&quot; % weight)</span><br><span class="line">        ax.plot(Ks, training_scores, label=&quot;training score: weight=%s&quot; % weight)</span><br><span class="line">    ax.legend(loc=&apos;best&apos;)</span><br><span class="line">    ax.set_xlabel(&quot;K&quot;)</span><br><span class="line">    ax.set_ylabel(&quot;score&quot;)</span><br><span class="line">    ax.set_ylim(0, 1.05)</span><br><span class="line">    ax.set_title(&quot;KNeighborsClassifier&quot;)</span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure><p>è¿è¡Œç»“æœï¼š</p><p><img src="/images/MachineLearning/KNearestNeighbor/20190728_ML_KNeighborsClassifier_K_W.png"></p><p>å¯ä»¥çœ‹åˆ°ä½¿ç”¨uniformæŠ•ç¥¨ç­–ç•¥çš„æƒ…å†µä¸‹ï¼ˆæŠ•ç¥¨æƒé‡éƒ½ç›¸åŒï¼‰ï¼Œåˆ†ç±»å™¨éšç€<span class="math inline">\(k\)</span>çš„å¢é•¿ï¼Œé¢„æµ‹æ€§èƒ½ç¨³å®šä¸‹é™ã€‚è¿™æ˜¯å› ä¸ºå½“<span class="math inline">\(k\)</span>å¢å¤§æ—¶ï¼Œè¾“å…¥å®ä¾‹è¾ƒè¿œçš„è®­ç»ƒå®ä¾‹ä¹Ÿä¼šå¯¹é¢„æµ‹èµ·ä½œç”¨ï¼Œä½¿é¢„æµ‹å‘ç”Ÿé”™è¯¯ã€‚</p><p>åœ¨ä½¿ç”¨distanceæŠ•ç¥¨ç­–ç•¥æƒ…å†µä¸‹ï¼ˆæŠ•ç¥¨æƒé‡ä¸è·ç¦»æˆåæ¯”ï¼‰ï¼Œåˆ†ç±»å™¨éšç€<span class="math inline">\(k\)</span>çš„å¢é•¿ï¼Œå¯¹æµ‹è¯•é›†çš„é¢„æµ‹æ€§èƒ½ç›¸å¯¹æ¯”è¾ƒç¨³å®šï¼Œè¿™æ˜¯å› ä¸ºè™½ç„¶<span class="math inline">\(k\)</span>å¢å¤§æ—¶ï¼Œè¾“å…¥å®ä¾‹è¾ƒè¿œçš„è®­ç»ƒå®ä¾‹ä¹Ÿä¼šå¯¹é¢„æµ‹èµ·ä½œç”¨ï¼Œä½†å› ä¸ºè·ç¦»è¾ƒè¿œï¼Œå…¶å½±å“å°å¾—å¤šï¼ˆæƒé‡å¾ˆå°ï¼‰ã€‚</p><p>ç„¶åè€ƒå¯Ÿ<span class="math inline">\(p\)</span>å€¼ï¼ˆå³è·ç¦»å‡½æ•°çš„å½¢å¼ï¼‰å¯¹äºé¢„æµ‹æ€§èƒ½çš„å½±å“ï¼š</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">def demo_KNeighborsClassifier_k_p(*data):</span><br><span class="line">    X_train, X_test, y_train, y_test = data</span><br><span class="line">    Ks = np.linspace(1, y_train.size, endpoint=False, dtype=&apos;int&apos;)</span><br><span class="line">    Ps = [1, 2, 10]</span><br><span class="line">    fig = plt.figure()</span><br><span class="line">    ax = fig.add_subplot(1, 1, 1)</span><br><span class="line">    for P in Ps:</span><br><span class="line">        training_scores = []</span><br><span class="line">        testing_scores = []</span><br><span class="line">        for K in Ks:</span><br><span class="line">            clf = neighbors.KNeighborsClassifier(p=P, n_neighbors=K)</span><br><span class="line">            clf.fit(X_train, y_train)</span><br><span class="line">            training_scores.append(clf.score(X_train, y_train))</span><br><span class="line">            testing_scores.append(clf.score(X_test, y_test))</span><br><span class="line">        ax.plot(Ks, testing_scores, label=&quot;testing score: p=%d&quot; % P)</span><br><span class="line">        ax.plot(Ks, training_scores, label=&quot;training score: p=%d&quot; % P)</span><br><span class="line">    ax.legend(loc=&apos;best&apos;)</span><br><span class="line">    ax.set_xlabel(&quot;K&quot;)</span><br><span class="line">    ax.set_ylabel(&quot;score&quot;)</span><br><span class="line">    ax.set_ylim(0, 1.05)</span><br><span class="line">    ax.set_title(&quot;KNeighborsClassifier&quot;)</span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure><p>è¿è¡Œç»“æœï¼š</p><p><img src="/images/MachineLearning/KNearestNeighbor/20190728_ML_KNeighborsClassifier_K_P.png"></p><p>å¯ä»¥çœ‹åˆ°<span class="math inline">\(p\)</span>å‚æ•°å¯¹äºåˆ†ç±»å™¨çš„é¢„æµ‹æ€§èƒ½æ²¡æœ‰ä»»ä½•å½±å“ã€‚å› ä¸º<span class="math inline">\(L_p(\vec{x}_i,\vec{x}_j)=(\sum_{l=1}^n|x_i^{(l)}-x_j^{(l)}|^p)^{1/p}\)</span>ï¼Œå½“<span class="math inline">\(p=1\)</span>æ—¶å¦‚æœ<span class="math inline">\(\vec{x}_j\)</span>æ˜¯<span class="math inline">\(\vec{x}_i\)</span>çš„æœ€è¿‘çš„ç‚¹ï¼Œåˆ™å½“<span class="math inline">\(p\)</span>ä¸ºå…¶ä»–å€¼æ—¶ï¼Œè¯¥ç»“è®ºä¹Ÿæˆç«‹ã€‚</p><h2 id="knnå›å½’kneighborsregressor">KNNå›å½’(KNeighborsRegressor)</h2><p>scikit-learnä¸­æä¾›äº†ä¸€ä¸ªKNeighborsRegressorç±»æ¥å®ç°kè¿‘é‚»æ³•å›å½’æ¨¡å‹ï¼Œå…¶åŸå‹ä¸ºï¼š</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">sklearn.neighbors.KNeighborsRegressor(n_neighbors=5, weights=&apos;uniform&apos;,</span><br><span class="line">                 algorithm=&apos;auto&apos;, leaf_size=30,</span><br><span class="line">                 p=2, metric=&apos;minkowski&apos;, metric_params=None, n_jobs=None,</span><br><span class="line">                 **kwargs)</span><br></pre></td></tr></table></figure><p>å‚æ•°ï¼š</p><ul><li>n_neighborsï¼šä¸€ä¸ªæ•´æ•°ï¼ŒæŒ‡å®š<span class="math inline">\(k\)</span>å€¼ã€‚</li><li>weightsï¼šä¸€ä¸ªå­—ç¬¦ä¸²æˆ–è€…å¯è°ƒç”¨å¯¹è±¡ï¼ŒæŒ‡å®šæŠ•ç¥¨æƒé‡ç±»å‹ã€‚<ul><li>'uniform'ï¼šæœ¬èŠ‚ç‚¹çš„æ‰€æœ‰é‚»å±…èŠ‚ç‚¹çš„æŠ•ç¥¨æƒé‡éƒ½ç›¸ç­‰ã€‚</li><li>'distance'ï¼šæœ¬èŠ‚ç‚¹çš„æ‰€æœ‰é‚»å±…èŠ‚ç‚¹çš„æŠ•ç¥¨æƒé‡ä¸è·ç¦»æˆåæ¯”ã€‚</li><li>[callable]ï¼šä¸€ä¸ªå¯è°ƒç”¨å¯¹è±¡ã€‚å®ƒä¼ å…¥è·ç¦»çš„æ•°ç»„ï¼Œè¿”å›åŒæ ·å½¢çŠ¶çš„æƒé‡æ•°ç»„ã€‚</li></ul></li><li>algorithmï¼šä¸€ä¸ªå­—ç¬¦ä¸²ï¼ŒæŒ‡å®šè®¡ç®—æœ€è¿‘é‚»çš„ç®—æ³•ã€‚<ul><li>'ball_tree'ï¼šä½¿ç”¨BallTreeç®—æ³•</li><li>'kd_tree'ï¼šä½¿ç”¨KDTreeç®—æ³•</li><li>'brute'ï¼šä½¿ç”¨æš´åŠ›æœç´¢æ³•</li><li>'auto'ï¼šè‡ªåŠ¨å†³å®šæœ€åˆé€‚çš„ç®—æ³•</li></ul></li><li>leaf_sizeï¼šä¸€ä¸ªæ•´æ•°ï¼ŒæŒ‡å®šBallTreeæˆ–è€…KDTreeå¶èŠ‚ç‚¹è§„æ¨¡ã€‚å®ƒå½±å“æ ‘çš„æ„å»ºå’ŒæŸ¥è¯¢é€Ÿåº¦ã€‚</li><li>metricï¼šä¸€ä¸ªå­—ç¬¦ä¸²ï¼ŒæŒ‡å®šè·ç¦»åº¦é‡ã€‚é»˜è®¤ä¸º'minkowski'è·ç¦»ã€‚</li><li>pï¼šæ•´æ•°å€¼ï¼ŒæŒ‡å®šåœ¨'Minkowski'åº¦é‡ä¸Šçš„æŒ‡æ•°ã€‚å¦‚æœp=1ï¼Œå¯¹åº”æ›¼å“ˆé¡¿è·ç¦»ï¼›å¦‚æœp=2ï¼Œå¯¹åº”æ¬§æ‹‰è·ç¦»ã€‚</li><li>n_jobsï¼šå¹¶è¡Œæ€§ã€‚é»˜è®¤ä¸º-1ï¼Œè¡¨ç¤ºæ´¾å‘ä»»åŠ¡åˆ°æ‰€æœ‰è®¡ç®—æœºçš„CPUä¸Šã€‚</li></ul><p>æ–¹æ³•ï¼š</p><ul><li>fit(X, y): è®­ç»ƒæ¨¡å‹</li><li>predict(X): ç”¨æ¨¡å‹è¿›è¡Œé¢„æµ‹ï¼Œè¿”å›å¾…é¢„æµ‹æ ·æœ¬çš„æ ‡è®°</li><li>score(X, y): è¿”å›é¢„æµ‹æ€§èƒ½å¾—åˆ†<ul><li>è®¾é¢„æµ‹é›†ä¸º<span class="math inline">\(T_{test}\)</span>ï¼ŒçœŸå®å€¼ä¸º<span class="math inline">\(y_i\)</span>ï¼ŒçœŸå®å€¼çš„å‡å€¼ä¸º<span class="math inline">\(\overline{y}\)</span>ï¼Œé¢„æµ‹å€¼ä¸º<span class="math inline">\(\hat{y}_i\)</span>ï¼Œåˆ™ï¼š<span class="math display">\[score=1-\frac{\sum_{T_{test}}(y_i-\hat{y}_i)^2}{(y_i-\overline{y})^2}\]</span><ul><li>scoreä¸è¶…è¿‡1ï¼Œä½†æ˜¯å¯èƒ½ä¸ºè´Ÿå€¼ï¼ˆé¢„æµ‹æ•ˆæœå¤ªå·®ï¼‰ã€‚</li><li>scoreè¶Šå¤§ï¼Œé¢„æµ‹æ€§èƒ½è¶Šå¥½ã€‚</li></ul></li></ul></li><li>kneighbors([X, n_neighbors, return_distance]): è¿”å›æ ·æœ¬ç‚¹çš„<span class="math inline">\(k\)</span>è¿‘é‚»ç‚¹ã€‚å¦‚æœ<code>return_distance=True</code>ï¼ŒåŒæ—¶è¿˜è¿”å›åˆ°è¿™äº›è¿‘é‚»ç‚¹çš„è·ç¦»ã€‚</li><li>kneighbors_graph([X, n_neighbors, mode]): è¿”å›æ ·æœ¬ç‚¹çš„è¿æ¥å›¾</li></ul><p>å…¶å‚æ•°æ„ä¹‰ä»¥åŠå®ä¾‹æ–¹æ³•ä¸KNeighborsClassifierå‡ ä¹å®Œå…¨ç›¸åŒã€‚ä¸¤è€…åŒºåˆ«åœ¨äºå›å½’åˆ†æå’Œåˆ†æå†³ç­–çš„ä¸åŒï¼š</p><ul><li>KNeighborsClassifierå°†å¾…é¢„æµ‹æ ·æœ¬ç‚¹æœ€è¿‘é‚»çš„<span class="math inline">\(k\)</span>ä¸ªè®­ç»ƒæ ·æœ¬ç‚¹ä¸­å‡ºç°æ¬¡æ•°æœ€å¤šçš„åˆ†ç±»ä½œä¸ºå¾…é¢„æµ‹æ ·æœ¬ç‚¹çš„åˆ†ç±»ã€‚</li><li>KNeighborsRegressorå°†å¾…é¢„æµ‹æ ·æœ¬ç‚¹æœ€è¿‘é‚»çš„<span class="math inline">\(k\)</span>ä¸ªè®­ç»ƒæ ·æœ¬ç‚¹çš„å¹³å‡å€¼ä½œä¸ºå¾…é¢„æµ‹æ ·æœ¬ç‚¹çš„å€¼ã€‚</li></ul><p>é¦–å…ˆä½¿ç”¨KNeighborsRegressorï¼š</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">def demo_KNeighborsRegressor(*data):</span><br><span class="line">    X_train, X_test, y_train, y_test = data</span><br><span class="line">    regr = neighbors.KNeighborsRegressor()</span><br><span class="line">    regr.fit(X_train, y_train)</span><br><span class="line">    print(&quot;Training score: %f&quot; % regr.score(X_train, y_train))</span><br><span class="line">    print(&quot;Testing score: %f&quot; % regr.score(X_test, y_test))</span><br></pre></td></tr></table></figure><p>è°ƒç”¨å‡½æ•°ï¼š</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">X_train, X_test, y_train, y_test = create_regression_data(1000)</span><br><span class="line">demo_KNeighborsRegressor(X_train, X_test, y_train, y_test)</span><br></pre></td></tr></table></figure><p>è¿™é‡Œæˆ‘ä»¬ç”Ÿæˆäº†1000ä¸ªæ ·æœ¬æ•°æ®ï¼Œç»“æœå¦‚ä¸‹ï¼š</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Training score: 0.977765</span><br><span class="line">Testing score: 0.958196</span><br></pre></td></tr></table></figure><p>ç„¶åè€ƒå¯Ÿ<span class="math inline">\(k\)</span>å€¼ä»¥åŠæŠ•ç¥¨ç­–ç•¥å¯¹é¢„æµ‹æ€§èƒ½çš„å½±å“ï¼š</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">def demo_KNeighborsRegressor_k_w(*data):</span><br><span class="line">    X_train, X_test, y_train, y_test = data</span><br><span class="line">    Ks = np.linspace(1, y_train.size, num=100, endpoint=False, dtype=&apos;int&apos;)</span><br><span class="line">    weights = [&apos;uniform&apos;, &apos;distance&apos;]</span><br><span class="line">    fig = plt.figure()</span><br><span class="line">    ax = fig.add_subplot(1, 1, 1)</span><br><span class="line">    for weight in weights:</span><br><span class="line">        training_scores = []</span><br><span class="line">        testing_scores = []</span><br><span class="line">        for K in Ks:</span><br><span class="line">            regr = neighbors.KNeighborsRegressor(weights=weight, n_neighbors=K)</span><br><span class="line">            regr.fit(X_train, y_train)</span><br><span class="line">            training_scores.append(regr.score(X_train, y_train))</span><br><span class="line">            testing_scores.append(regr.score(X_test, y_test))</span><br><span class="line">        ax.plot(Ks, testing_scores, label=&quot;testing score: weight=%s&quot; % weight)</span><br><span class="line">        ax.plot(Ks, training_scores, label=&quot;training score: weight=%s&quot; % weight)</span><br><span class="line">    ax.legend(loc=&apos;best&apos;)</span><br><span class="line">    ax.set_xlabel(&quot;K&quot;)</span><br><span class="line">    ax.set_ylabel(&quot;score&quot;)</span><br><span class="line">    ax.set_ylim(0, 1.05)</span><br><span class="line">    ax.set_title(&quot;KNeighborsRegressor&quot;)</span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure><p>ç»“æœå¦‚ä¸‹ï¼Œå…¶è®¨è®ºä¸KNeighborsClassifierç›¸åŒã€‚</p><p><img src="/images/MachineLearning/KNearestNeighbor/20190728_ML_KNeighborsRegressor_K_W.png"></p><p>ç„¶åè€ƒå¯Ÿ<span class="math inline">\(p\)</span>å€¼ï¼ˆè·ç¦»å‡½æ•°çš„å½¢å¼ï¼‰å¯¹äºé¢„æµ‹æ€§èƒ½çš„å½±å“ï¼š</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">def demo_KNeighborsRegressor_k_p(*data):</span><br><span class="line">    X_train, X_test, y_train, y_test = data</span><br><span class="line">    Ks = np.linspace(1, y_train.size, endpoint=False, dtype=&apos;int&apos;)</span><br><span class="line">    Ps = [1, 2, 10]</span><br><span class="line">    fig = plt.figure()</span><br><span class="line">    ax = fig.add_subplot(1, 1, 1)</span><br><span class="line">    for P in Ps:</span><br><span class="line">        training_scores = []</span><br><span class="line">        testing_scores = []</span><br><span class="line">        for K in Ks:</span><br><span class="line">            regr = neighbors.KNeighborsRegressor(p=P, n_neighbors=K)</span><br><span class="line">            regr.fit(X_train, y_train)</span><br><span class="line">            training_scores.append(regr.score(X_train, y_train))</span><br><span class="line">            testing_scores.append(regr.score(X_test, y_test))</span><br><span class="line">        ax.plot(Ks, testing_scores, label=&quot;testing score: p=%d&quot; % P)</span><br><span class="line">        ax.plot(Ks, training_scores, label=&quot;training score: p=%d&quot; % P)</span><br><span class="line">    ax.legend(loc=&apos;best&apos;)</span><br><span class="line">    ax.set_xlabel(&quot;K&quot;)</span><br><span class="line">    ax.set_ylabel(&quot;score&quot;)</span><br><span class="line">    ax.set_ylim(0, 1.05)</span><br><span class="line">    ax.set_title(&quot;KNeighborsRegressor&quot;)</span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure><p>ç»“æœå¦‚ä¸‹ï¼Œå…¶è®¨è®ºä¸KNeighborsClassifierç›¸åŒã€‚</p><p><img src="/images/MachineLearning/KNearestNeighbor/20190728_ML_KNeighborsRegressor_K_P.png"></p>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;æ¦‚è¿°&quot;&gt;æ¦‚è¿°&lt;/h1&gt;
&lt;p&gt;kè¿‘é‚»æ³•(k-Nearest Neighbor, kNN)æ˜¯æœºå™¨å­¦ä¹ æ‰€æœ‰ç®—æ³•ä¸­ç†è®ºæœ€ç®€å•ï¼Œæœ€å¥½ç†è§£çš„ç®—æ³•ã€‚å®ƒæ˜¯ä¸€ç§åŸºæœ¬çš„åˆ†ç±»ä¸å›å½’æ–¹æ³•ï¼Œå®ƒçš„è¾“å…¥ä¸ºå®ä¾‹çš„ç‰¹å¾å‘é‡ï¼Œé€šè¿‡è®¡ç®—æ–°æ•°æ®ä¸è®­ç»ƒæ•°æ®ç‰¹å¾å€¼ä¹‹é—´çš„è·ç¦»ï¼Œç„¶åé€‰å–&lt;span class=&quot;math inline&quot;&gt;\(K(Kâ‰¥1)\)&lt;/span&gt;ä¸ªè·ç¦»æœ€è¿‘çš„é‚»å±…è¿›è¡Œåˆ†ç±»åˆ¤æ–­(æŠ•ç¥¨æ³•)æˆ–è€…å›å½’ã€‚å¦‚æœ&lt;span class=&quot;math inline&quot;&gt;\(K=1\)&lt;/span&gt;ï¼Œé‚£ä¹ˆæ–°æ•°æ®è¢«ç®€å•åœ°åˆ†é…ç»™å…¶è¿‘é‚»çš„ç±»ã€‚&lt;/p&gt;
&lt;p&gt;å¯¹äºåˆ†ç±»é—®é¢˜ï¼šè¾“å‡ºä¸ºå®ä¾‹çš„ç±»åˆ«ã€‚åˆ†ç±»æ—¶ï¼Œå¯¹äºæ–°çš„å®ä¾‹ï¼Œæ ¹æ®å…¶&lt;span class=&quot;math inline&quot;&gt;\(k\)&lt;/span&gt;ä¸ªæœ€è¿‘é‚»çš„è®­ç»ƒå®ä¾‹çš„ç±»åˆ«ï¼Œé€šè¿‡å¤šæ•°è¡¨å†³ç­‰æ–¹å¼è¿›è¡Œé¢„æµ‹ã€‚&lt;/p&gt;
&lt;p&gt;å¯¹äºå›å½’é—®é¢˜ï¼šè¾“å‡ºä¸ºå®ä¾‹çš„å€¼ã€‚å›å½’æ—¶ï¼Œå¯¹äºæ–°çš„å®ä¾‹ï¼Œå–å…¶&lt;span class=&quot;math inline&quot;&gt;\(k\)&lt;/span&gt;ä¸ªæœ€è¿‘é‚»çš„è®­ç»ƒå®ä¾‹çš„å¹³å‡å€¼ä¸ºé¢„æµ‹å€¼ã€‚&lt;/p&gt;
&lt;p&gt;kè¿‘é‚»æ³•åˆ†ç±»çš„ç›´è§‚ç†è§£ï¼šç»™å®šä¸€ä¸ªè®­ç»ƒæ•°æ®é›†ï¼Œå¯¹äºæ–°çš„è¾“å…¥å®ä¾‹ï¼Œåœ¨è®­ç»ƒé›†ä¸­æ‰¾åˆ°ä¸è¯¥å®ä¾‹æœ€é‚»è¿‘çš„&lt;span class=&quot;math inline&quot;&gt;\(k\)&lt;/span&gt;ä¸ªå®ä¾‹ã€‚è¿™&lt;span class=&quot;math inline&quot;&gt;\(k\)&lt;/span&gt;ä¸ªå®ä¾‹çš„å¤šæ•°å±äºæŸä¸ªç±»åˆ«ï¼Œåˆ™è¯¥è¾“å…¥å®ä¾‹å°±åˆ’åˆ†ä¸ºè¿™ä¸ªç±»åˆ«ã€‚&lt;/p&gt;
&lt;p&gt;kè¿‘é‚»æ³•ä¸å…·æœ‰æ˜¾å¼çš„å­¦ä¹ è¿‡ç¨‹ï¼Œå®ƒæ˜¯ç›´æ¥é¢„æµ‹ã€‚å®é™…ä¸Šå®ƒæ˜¯åˆ©ç”¨è®­ç»ƒæ•°æ®é›†å¯¹ç‰¹å¾å‘é‡ç©ºé—´è¿›è¡Œåˆ’åˆ†ï¼Œå¹¶ä¸”ä½œä¸ºå…¶åˆ†ç±»çš„â€œæ¨¡å‹â€ã€‚&lt;/p&gt;
    
    </summary>
    
      <category term="Machine Learning" scheme="http://yoursite.com/categories/Machine-Learning/"/>
    
    
      <category term="machine learning" scheme="http://yoursite.com/tags/machine-learning/"/>
    
      <category term="python" scheme="http://yoursite.com/tags/python/"/>
    
      <category term="sklearn" scheme="http://yoursite.com/tags/sklearn/"/>
    
      <category term="knn" scheme="http://yoursite.com/tags/knn/"/>
    
  </entry>
  
  <entry>
    <title>MachineLearning Chapter-3 Bayes Classifier</title>
    <link href="http://yoursite.com/2019/07/27/MachineLearning-Chapter-3-Bayes-Classifier/"/>
    <id>http://yoursite.com/2019/07/27/MachineLearning-Chapter-3-Bayes-Classifier/</id>
    <published>2019-07-27T04:20:01.000Z</published>
    <updated>2019-07-28T06:25:37.726Z</updated>
    
    <content type="html"><![CDATA[<h1 id="æ¦‚è¿°">æ¦‚è¿°</h1><p>è´å¶æ–¯åˆ†ç±»æ˜¯ä¸€ç§åˆ†ç±»ç®—æ³•çš„æ€»ç§°ï¼Œè¿™ç§ç®—æ³•å‡ä»¥è´å¶æ–¯å®šç†ä¸ºåŸºç¡€ï¼Œæ‰€ä»¥ç»Ÿç§°ä¸ºè´å¶æ–¯åˆ†ç±»ã€‚</p><p>è´å¶æ–¯åˆ†ç±»å™¨çš„åˆ†ç±»åŸç†æ˜¯é€šè¿‡æŸå¯¹è±¡çš„å…ˆéªŒæ¦‚ç‡ï¼Œåˆ©ç”¨è´å¶æ–¯å…¬å¼è®¡ç®—å‡ºå…¶åéªŒæ¦‚ç‡ï¼Œå³è¯¥å¯¹è±¡å±äºæŸä¸€ç±»çš„æ¦‚ç‡ï¼Œé€‰æ‹©å…·æœ‰æœ€å¤§åéªŒæ¦‚ç‡çš„ç±»ä½œä¸ºè¯¥å¯¹è±¡æ‰€å±çš„ç±»ã€‚</p><p>è´å¶æ–¯åˆ†ç±»å™¨çš„ä¸»è¦ç‰¹ç‚¹ï¼š</p><ul><li>å±æ€§å¯ä»¥ç¦»æ•£ï¼Œä¹Ÿå¯ä»¥è¿ç»­</li><li>æ•°å­¦åŸºç¡€æ‰å®ï¼Œåˆ†ç±»æ•ˆç‡ç¨³å®š</li><li>å¯¹ç¼ºå¤±å’Œå™ªå£°æ•°æ®ä¸å¤ªæ•æ„Ÿ</li><li>å±æ€§å¦‚æœä¸ç›¸å…³ï¼Œåˆ†ç±»æ•ˆæœå¾ˆå¥½ï¼›å¦‚æœç›¸å…³ï¼Œåˆ™ä¸ä½äºå†³ç­–æ ‘</li></ul><a id="more"></a><h1 id="ç®—æ³•">ç®—æ³•</h1><h2 id="è´å¶æ–¯å®šç†">è´å¶æ–¯å®šç†</h2><p>è´å¶æ–¯å®šç†æ˜¯ç”¨æ•°å­¦çš„æ–¹æ³•æ¥è§£é‡Šç”Ÿæ´»ä¸­å¤§å®¶éƒ½çŸ¥é“çš„å¸¸è¯†ï¼Œè€Œæœºå™¨å­¦ä¹ ä½¿ç”¨çš„å„ç§ç®—æ³•ä¸­ï¼Œæœ€å¸¸è§çš„å°±æ˜¯è´å¶æ–¯å®šç†ã€‚</p><p>å…ˆéªŒæ¦‚ç‡æ˜¯æ ¹æ®ä»¥å¾€ç»éªŒå’Œåˆ†æå¾—åˆ°çš„æ¦‚ç‡ã€‚æ¯”å¦‚ï¼šä½ åœ¨å±±æ´é—¨å£ï¼Œè§‰å¾—å±±æ´ä¸­æœ‰ç†Šå‡ºç°çš„äº‹ä»¶ä¸º<span class="math inline">\(Y\)</span>ï¼Œç„¶åå¬åˆ°å±±æ´ä¸­ä¼ æ¥ä¸€é˜µç†Šå¼çš„äº‹ä»¶ä¸º<span class="math inline">\(X\)</span>ã€‚ä¸€å¼€å§‹ä½ ä»¥ä¸ºå±±æ´ä¸­æœ‰ç†Šçš„æ¦‚ç‡ä¸º<span class="math inline">\(P(Y)\)</span>ï¼Œå¬åˆ°ç†Šå¼ä¹‹åè®¤ä¸ºæœ‰ç†Šçš„æ¦‚ç‡ä¸º<span class="math inline">\(P(Y/X)\)</span>ã€‚å¾ˆæ˜æ˜¾<span class="math inline">\(P(Y/X)&gt;P(Y)\)</span>ã€‚è¿™é‡Œï¼š</p><ul><li><span class="math inline">\(P(Y)\)</span>ä¸ºå…ˆéªŒæ¦‚ç‡ï¼Œæ˜¯æ ¹æ®ä»¥å¾€çš„æ•°æ®åˆ†ææˆ–è€…ç»éªŒå¾—åˆ°çš„æ¦‚ç‡</li><li><span class="math inline">\(P(Y/X)\)</span>ä¸ºåéªŒæ¦‚ç‡ï¼Œæ˜¯å¾—åˆ°æœ¬æ¬¡è¯•éªŒçš„ä¿¡æ¯ä»è€Œé‡æ–°ä¿®æ­£çš„æ¦‚ç‡</li></ul><p>è®¾<span class="math inline">\(S\)</span>ä¸ºè¯•éªŒ<span class="math inline">\(E\)</span>çš„æ ·æœ¬ç©ºé—´ã€‚<span class="math inline">\(B_1,B_2,â€¦,B_n\)</span>ä¸º<span class="math inline">\(E\)</span>çš„ä¸€ç»„äº‹ä»¶ã€‚è‹¥ï¼š</p><ul><li><span class="math inline">\(B_i\cap B_j=\phi ,iâ‰ j,i,j=1,2,â€¦,n\)</span></li><li><span class="math inline">\(B_1\cup B_2\cup â€¦\cup B_n=S\)</span></li></ul><p>åˆ™ç§°<span class="math inline">\(B_1,B_2,â€¦,B_n\)</span>ä¸ºæ ·æœ¬ç©ºé—´<span class="math inline">\(S\)</span>çš„ä¸€ä¸ªåˆ’åˆ†ã€‚å¦‚æœ<span class="math inline">\(B_1,B_2,â€¦,B_n\)</span>ä¸ºæ ·æœ¬ç©ºé—´<span class="math inline">\(S\)</span>çš„ä¸€ä¸ªåˆ’åˆ†ï¼Œåˆ™å¯¹äºæ¯æ¬¡è¯•éªŒï¼Œäº‹ä»¶<span class="math inline">\(B_1,B_2,â€¦,B_n\)</span>ä¸­æœ‰ä¸”ä»…æœ‰ä¸€ä¸ªäº‹ä»¶å‘ç”Ÿã€‚</p><p>å…¨æ¦‚ç‡å…¬å¼ï¼šè®¾è¯•éªŒ<span class="math inline">\(E\)</span>çš„æ ·æœ¬ç©ºé—´ä¸º<span class="math inline">\(S\)</span>ï¼Œ<span class="math inline">\(A\)</span>ä¸º<span class="math inline">\(E\)</span>çš„äº‹ä»¶ï¼Œ<span class="math inline">\(B_1,B_2,â€¦,B_n\)</span>ä¸ºæ ·æœ¬ç©ºé—´<span class="math inline">\(S\)</span>çš„ä¸€ä¸ªåˆ’åˆ†ï¼Œä¸”<span class="math inline">\(P(B_i)â‰¥0(i=1,2,â€¦,n)\)</span>ï¼Œåˆ™æœ‰ï¼š</p><p><span class="math display">\[P(A)=P(A/B_1)P(B_1)+P(A/B_2)P(B_2)+â€¦+P(A/B_n)P(B_n)=\sum_{j=1}^nP(A/B_j)P(B_j)\]</span></p><p>è´å¶æ–¯å®šç†ï¼šè®¾è¯•éªŒ<span class="math inline">\(E\)</span>çš„æ ·æœ¬ç©ºé—´ä¸º<span class="math inline">\(S\)</span>ï¼Œ<span class="math inline">\(A\)</span>ä¸º<span class="math inline">\(E\)</span>çš„äº‹ä»¶ï¼Œ<span class="math inline">\(B_1,B_2,â€¦,B_n\)</span>ä¸ºæ ·æœ¬ç©ºé—´<span class="math inline">\(S\)</span>çš„ä¸€ä¸ªåˆ’åˆ†ï¼Œä¸”<span class="math inline">\(P(A)&gt;0\)</span>ï¼Œ<span class="math inline">\(P(B_i)â‰¥0(i=1,2,â€¦,n)\)</span>ï¼Œåˆ™æœ‰ï¼š</p><p><span class="math display">\[P(B_i/A)=\frac{P(A/B_i)P(B_i)}{\sum_{j=1}^nP(A/B_j)P(B_j)}\]</span></p><h2 id="æœ´ç´ è´å¶æ–¯æ³•">æœ´ç´ è´å¶æ–¯æ³•</h2><h3 id="åŸç†">åŸç†</h3><p>è®¾æ ·æœ¬<span class="math inline">\(\vec{x}=(x^{(1)},x^{(2)},â€¦,x^{(n)})^T \in ğ’³ \subseteq R^n\)</span>ï¼Œè®¾æ ‡è®°<span class="math inline">\(y\in ğ’´=\{c_1,c_2,â€¦,c_K\}\)</span>ã€‚ä»¤<span class="math inline">\(X\)</span>ä¸ºğ’³ä¸Šçš„éšæœºå‘é‡ï¼Œ<span class="math inline">\(Y\)</span>ä¸ºğ’´ä¸Šçš„éšæœºå˜é‡ï¼Œ<span class="math inline">\(P(X,Y)\)</span>ä¸º<span class="math inline">\(X\)</span>å’Œ<span class="math inline">\(Y\)</span>çš„è”åˆæ¦‚ç‡åˆ†å¸ƒã€‚å‡å®šè®­ç»ƒæ•°æ®é›†<span class="math inline">\(T=\{(\vec{x}_1,y_1),(\vec{x}_2,y_2),â€¦,(\vec{x}_N,y_N)\}\)</span>ç”±<span class="math inline">\(P(X,Y)\)</span>ç‹¬ç«‹åŒåˆ†å¸ƒäº§ç”Ÿï¼Œé‚£ä¹ˆæœ´ç´ è´å¶æ–¯æ³•å¯ä»è®­ç»ƒæ•°æ®é›†ä¸­å­¦ä¹ è”åˆæ¦‚ç‡åˆ†å¸ƒ<span class="math inline">\(P(X,Y)\)</span>ï¼Œä¹Ÿå°±æ˜¯å­¦ä¹ ä¸‹åˆ—æ¦‚ç‡åˆ†å¸ƒï¼š</p><ul><li>å…ˆéªŒæ¦‚ç‡åˆ†å¸ƒï¼š<span class="math inline">\(P(Y=c_k),k=1,2,â€¦,K\)</span></li><li>æ¡ä»¶æ¦‚ç‡åˆ†å¸ƒï¼š<span class="math inline">\(P(X=\vec{x}/Y=c_k),k=1,2,â€¦,K\)</span></li></ul><p>æœ´ç´ è´å¶æ–¯æ³•å‡è®¾ï¼šåœ¨åˆ†ç±»ç¡®å®šçš„æ¡ä»¶ä¸‹ï¼Œç”¨äºåˆ†ç±»çš„ç‰¹å¾æ˜¯æ¡ä»¶ç‹¬ç«‹çš„ã€‚å³ï¼š</p><p><span class="math display">\[P(X=\vec{x}/Y=c_k)=P(X^{(1)}=x^{(1)},X^{(2)}=x^{(2)},â€¦,X^{(n)}=x^{(n)}/Y=c_k) \\ =\prod_{j=1}^nP(X^{(j)}=x^{(j)}/Y=c_k),k=1,2,â€¦,K\]</span></p><p>æ ¹æ®è´å¶æ–¯å®šç†ï¼š</p><p><span class="math display">\[P(Y=c_k/X=\vec{x})=\frac{P(X=\vec{x}/Y=c_k)P(Y=c_k)}{\sum_{j=1}^KP(X=\vec{x}/Y=c_j)P(Y=c_j)}\]</span></p><p>è€ƒè™‘åˆ†ç±»ç‰¹å¾çš„æ¡ä»¶ç‹¬ç«‹å‡è®¾æœ‰ï¼š</p><p><span class="math display">\[P(Y=c_k/X=\vec{x})=\frac{P(Y=c_k)\prod_{i=1}^nP(X^{(i)}=x^{(i)}/Y=c_k)}{\sum_{j=1}^KP(X=\vec{x}/Y=c_j)P(Y=c_j)},k=1,2,â€¦,K\]</span></p><p>äºæ˜¯æœ´ç´ è´å¶æ–¯åˆ†ç±»å™¨è¡¨ç¤ºä¸ºï¼š</p><p><span class="math display">\[y=f(\vec{x})=\arg \max_{c_k}\frac{P(Y=c_k)\prod_{i=1}^nP(X^{(i)}=x^{(i)}/Y=c_k)}{\sum_{j=1}^KP(X=\vec{x}/Y=c_j)P(Y=c_j)}\]</span></p><p>ç”±äºå¯¹æ‰€æœ‰çš„<span class="math inline">\(c_k,k=1,2,â€¦,K\)</span>ï¼Œä¸Šå¼çš„åˆ†æ¯éƒ½ç›¸åŒï¼Œå› æ­¤ä¸Šå¼å¯é‡å†™ä¸ºï¼š</p><p><span class="math display">\[y=f(\vec{x})=\arg \max_{c_k}P(Y=c_k)\prod_{i=1}^nP(X^{(i)}=x^{(i)}/Y=c_k)\]</span></p><h3 id="æœ´ç´ è´å¶æ–¯æ³•çš„å­¦ä¹ ">æœ´ç´ è´å¶æ–¯æ³•çš„å­¦ä¹ </h3><p>åœ¨æœ´ç´ è´å¶æ–¯æ³•ä¸­ï¼Œè¦å­¦ä¹ çš„å‚æ•°å°±æ˜¯ä»¥ä¸‹ä¸¤ç§æ¦‚ç‡ï¼š</p><ul><li>å…ˆéªŒæ¦‚ç‡<span class="math inline">\(P(Y=c_k)\)</span></li><li>æ¡ä»¶æ¦‚ç‡<span class="math inline">\(P(X^{(j)}=x^{(j)}/Y=c_k)\)</span></li></ul><p>é€šå¸¸é‡‡ç”¨æå¤§ä¼¼ç„¶ä¼°è®¡è¿™ä¸¤ç§æ¦‚ç‡ã€‚</p><ul><li>å…ˆéªŒæ¦‚ç‡<span class="math inline">\(P(Y=c_k)\)</span>çš„æå¤§ä¼¼ç„¶ä¼°è®¡ä¸ºï¼š<span class="math display">\[P(Y=c_k)=\frac{1}{N}\sum_{i=1}^NI(y_i=c_k),k=1,2,â€¦,K\]</span></li><li>æ¡ä»¶æ¦‚ç‡<span class="math inline">\(P(X^{(j)}=a_{jl}/Y=c_k)\)</span>çš„æå¤§ä¼¼ç„¶ä¼°è®¡ä¸ºï¼š<span class="math display">\[P(X^{(j)}=a_{jl}/Y=c_k)=\frac{\sum_{i=1}^NI(x_i^{(j)}=a_{jl},y_i=c_k)}{\sum_{i=1}^NI(y_i=c_k)}\\j=1,2,â€¦,n ;l=1,2,â€¦,s_j ; k=1,2,â€¦,K\]</span>å…¶ä¸­ï¼Œ<span class="math inline">\(a_{j1},a_{j2},â€¦,a_{js_j}\)</span>ä¸ºç¬¬<span class="math inline">\(j\)</span>ä¸ªç‰¹å¾<span class="math inline">\(x^{(j)}\)</span>å¯èƒ½çš„å–å€¼ã€‚</li></ul><h3 id="æœ´ç´ è´å¶æ–¯æ³•ç®—æ³•">æœ´ç´ è´å¶æ–¯æ³•ç®—æ³•</h3><p>è¾“å…¥ï¼š</p><ul><li>è®­ç»ƒé›†<span class="math inline">\(T=\{(\vec{x}_1,y_1),(\vec{x}_2,y_2),â€¦,(\vec{x}_N,y_N)\}\)</span>, <span class="math inline">\(\vec{x}_i=(x^{(1)}_i,x^{(2)}_i,â€¦,x^{(n)}_i)^T\)</span>ï¼Œ<span class="math inline">\(x^{(j)}_i\)</span>ä¸ºç¬¬<span class="math inline">\(i\)</span>ä¸ªæ ·æœ¬çš„ç¬¬<span class="math inline">\(j\)</span>ä¸ªç‰¹å¾ï¼Œå…¶ä¸­<span class="math inline">\(x^{(j)}_i\in \{a_{j1},a_{j2},â€¦,a_{js_j}\}\)</span>ï¼Œ<span class="math inline">\(a_{jl}\)</span>ä¸ºç¬¬<span class="math inline">\(j\)</span>ä¸ªç‰¹å¾å¯èƒ½å–åˆ°çš„ç¬¬<span class="math inline">\(l\)</span>ä¸ªå€¼ï¼Œ<span class="math inline">\(j=1,2,â€¦,n\)</span>ï¼Œ<span class="math inline">\(l=1,2,â€¦,s_j\)</span>ï¼Œ<span class="math inline">\(y_i\in \{c_1,c_2,â€¦,c_K\}\)</span>ã€‚</li><li>å®ä¾‹<span class="math inline">\(\vec{x}\)</span></li></ul><p>è¾“å‡ºï¼šå®ä¾‹<span class="math inline">\(\vec{x}\)</span>çš„åˆ†ç±»</p><p>ç®—æ³•æ­¥éª¤ï¼š</p><ul><li>è®¡ç®—å…ˆéªŒæ¦‚ç‡çš„ä¼°è®¡å€¼ä»¥åŠæ¡ä»¶æ¦‚ç‡çš„ä¼°è®¡å€¼ï¼š<span class="math display">\[P(Y=c_k)=\frac{\sum_{i=1}^NI(y_i=c_k)}{N},k=1,2,â€¦,K \\ P(X^{(j)}=a_{jl}/Y=c_k)=\frac{\sum_{i=1}^NI(x_i^{(j)}=a_{jl},y_i=c_k)}{\sum_{i=1}^NI(y_i=c_k)} \\ j=1,2,â€¦,n; l=1,2,â€¦,s_j; k=1,2,â€¦,K\]</span></li><li>å¯¹äºç»™å®šçš„å®ä¾‹<span class="math inline">\(\vec{x}=(x^{(1)},x^{(2)},â€¦,x^{(n)})^T\)</span>ï¼Œè®¡ç®—ï¼š<span class="math display">\[P(Y=c_k)\prod_{j=1}^nP(X^{(j)}=x^{(j)}/Y=c_k),k=1,2,â€¦,K\]</span></li><li>è®¡ç®—å¹¶è¿”å›å®ä¾‹<span class="math inline">\(\vec{x}\)</span>çš„åˆ†ç±»<span class="math inline">\(y\)</span>ï¼š<span class="math display">\[y=\arg \max_{c_k}P(Y=c_k)\prod_{j=1}^nP(X^{(j)}=x^{(j)}/Y=c_k)\]</span></li></ul><h3 id="è´å¶æ–¯ä¼°è®¡">è´å¶æ–¯ä¼°è®¡</h3><p>è®¾ç¬¬<span class="math inline">\(j\)</span>ä¸ªç‰¹å¾<span class="math inline">\(x^{(j)}\)</span>å¯èƒ½çš„å–å€¼ä¸º<span class="math inline">\(a_{j1},a_{j2},â€¦,a_{js_j}\)</span>ï¼Œåˆ™æ¡ä»¶æ¦‚ç‡<span class="math inline">\(P(X^{(j)}=a_{jl}/Y=c_k)\)</span>çš„æå¤§ä¼¼ç„¶ä¼°è®¡ä¸ºï¼š</p><p><span class="math display">\[P(X^{(j)}=a_{jl}/Y=c_k)=\frac{\sum_{i=1}^NI(x_i^{(j)}=a_{jl},y_i=c_k)}{\sum_{i=1}^NI(y_i=c_k)} \\ j=1,2,â€¦,n; l=1,2,â€¦,s_j; k=1,2,â€¦,K\]</span></p><p>ç”¨æå¤§ä¼¼ç„¶ä¼°è®¡å¯èƒ½ä¼šå‡ºç°åˆ†æ¯<span class="math inline">\(\sum_{i=1}^NI(y_i=c_k)\)</span>ä¸º0çš„æƒ…å†µï¼Œæ­¤æ—¶å¯ä»¥é‡‡ç”¨è´å¶æ–¯ä¼°è®¡ï¼ˆæœ€å¤§åéªŒä¼°è®¡ï¼‰ï¼š</p><p><span class="math display">\[P_{\lambda}(X^{(j)}=a_{jl}/Y=c_k)=\frac{\sum_{i=1}^NI(x_i^{(j)}=a_{jl},y_i=c_k)+\lambda }{\sum_{i=1}^NI(y_i=c_k)+s_j\lambda } \\ j=1,2,â€¦,n; l=1,2,â€¦,s_j; k=1,2,â€¦,K\]</span></p><blockquote><p>å®ƒç­‰ä»·äºåœ¨<span class="math inline">\(X^{(j)}\)</span>çš„å„ä¸ªå–å€¼çš„é¢‘æ•°ä¸Šèµ‹äºˆä¸€ä¸ªæ­£æ•°<span class="math inline">\(\lambda\)</span></p></blockquote><p>å®ƒæ»¡è¶³æ¦‚ç‡åˆ†å¸ƒå‡½æ•°çš„æ¡ä»¶ï¼š</p><p><span class="math display">\[P_{\lambda}(X^{(j)}=a_{jl}/Y=c_k)&gt;0;l=1,2,â€¦,s_j;k=1,2,â€¦,K \\ \sum_{l=1}^{s_j}P_{\lambda}(X^{(j)}=a_{jl}/Y=c_k)=1 \]</span></p><p>æ­¤æ—¶<span class="math inline">\(P(Y=c_k)\)</span>çš„è´å¶æ–¯ä¼°è®¡è°ƒæ•´ä¸ºï¼š</p><p><span class="math display">\[P_{\lambda}(Y=c_k)=\frac{\sum_{i=1}^NI(y_i=c_k)+\lambda}{N+K\lambda}\]</span></p><ul><li>å½“<span class="math inline">\(\lambda =0\)</span>æ—¶ï¼Œä¸ºæå¤§ä¼¼ç„¶ä¼°è®¡</li><li>å½“<span class="math inline">\(\lambda =1\)</span>æ—¶ï¼Œä¸ºæ‹‰æ™®æ‹‰æ–¯å¹³æ»‘</li></ul><h1 id="pythonå®æˆ˜">Pythonå®æˆ˜</h1><p>åœ¨scikitä¸­æœ‰å¤šç§ä¸åŒçš„æœ´ç´ è´å¶æ–¯åˆ†ç±»å™¨ï¼Œå®ƒä»¬çš„åŒºåˆ«å°±åœ¨äºå‡è®¾äº†ä¸åŒçš„<span class="math inline">\(P(X^{(j)}/y=c_k)\)</span>åˆ†å¸ƒï¼Œä¸‹é¢ä»‹ç»ä¸‰ç§å¸¸ç”¨çš„æœ´ç´ è´å¶æ–¯åˆ†ç±»å™¨ï¼š</p><ul><li>GaussianNBæ˜¯é«˜æ–¯è´å¶æ–¯åˆ†ç±»å™¨ã€‚å®ƒå‡è®¾ç‰¹å¾çš„æ¡ä»¶æ¦‚ç‡åˆ†å¸ƒæ»¡è¶³é«˜æ–¯åˆ†å¸ƒï¼š<span class="math display">\[P(X^{(j)}/y=c_k)=\frac{1}{\sqrt{2\pi \sigma_k^2}}\exp (-\frac{(X^{(j)}-\mu_k)^2}{2\sigma_k^2})\]</span></li><li>MultinomialNBæ˜¯å¤šé¡¹å¼è´å¶æ–¯åˆ†ç±»å™¨ã€‚å®ƒå‡è®¾ç‰¹å¾çš„æ¡ä»¶æ¦‚ç‡åˆ†å¸ƒæ»¡è¶³å¤šé¡¹å¼åˆ†å¸ƒï¼š<span class="math display">\[P(X^{(j)}=a_{sj}/y=c_k)=\frac{N_{kj}+\alpha }{N_k+\alpha n}\]</span>å…¶ä¸­ï¼Œ<span class="math inline">\(a_{sj}\)</span>è¡¨ç¤ºç‰¹å¾<span class="math inline">\(X^{(j)}\)</span>çš„å–å€¼ï¼Œå…¶å–å€¼ä¸ªæ•°ä¸º<span class="math inline">\(s_j\)</span>ä¸ªï¼›<span class="math inline">\(N_k=\sum_{i=1}^NI(y_i=c_k)\)</span>ï¼Œè¡¨ç¤ºå±äºç±»åˆ«<span class="math inline">\(c_k\)</span>çš„æ ·æœ¬çš„æ•°é‡ï¼›<span class="math inline">\(N_{kj}=\sum_{i=1}^NI(y_i=c_k,X^{(j)}=a_{sj})\)</span>ï¼Œè¡¨ç¤ºå±äºç±»åˆ«<span class="math inline">\(c_k\)</span>ä¸”ç‰¹å¾<span class="math inline">\(X^{(j)}=a_{sj}\)</span>çš„æ ·æœ¬çš„æ•°é‡ã€‚<span class="math inline">\(\alpha\)</span>å°±æ˜¯å‰è¿°è´å¶æ–¯ä¼°è®¡ä¸­çš„<span class="math inline">\(\lambda\)</span>ã€‚</li><li>BernoulliNBæ˜¯ä¼¯åŠªåˆ©è´å¶æ–¯åˆ†ç±»å™¨ã€‚å®ƒå‡è®¾ç‰¹å¾çš„æ¡ä»¶æ¦‚ç‡åˆ†å¸ƒæ»¡è¶³äºŒé¡¹åˆ†å¸ƒï¼š<span class="math display">\[P(X^{(j)}/y=c_k)=pX^{(j)}+(1-p)(1-X^{(j)})\]</span>å…¶ä¸­ï¼Œè¦æ±‚ç‰¹å¾çš„å–å€¼ä¸º<span class="math inline">\(X^{(j)}\in \{0,1\}\)</span>ï¼Œä¸”<span class="math inline">\(P(X^{(j)}=1/y=c_k)=p\)</span>ã€‚</li></ul><p>ä¸å¤šé¡¹å¼æ¨¡å‹ä¸€æ ·ï¼Œä¼¯åŠªåˆ©æ¨¡å‹é€‚ç”¨äºç¦»æ•£ç‰¹å¾çš„æƒ…å†µï¼Œæ‰€ä¸åŒçš„æ˜¯ï¼Œä¼¯åŠªåˆ©æ¨¡å‹ä¸­æ¯ä¸ªç‰¹å¾çš„å–å€¼åªèƒ½æ˜¯1å’Œ0ã€‚</p><p>é¦–å…ˆå¯¼å…¥åŒ…ï¼š</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">from sklearn import datasets, model_selection, naive_bayes</span><br><span class="line">import numpy as np</span><br><span class="line">import matplotlib.pyplot as plt</span><br></pre></td></tr></table></figure><p>è¿™é‡Œä½¿ç”¨çš„æ˜¯scikit-learnè‡ªå¸¦çš„æ‰‹å†™è¯†åˆ«æ•°æ®é›†Digit Datasetã€‚è¯¥æ•°æ®é›†ç”±1791å¼ æ ·æœ¬å›¾ç‰‡ç»„æˆï¼Œæ¯å¼ å›¾ç‰‡éƒ½æ˜¯ä¸€ä¸ª<span class="math inline">\(8\times 8\)</span>å¤§å°çš„æ‰‹å†™æ•°å­—ä½å›¾ã€‚ä¸ºäº†ä¾¿äºå¤„ç†ï¼Œscikit-learnå°†æ ·æœ¬å›¾ç‰‡è½¬æ¢æˆ64ç»´çš„å‘é‡ã€‚æˆ‘ä»¬é€šè¿‡ä¸‹é¢çš„å‡½æ•°æ¥è§‚å¯ŸDigit Datasetæ•°æ®é›†ï¼š</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">def show_digits():</span><br><span class="line">    digits = datasets.load_digits()</span><br><span class="line">    fig = plt.figure()</span><br><span class="line">    print(&quot;vector from images 0:&quot;, digits.data[0])</span><br><span class="line">    for i in range(25):</span><br><span class="line">        ax = fig.add_subplot(5, 5, i+1)</span><br><span class="line">        ax.imshow(digits.images[i], cmap=plt.cm.gray_r, interpolation=&apos;nearest&apos;)</span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure><p>è°ƒç”¨è¯¥å‡½æ•°ï¼Œç»“æœå¦‚ä¸‹ï¼š</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">vector from images 0: </span><br><span class="line">[ 0.  0.  5. 13.  9.  1.  0.  0.  0.  0. 13. 15. 10. 15.  5.  0.  0.  3.</span><br><span class="line">  1.  2.  0. 11.  8.  0.  0.  4. 12.  0.  0.  8.  8.  0.  0.  5.  8.  0.</span><br><span class="line">  1.  9.  8.  0.  0.  4. 11.  0.  1. 12.  7.  0.  0.  2. 14.  5. 10. 12.</span><br><span class="line">  2.  0.  0.  0.  6. 13. 10.  0.  0.  0.]</span><br></pre></td></tr></table></figure><p><img src="/images/MachineLearning/BayesClassifier/20190727_ML_Digit.png"></p><p>åŠ è½½æ•°æ®é›†ï¼š</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">def load_data():</span><br><span class="line">    digits = datasets.load_digits()</span><br><span class="line">    return model_selection.train_test_split(digits.data, digits.target, test_size=0.25, random_state=0)</span><br></pre></td></tr></table></figure><h2 id="é«˜æ–¯è´å¶æ–¯åˆ†ç±»å™¨gaussiannb">é«˜æ–¯è´å¶æ–¯åˆ†ç±»å™¨(GaussianNB)</h2><p>å…¶åŸå‹ä¸ºï¼š<code>class sklearn.native_bayes.GaussianNB</code>ã€‚GaussianNBæ²¡æœ‰å‚æ•°ï¼Œå› æ­¤ä¸éœ€è¦è°ƒå‚ã€‚</p><p>å±æ€§ï¼š</p><ul><li>class_prior_: ä¸€ä¸ªæ•°ç»„ï¼Œå½¢çŠ¶ä¸º(n_classes,)ï¼Œæ˜¯æ¯ä¸ªç±»åˆ«çš„æ¦‚ç‡<span class="math inline">\(P(y=c_k)\)</span></li><li>class_count_: ä¸€ä¸ªæ•°ç»„ï¼Œå½¢çŠ¶ä¸º(n_classes,)ï¼Œæ˜¯æ¯ä¸ªç±»åˆ«åŒ…å«çš„è®­ç»ƒæ ·æœ¬æ•°é‡</li><li>theta_: ä¸€ä¸ªæ•°ç»„ï¼Œå½¢çŠ¶ä¸º(n_classes, n_features)ï¼Œæ˜¯æ¯ä¸ªç±»åˆ«ä¸Šæ¯ä¸ªç‰¹å¾å€¼çš„å‡å€¼<span class="math inline">\(\mu_k\)</span></li><li>sigma_: ä¸€ä¸ªæ•°ç»„ï¼Œå½¢çŠ¶ä¸º(n_classes, n_features)ï¼Œæ˜¯æ¯ä¸ªç±»åˆ«ä¸Šæ¯ä¸ªç‰¹å¾çš„æ ‡å‡†å·®<span class="math inline">\(\sigma_k\)</span></li></ul><p>æ–¹æ³•ï¼š</p><ul><li>fit(X, y[, sample_weight]): è®­ç»ƒæ¨¡å‹</li><li>partial_fit(X, y[, classes, sample_weight]): è¿½åŠ è®­ç»ƒæ¨¡å‹ã€‚è¯¥æ–¹æ³•ä¸»è¦ç”¨äºå¤§è§„æ¨¡æ•°æ®é›†çš„è®­ç»ƒã€‚æ­¤æ—¶å¯ä»¥å°†å¤§æ•°æ®é›†åˆ’åˆ†æˆè‹¥å¹²ä¸ªå°æ•°æ®é›†ï¼Œç„¶ååœ¨è¿™äº›å°æ•°æ®é›†ä¸Šè¿ç»­è°ƒç”¨partial_fitæ–¹æ³•æ¥è®­ç»ƒæ¨¡å‹ã€‚</li><li>predict(X): ç”¨æ¨¡å‹è¿›è¡Œé¢„æµ‹ï¼Œè¿”å›é¢„æµ‹å€¼</li><li>predict_log_proba(X): è¿”å›ä¸€ä¸ªæ•°ç»„ï¼Œæ•°ç»„çš„å…ƒç´ ä¾æ¬¡æ˜¯Xé¢„æµ‹ä¸ºå„ä¸ªç±»åˆ«çš„æ¦‚ç‡çš„å¯¹æ•°å€¼</li><li>predict_proba(X): è¿”å›ä¸€ä¸ªæ•°ç»„ï¼Œæ•°ç»„çš„å…ƒç´ ä¾æ¬¡æ˜¯Xé¢„æµ‹ä¸ºå„ä¸ªç±»åˆ«çš„æ¦‚ç‡å€¼</li><li>score(X, y[, sample_weight]): è¿”å›åœ¨(X, y)ä¸Šé¢„æµ‹çš„å‡†ç¡®ç‡</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">def demo_GaussianNB(*data):</span><br><span class="line">    X_train, X_test, y_train, y_test = data</span><br><span class="line">    cls = naive_bayes.GaussianNB()</span><br><span class="line">    cls.fit(X_train, y_train)</span><br><span class="line">    print(&quot;Training score: %.2f&quot; % cls.score(X_train, y_train))</span><br><span class="line">    print(&quot;Testing score: %.2f&quot; % cls.score(X_test, y_test))</span><br></pre></td></tr></table></figure><p>è¿è¡Œç»“æœï¼š</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Training score: 0.86</span><br><span class="line">Testing score: 0.83</span><br></pre></td></tr></table></figure><p>å¯ä»¥çœ‹åˆ°é«˜æ–¯è´å¶æ–¯åˆ†ç±»å™¨å¯¹è®­ç»ƒæ•°æ®é›†çš„é¢„æµ‹å‡†ç¡®ç‡ä¸º86%ï¼Œå¯¹æµ‹è¯•æ•°æ®é›†çš„é¢„æµ‹å‡†ç¡®ç‡ä¸º83%ã€‚</p><h2 id="å¤šé¡¹å¼è´å¶æ–¯åˆ†ç±»å™¨multinomialnb">å¤šé¡¹å¼è´å¶æ–¯åˆ†ç±»å™¨(MultinomialNB)</h2><p>å…¶åŸå‹ä¸ºï¼š</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">class sklearn.native_bayes.MultinomialNB(alpha=1.0, fit_prior=True, class_prior=None)</span><br></pre></td></tr></table></figure><p>å‚æ•°ï¼š</p><ul><li>alpha: ä¸€ä¸ªæµ®ç‚¹æ•°ï¼ŒæŒ‡å®š<span class="math inline">\(\alpha\)</span>å€¼</li><li>fit_prior: booleanï¼Œå¦‚æœä¸ºTrueï¼Œåˆ™ä¸å»å­¦ä¹ <span class="math inline">\(P(y=c_k)\)</span>ï¼Œæ›¿ä»£ä»¥å‡åŒ€åˆ†å¸ƒã€‚</li><li>class_prior: ä¸€ä¸ªæ•°ç»„ï¼ŒæŒ‡å®šäº†æ¯ä¸ªåˆ†ç±»çš„å…ˆéªŒæ¦‚ç‡<span class="math inline">\(P(y=c_1),P(y=c_2),â€¦,P(y=c_K)\)</span>ã€‚å¦‚æœæŒ‡å®šäº†è¯¥å‚æ•°ï¼Œåˆ™æ¯ä¸ªåˆ†ç±»çš„å…ˆéªŒæ¦‚ç‡ä¸å†ä»æ•°æ®é›†ä¸­å­¦å¾—ã€‚</li></ul><p>å±æ€§ï¼š</p><ul><li>class_log_prior_: ä¸€ä¸ªæ•°ç»„å¯¹è±¡ï¼Œå½¢çŠ¶ä¸º(n_classes,)ã€‚ç»™å‡ºæ¯ä¸ªç±»åˆ«è°ƒæ•´åçš„ç»éªŒæ¦‚ç‡åˆ†å¸ƒçš„å¯¹æ•°å€¼</li><li>feature_log_prob_: ä¸€ä¸ªæ•°ç»„å¯¹è±¡ï¼Œå½¢çŠ¶ä¸º(n_classes, n_features)ã€‚ç»™å‡ºäº†<span class="math inline">\(P(X^{(j)}/y=c_k)\)</span>çš„ç»éªŒæ¦‚ç‡åˆ†å¸ƒçš„å¯¹æ•°å€¼</li><li>class_count_: ä¸€ä¸ªæ•°ç»„ï¼Œå½¢çŠ¶ä¸º(n_classes,)ï¼Œæ˜¯æ¯ä¸ªç±»åˆ«åŒ…å«çš„è®­ç»ƒæ ·æœ¬æ•°é‡</li><li>feature_count_: ä¸€ä¸ªæ•°ç»„ï¼Œå½¢çŠ¶ä¸º(n_classes, n_features)ã€‚è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œæ¯ä¸ªç±»åˆ«æ¯ä¸ªç‰¹å¾é‡åˆ°çš„æ ·æœ¬æ•°ã€‚</li></ul><p>æ–¹æ³•ï¼š</p><ul><li>fit(X, y[, sample_weight]): è®­ç»ƒæ¨¡å‹</li><li>partial_fit(X, y[, classes, sample_weight]): è¿½åŠ è®­ç»ƒæ¨¡å‹ã€‚è¯¥æ–¹æ³•ä¸»è¦ç”¨äºå¤§è§„æ¨¡æ•°æ®é›†çš„è®­ç»ƒã€‚æ­¤æ—¶å¯ä»¥å°†å¤§æ•°æ®é›†åˆ’åˆ†æˆè‹¥å¹²ä¸ªå°æ•°æ®é›†ï¼Œç„¶ååœ¨è¿™äº›å°æ•°æ®é›†ä¸Šè¿ç»­è°ƒç”¨partial_fitæ–¹æ³•æ¥è®­ç»ƒæ¨¡å‹ã€‚</li><li>predict(X): ç”¨æ¨¡å‹è¿›è¡Œé¢„æµ‹ï¼Œè¿”å›é¢„æµ‹å€¼</li><li>predict_log_proba(X): è¿”å›ä¸€ä¸ªæ•°ç»„ï¼Œæ•°ç»„çš„å…ƒç´ ä¾æ¬¡æ˜¯Xé¢„æµ‹ä¸ºå„ä¸ªç±»åˆ«çš„æ¦‚ç‡çš„å¯¹æ•°å€¼</li><li>predict_proba(X): è¿”å›ä¸€ä¸ªæ•°ç»„ï¼Œæ•°ç»„çš„å…ƒç´ ä¾æ¬¡æ˜¯Xé¢„æµ‹ä¸ºå„ä¸ªç±»åˆ«çš„æ¦‚ç‡å€¼</li><li>score(X, y[, sample_weight]): è¿”å›åœ¨(X, y)ä¸Šé¢„æµ‹çš„å‡†ç¡®ç‡</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">def demo_MultinomialNB(*data):</span><br><span class="line">    X_train, X_test, y_train, y_test = data</span><br><span class="line">    cls = naive_bayes.MultinomialNB()</span><br><span class="line">    cls.fit(X_train, y_train)</span><br><span class="line">    print(&quot;Training score: %.2f&quot; % cls.score(X_train, y_train))</span><br><span class="line">    print(&quot;Testing score: %.2f&quot; % cls.score(X_test, y_test))</span><br></pre></td></tr></table></figure><p>è¿è¡Œç»“æœï¼š</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Training score: 0.91</span><br><span class="line">Testing score: 0.91</span><br></pre></td></tr></table></figure><p>æ¥ç€æ£€éªŒä¸åŒçš„<span class="math inline">\(\alpha\)</span>å¯¹å¤šé¡¹å¼è´å¶æ–¯åˆ†ç±»å™¨å¯¹é¢„æµ‹æ€§èƒ½çš„å½±å“ï¼š</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">def demo_MultinomialNB_alpha(*data):</span><br><span class="line">    X_train, X_test, y_train, y_test = data</span><br><span class="line">    alphas = np.logspace(-2, 5, num=200)</span><br><span class="line">    training_scores = []</span><br><span class="line">    testing_scores = []</span><br><span class="line">    for alpha in alphas:</span><br><span class="line">        cls = naive_bayes.MultinomialNB(alpha=alpha)</span><br><span class="line">        cls.fit(X_train, y_train)</span><br><span class="line">        training_scores.append(cls.score(X_train, y_train))</span><br><span class="line">        testing_scores.append(cls.score(X_test, y_test))</span><br><span class="line">    # ç»˜å›¾</span><br><span class="line">    fig = plt.figure()</span><br><span class="line">    ax = fig.add_subplot(1, 1, 1)</span><br><span class="line">    ax.plot(alphas, training_scores, label=&quot;training score&quot;)</span><br><span class="line">    ax.plot(alphas, testing_scores, label=&quot;testing score&quot;)</span><br><span class="line">    ax.set_xlabel(r&quot;$\alpha$&quot;)</span><br><span class="line">    ax.set_ylabel(&quot;score&quot;)</span><br><span class="line">    ax.set_ylim(0, 1.0)</span><br><span class="line">    ax.set_title(&quot;MultinomialNB&quot;)</span><br><span class="line">    ax.set_xscale(&quot;log&quot;)</span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure><p>è¿è¡Œç»“æœï¼š</p><p><img src="/images/MachineLearning/BayesClassifier/20190727_ML_MultinomialNB_Alpha.png"></p><p>ä¸ºäº†ä¾¿äºè§‚å¯Ÿæˆ‘ä»¬å°†<span class="math inline">\(x\)</span>è½´è®¾ç½®ä¸ºå¯¹æ•°åæ ‡ã€‚å¯ä»¥çœ‹åˆ°<span class="math inline">\(\alpha &gt;100\)</span>ä¹‹åï¼Œéšç€<span class="math inline">\(\alpha\)</span>çš„å¢é•¿ï¼Œé¢„æµ‹å‡†ç¡®ç‡åœ¨ä¸‹é™ã€‚è¿™æ˜¯å› ä¸ºå¤šé¡¹å¼è´å¶æ–¯ä¼°è®¡ä¸­ï¼Œå‡è®¾ç‰¹å¾çš„æ¡ä»¶æ¦‚ç‡åˆ†å¸ƒæ»¡è¶³å¤šé¡¹å¼åˆ†å¸ƒï¼š<span class="math display">\[P(X^{(j)}=a_{sj}/y=c_k)=\frac{N_{kj}+\alpha }{N_k+\alpha n}\]</span></p><p>å½“<span class="math inline">\(\alpha \to âˆ\)</span>æ—¶ï¼Œ<span class="math inline">\(\frac{N_{kj}+\alpha }{N_k+\alpha n} \to \frac{1}{n}\)</span>ï¼Œå³å¯¹ä»»ä½•ç±»å‹çš„ç‰¹å¾ã€è¯¥ç±»å‹ç‰¹å¾çš„ä»»æ„å–å€¼ï¼Œå‡ºç°çš„æ¦‚ç‡éƒ½æ˜¯<span class="math inline">\(\frac{1}{n}\)</span>ã€‚å®ƒå®Œå…¨å¿½ç•¥äº†å„ä¸ªç‰¹å¾ä¹‹é—´çš„å·®åˆ«ï¼Œä¹Ÿå¿½ç•¥äº†æ¯ä¸ªç‰¹å¾å†…éƒ¨çš„åˆ†å¸ƒã€‚åœ¨æœ¬é—®é¢˜ä¸­æ€»çš„æ ·æœ¬æ•°é‡åœ¨<span class="math inline">\(10^3\)</span>ï¼Œ<span class="math inline">\(N_k\)</span>çš„é‡çº§åœ¨<span class="math inline">\(10^2\)</span>ï¼Œå› æ­¤åœ¨<span class="math inline">\(\alpha &gt;100\)</span>ä¹‹åï¼Œé¢„æµ‹å‡†ç¡®ç‡å—å½±å“è¾ƒå¤§ã€‚</p><h2 id="ä¼¯åŠªåˆ©è´å¶æ–¯åˆ†ç±»å™¨bernoullinb">ä¼¯åŠªåˆ©è´å¶æ–¯åˆ†ç±»å™¨(BernoulliNB)</h2><p>å…¶åŸå‹ä¸ºï¼š</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">class sklearn.native_bayes.BernoulliNB(alpha=1.0, binarize=.0, fit_prior=True,</span><br><span class="line">                 class_prior=None)</span><br></pre></td></tr></table></figure><p>å‚æ•°ï¼š</p><ul><li>alpha: ä¸€ä¸ªæµ®ç‚¹æ•°ï¼ŒæŒ‡å®š<span class="math inline">\(\alpha\)</span>å€¼ï¼Œå°±æ˜¯å‰è¿°è´å¶æ–¯ä¼°è®¡ä¸­çš„<span class="math inline">\(\lambda\)</span></li><li>binarize: ä¸€ä¸ªæµ®ç‚¹æ•°æˆ–è€…None<ul><li>None: å‡å®šåŸå§‹æ•°æ®å·²ç»äºŒå…ƒåŒ–äº†</li><li>æµ®ç‚¹æ•°: ä»¥è¯¥æ•°ä¸ºç•Œï¼Œç‰¹å¾å–å€¼å¤§äºå®ƒçš„ä½œä¸º1ï¼Œç‰¹å¾å–å€¼å°äºå®ƒçš„ä½œä¸º0ã€‚é‡‡å–è¿™ç§ç­–ç•¥æ¥äºŒå…ƒåŒ–</li></ul></li><li>fit_prior: booleanï¼Œå¦‚æœä¸ºTrueï¼Œåˆ™ä¸å»å­¦ä¹ <span class="math inline">\(P(y=c_k)\)</span>ï¼Œæ›¿ä»£ä»¥å‡åŒ€åˆ†å¸ƒã€‚</li><li>class_prior: ä¸€ä¸ªæ•°ç»„ï¼ŒæŒ‡å®šäº†æ¯ä¸ªåˆ†ç±»çš„å…ˆéªŒæ¦‚ç‡<span class="math inline">\(P(y=c_1),P(y=c_2),â€¦,P(y=c_K)\)</span>ã€‚å¦‚æœæŒ‡å®šäº†è¯¥å‚æ•°ï¼Œåˆ™æ¯ä¸ªåˆ†ç±»çš„å…ˆéªŒæ¦‚ç‡ä¸å†ä»æ•°æ®é›†ä¸­å­¦å¾—ã€‚</li></ul><p>å±æ€§ï¼š</p><ul><li>class_log_prior_: ä¸€ä¸ªæ•°ç»„å¯¹è±¡ï¼Œå½¢çŠ¶ä¸º(n_classes,)ã€‚ç»™å‡ºæ¯ä¸ªç±»åˆ«è°ƒæ•´åçš„ç»éªŒæ¦‚ç‡åˆ†å¸ƒçš„å¯¹æ•°å€¼</li><li>feature_log_prob_: ä¸€ä¸ªæ•°ç»„å¯¹è±¡ï¼Œå½¢çŠ¶ä¸º(n_classes, n_features)ã€‚ç»™å‡ºäº†<span class="math inline">\(P(X^{(j)}/y=c_k)\)</span>çš„ç»éªŒæ¦‚ç‡åˆ†å¸ƒçš„å¯¹æ•°å€¼</li><li>class_count_: ä¸€ä¸ªæ•°ç»„ï¼Œå½¢çŠ¶ä¸º(n_classes,)ï¼Œæ˜¯æ¯ä¸ªç±»åˆ«åŒ…å«çš„è®­ç»ƒæ ·æœ¬æ•°é‡</li><li>feature_count_: ä¸€ä¸ªæ•°ç»„ï¼Œå½¢çŠ¶ä¸º(n_classes, n_features)ã€‚è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œæ¯ä¸ªç±»åˆ«æ¯ä¸ªç‰¹å¾é‡åˆ°çš„æ ·æœ¬æ•°ã€‚</li></ul><p>æ–¹æ³•ï¼š</p><ul><li>fit(X, y[, sample_weight]): è®­ç»ƒæ¨¡å‹</li><li>partial_fit(X, y[, classes, sample_weight]): è¿½åŠ è®­ç»ƒæ¨¡å‹ã€‚è¯¥æ–¹æ³•ä¸»è¦ç”¨äºå¤§è§„æ¨¡æ•°æ®é›†çš„è®­ç»ƒã€‚æ­¤æ—¶å¯ä»¥å°†å¤§æ•°æ®é›†åˆ’åˆ†æˆè‹¥å¹²ä¸ªå°æ•°æ®é›†ï¼Œç„¶ååœ¨è¿™äº›å°æ•°æ®é›†ä¸Šè¿ç»­è°ƒç”¨partial_fitæ–¹æ³•æ¥è®­ç»ƒæ¨¡å‹ã€‚</li><li>predict(X): ç”¨æ¨¡å‹è¿›è¡Œé¢„æµ‹ï¼Œè¿”å›é¢„æµ‹å€¼</li><li>predict_log_proba(X): è¿”å›ä¸€ä¸ªæ•°ç»„ï¼Œæ•°ç»„çš„å…ƒç´ ä¾æ¬¡æ˜¯Xé¢„æµ‹ä¸ºå„ä¸ªç±»åˆ«çš„æ¦‚ç‡çš„å¯¹æ•°å€¼</li><li>predict_proba(X): è¿”å›ä¸€ä¸ªæ•°ç»„ï¼Œæ•°ç»„çš„å…ƒç´ ä¾æ¬¡æ˜¯Xé¢„æµ‹ä¸ºå„ä¸ªç±»åˆ«çš„æ¦‚ç‡å€¼</li><li>score(X, y[, sample_weight]): è¿”å›åœ¨(X, y)ä¸Šé¢„æµ‹çš„å‡†ç¡®ç‡</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">def demo_BernoulliNB(*data):</span><br><span class="line">    X_train, X_test, y_train, y_test = data</span><br><span class="line">    cls = naive_bayes.BernoulliNB()</span><br><span class="line">    cls.fit(X_train, y_train)</span><br><span class="line">    print(&quot;Training score: %.2f&quot; % cls.score(X_train, y_train))</span><br><span class="line">    print(&quot;Testing score: %.2f&quot; % cls.score(X_test, y_test))</span><br></pre></td></tr></table></figure><p>è¿è¡Œç»“æœï¼š</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Training score: 0.87</span><br><span class="line">Testing score: 0.85</span><br></pre></td></tr></table></figure><p>æ¥ç€æ£€éªŒä¸åŒçš„<span class="math inline">\(\alpha\)</span>å¯¹ä¼¯åŠªåˆ©è´å¶æ–¯åˆ†ç±»å™¨é¢„æµ‹æ€§èƒ½çš„å½±å“ï¼š</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">def demo_BernoulliNB_alpha(*data):</span><br><span class="line">    X_train, X_test, y_train, y_test = data</span><br><span class="line">    alphas = np.logspace(-2, 5, num=200)</span><br><span class="line">    training_scores = []</span><br><span class="line">    testing_scores = []</span><br><span class="line">    for alpha in alphas:</span><br><span class="line">        cls = naive_bayes.BernoulliNB(alpha=alpha)</span><br><span class="line">        cls.fit(X_train, y_train)</span><br><span class="line">        training_scores.append(cls.score(X_train, y_train))</span><br><span class="line">        testing_scores.append(cls.score(X_test, y_test))</span><br><span class="line">    # ç»˜å›¾</span><br><span class="line">    fig = plt.figure()</span><br><span class="line">    ax = fig.add_subplot(1, 1, 1)</span><br><span class="line">    ax.plot(alphas, training_scores, label=&quot;training score&quot;)</span><br><span class="line">    ax.plot(alphas, testing_scores, label=&quot;testing score&quot;)</span><br><span class="line">    ax.set_xlabel(r&quot;$\alpha$&quot;)</span><br><span class="line">    ax.set_ylabel(&quot;score&quot;)</span><br><span class="line">    ax.set_ylim(0, 1.0)</span><br><span class="line">    ax.set_title(&quot;BernoullizNB&quot;)</span><br><span class="line">    ax.set_xscale(&quot;log&quot;)</span><br><span class="line">    ax.legend(loc=&quot;best&quot;)</span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure><p>è¿è¡Œç»“æœï¼š</p><p><img src="/images/MachineLearning/BayesClassifier/20190727_ML_BernoulliNB_Alpha.png"></p><p>å¯ä»¥çœ‹åˆ°<span class="math inline">\(\alpha &gt;100\)</span>ä¹‹åï¼Œéšç€<span class="math inline">\(\alpha\)</span>çš„å¢é•¿ï¼Œé¢„æµ‹å‡†ç¡®ç‡åœ¨ä¸‹é™ã€‚åŸå› ä¸å¤šé¡¹å¼è´å¶æ–¯åˆ†ç±»å™¨çš„æƒ…å†µç›¸åŒã€‚</p><p>æœ€åè€ƒå¯Ÿbinarizeçš„å‚æ•°å¯¹ä¼¯åŠªåˆ©è´å¶æ–¯åˆ†ç±»å™¨çš„é¢„æµ‹æ€§èƒ½çš„å½±å“ã€‚è¯¥å‚æ•°ç»™å®šäº†äºŒå…ƒåŒ–æ—¶ï¼Œ0-1çš„é˜ˆå€¼ã€‚</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">def demo_BernoulliNB_binarize(*data):</span><br><span class="line">    X_train, X_test, y_train, y_test = data</span><br><span class="line">    min_x = min(np.min(X_train.ravel()), np.min(X_test.ravel())) - 0.1</span><br><span class="line">    max_x = max(np.max(X_train.ravel()), np.max(X_test.ravel())) + 0.1</span><br><span class="line">    binarizes = np.linspace(min_x, max_x, endpoint=True, num=100)</span><br><span class="line">    training_scores = []</span><br><span class="line">    testing_scores = []</span><br><span class="line">    for binarize in binarizes:</span><br><span class="line">        cls = naive_bayes.BernoulliNB(binarize=binarize)</span><br><span class="line">        cls.fit(X_train, y_train)</span><br><span class="line">        training_scores.append(cls.score(X_train, y_train))</span><br><span class="line">        testing_scores.append(cls.score(X_test, y_test))</span><br><span class="line">    # ç»˜å›¾</span><br><span class="line">    fig = plt.figure()</span><br><span class="line">    ax = fig.add_subplot(1, 1, 1)</span><br><span class="line">    ax.plot(binarizes, training_scores, label=&quot;training score&quot;)</span><br><span class="line">    ax.plot(binarizes, testing_scores, label=&quot;testing score&quot;)</span><br><span class="line">    ax.set_xlabel(&quot;binarize&quot;)</span><br><span class="line">    ax.set_ylabel(&quot;score&quot;)</span><br><span class="line">    ax.set_ylim(0, 1.0)</span><br><span class="line">    ax.set_xlim(min_x - 1, max_x + 1)</span><br><span class="line">    ax.set_title(&quot;BernoullizNB&quot;)</span><br><span class="line">    ax.legend(loc=&quot;best&quot;)</span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure><p>è¿è¡Œç»“æœï¼š</p><p><img src="/images/MachineLearning/BayesClassifier/20190727_ML_BernoulliNB_Binarize.png"></p><p>å½“æŒ‡å®šçš„binarizeçš„æœ€å°å€¼ä¸ºæ ·æœ¬é›†ï¼ˆåŒ…æ‹¬æµ‹è¯•é›†ï¼‰æ‰€ä»¥ç‰¹å¾çš„æ‰€æœ‰å€¼ä¸­çš„æœ€å°å€¼å‡å»0.1ï¼Œå½“binarizeå–æœ€å°å€¼æ—¶æ‰€æœ‰ç‰¹å¾çš„æ‰€æœ‰å€¼éƒ½è§†ä¸º1ï¼›æŒ‡å®šçš„binarizeçš„æœ€å¤§å€¼ä¸ºæ ·æœ¬é›†ï¼ˆåŒ…æ‹¬æµ‹è¯•é›†ï¼‰æ‰€ä»¥ç‰¹å¾çš„æ‰€æœ‰å€¼ä¸­çš„æœ€å¤§å€¼åŠ ä¸Š0.1ï¼Œå½“binarizeå–æœ€å¤§å€¼æ—¶æ‰€æœ‰ç‰¹å¾çš„æ‰€æœ‰å€¼éƒ½è§†ä¸º0ã€‚å¯ä»¥çœ‹åˆ°å½“binarizeå¤ªå°æ—¶ï¼Œé¢„æµ‹å‡†ç¡®ç‡æ–­å´–å¼ä¸‹é™ï¼Œè¿™æ˜¯å› ä¸ºæ­¤æ—¶æ‰€æœ‰ç‰¹å¾çš„æ‰€æœ‰å€¼éƒ½è§†ä¸º0ï¼Œæ­¤æ—¶å¯¹äºä¼¯åŠªåˆ©è´å¶æ–¯åˆ†ç±»å™¨æ¥è®²ï¼Œæ‰€æœ‰æ ·æœ¬çš„æ‰€æœ‰ç‰¹å¾ä¹‹é—´æ²¡æœ‰ä»»ä½•åŒºåˆ†ï¼Œæ‰€ä»¥ä¹Ÿæ— ä»é¢„æµ‹ã€‚binarizeçš„å–å€¼å¿…é¡»åœ¨æ ·æœ¬é›†ï¼ˆåŒ…æ‹¬æµ‹è¯•é›†ï¼‰æ‰€æœ‰ç‰¹å¾çš„æ‰€æœ‰å€¼çš„æœ€å°å€¼å’Œæœ€å¤§å€¼ä¹‹é—´ï¼Œä¸”æœ€å¥½èƒ½ä½¿å¾—äºŒå…ƒåŒ–ä¹‹åçš„ç‰¹å¾åˆ†å¸ƒå°½å¯èƒ½è¿‘ä¼¼äºåŸå§‹ç‰¹å¾çš„åˆ†å¸ƒã€‚</p><blockquote><p>å¯ä»¥å°†binarizeå–â€œï¼ˆæ‰€æœ‰ç‰¹å¾çš„æ‰€æœ‰å€¼çš„æœ€å°å€¼+æ‰€æœ‰ç‰¹å¾æ‰€æœ‰å€¼çš„æœ€å¤§å€¼ï¼‰/2â€</p></blockquote><h2 id="é€’å¢å¼å­¦ä¹ partial_fitæ–¹æ³•">é€’å¢å¼å­¦ä¹ partial_fitæ–¹æ³•</h2><p>æœ´ç´ è´å¶æ–¯æ¨¡å‹å¯ä»¥ç”¨æ¥è§£å†³å¤§è§„æ¨¡çš„åˆ†ç±»é—®é¢˜ï¼Œå…¶å®Œæ•´çš„è®­ç»ƒé›†å¯èƒ½ä¸é€‚åˆæ”¾åœ¨å†…å­˜ä¸­ã€‚ä¸ºè§£å†³è¿™ä¸ªé—®é¢˜ï¼Œä¸Šè¿°ä¸‰ä¸ªåˆ†ç±»å™¨éƒ½æœ‰ä¸€ä¸ªpartial_fitæ–¹æ³•ï¼Œå¯ä»¥åŠ¨æ€åœ°å¢åŠ æ•°æ®æ¥ä½¿ç”¨(online classifier)ï¼Œèƒ½å¤Ÿç”¨äºé€’å¢å¼å­¦ä¹ ã€‚</p><p>partial_fitçš„åŸå‹ä¸º<code>partial_fit(X, y, classes=None, sample_weight=None)</code></p><ul><li>X: æ ·æœ¬æ•°æ®</li><li>y: æ ·æœ¬æ ‡è®°</li><li>classes: ä¸€ä¸ªæ•°ç»„å¯¹è±¡ï¼Œå½¢çŠ¶ä¸º(n_classes,)ï¼Œå®ƒåˆ—å‡ºäº†æ‰€æœ‰å¯èƒ½çš„ç±»åˆ«ã€‚ç¬¬ä¸€æ¬¡è°ƒç”¨partial_fitæ—¶ï¼Œå¿…é¡»ä¼ å…¥è¯¥å‚æ•°ï¼Œåç»­çš„è°ƒç”¨ä¸å¿…ä¼ å…¥ã€‚</li><li>sample_weight: ä¸€ä¸ªæ•°ç»„å¯¹è±¡ï¼Œå½¢çŠ¶ä¸º(n_samples,)ã€‚ç»™å‡ºæ¯ä¸ªæ ·æœ¬çš„æƒé‡ã€‚å¦‚æœæœªæŒ‡å®šï¼Œåˆ™å…¨ä¸º1.</li></ul><p>ä½¿ç”¨è¯¥æ–¹æ³•æ—¶ï¼Œæœ€å¥½æ¯æ¬¡çš„æ•°æ®å—éƒ½è¶³å¤Ÿå¤§ï¼Œæ¨èæ¯æ¬¡å¡«æ»¡æ•´ä¸ªå†…å­˜ã€‚</p>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;æ¦‚è¿°&quot;&gt;æ¦‚è¿°&lt;/h1&gt;
&lt;p&gt;è´å¶æ–¯åˆ†ç±»æ˜¯ä¸€ç§åˆ†ç±»ç®—æ³•çš„æ€»ç§°ï¼Œè¿™ç§ç®—æ³•å‡ä»¥è´å¶æ–¯å®šç†ä¸ºåŸºç¡€ï¼Œæ‰€ä»¥ç»Ÿç§°ä¸ºè´å¶æ–¯åˆ†ç±»ã€‚&lt;/p&gt;
&lt;p&gt;è´å¶æ–¯åˆ†ç±»å™¨çš„åˆ†ç±»åŸç†æ˜¯é€šè¿‡æŸå¯¹è±¡çš„å…ˆéªŒæ¦‚ç‡ï¼Œåˆ©ç”¨è´å¶æ–¯å…¬å¼è®¡ç®—å‡ºå…¶åéªŒæ¦‚ç‡ï¼Œå³è¯¥å¯¹è±¡å±äºæŸä¸€ç±»çš„æ¦‚ç‡ï¼Œé€‰æ‹©å…·æœ‰æœ€å¤§åéªŒæ¦‚ç‡çš„ç±»ä½œä¸ºè¯¥å¯¹è±¡æ‰€å±çš„ç±»ã€‚&lt;/p&gt;
&lt;p&gt;è´å¶æ–¯åˆ†ç±»å™¨çš„ä¸»è¦ç‰¹ç‚¹ï¼š&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;å±æ€§å¯ä»¥ç¦»æ•£ï¼Œä¹Ÿå¯ä»¥è¿ç»­&lt;/li&gt;
&lt;li&gt;æ•°å­¦åŸºç¡€æ‰å®ï¼Œåˆ†ç±»æ•ˆç‡ç¨³å®š&lt;/li&gt;
&lt;li&gt;å¯¹ç¼ºå¤±å’Œå™ªå£°æ•°æ®ä¸å¤ªæ•æ„Ÿ&lt;/li&gt;
&lt;li&gt;å±æ€§å¦‚æœä¸ç›¸å…³ï¼Œåˆ†ç±»æ•ˆæœå¾ˆå¥½ï¼›å¦‚æœç›¸å…³ï¼Œåˆ™ä¸ä½äºå†³ç­–æ ‘&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
      <category term="Machine Learning" scheme="http://yoursite.com/categories/Machine-Learning/"/>
    
    
      <category term="machine learning" scheme="http://yoursite.com/tags/machine-learning/"/>
    
      <category term="bayes classifier" scheme="http://yoursite.com/tags/bayes-classifier/"/>
    
      <category term="python" scheme="http://yoursite.com/tags/python/"/>
    
      <category term="sklearn" scheme="http://yoursite.com/tags/sklearn/"/>
    
  </entry>
  
  <entry>
    <title>MachineLearning Chapter-2 Decision Tree</title>
    <link href="http://yoursite.com/2019/07/26/MachineLearning-Chapter-2-Decision-Tree/"/>
    <id>http://yoursite.com/2019/07/26/MachineLearning-Chapter-2-Decision-Tree/</id>
    <published>2019-07-26T04:28:44.000Z</published>
    <updated>2019-07-28T06:25:05.357Z</updated>
    
    <content type="html"><![CDATA[<h1 id="æ¦‚è¿°">æ¦‚è¿°</h1><p>å†³ç­–æ ‘(decision tree)æ˜¯åŠŸèƒ½å¼ºå¤§è€Œä¸”å¾ˆå—æ¬¢è¿çš„åˆ†ç±»å’Œé¢„æµ‹æ–¹æ³•ï¼Œå®ƒæ˜¯ä¸€ç§æœ‰ç›‘ç£çš„å­¦ä¹ ç®—æ³•ï¼Œä»¥æ ‘çŠ¶å›¾ä¸ºåŸºç¡€ï¼Œå…¶è¾“å‡ºç»“æœä¸ºä¸€ç³»åˆ—ç®€å•å®ç”¨çš„è§„åˆ™ã€‚å†³ç­–æ ‘å°±æ˜¯ä¸€ç³»åˆ—çš„if-thenäºè¯­å¥ï¼Œå¯ä»¥ç”¨äºåˆ†ç±»é—®é¢˜ï¼Œä¹Ÿå¯ä»¥ç”¨äºå›å½’é—®é¢˜ã€‚</p><p>å†³ç­–æ ‘æ¨¡å‹åŸºäºç‰¹å¾å¯¹å®ä¾‹è¿›è¡Œåˆ†ç±»ï¼Œå®ƒæ˜¯ä¸€ç§æ ‘çŠ¶ç»“æ„ã€‚ä¼˜ç‚¹æ˜¯å¯è¯»æ€§å¼ºï¼Œåˆ†ç±»é€Ÿåº¦å¿«ã€‚å­¦ä¹ å†³ç­–æ ‘æ—¶ï¼Œé€šå¸¸é‡‡ç”¨æŸå¤±å‡½æ•°æœ€å°åŒ–åŸåˆ™ã€‚</p><blockquote><p>æœ¬ç« ä¸­ï¼Œè®­ç»ƒé›†ç”¨Dè¡¨ç¤ºï¼ŒTè¡¨ç¤ºä¸€æ£µå†³ç­–æ ‘ã€‚</p></blockquote><a id="more"></a><h1 id="ç®—æ³•">ç®—æ³•</h1><h2 id="å†³ç­–æ ‘åŸç†">å†³ç­–æ ‘åŸç†</h2><p>å†³ç­–æ ‘æ˜¯ä¸€ä¸ªè´ªå¿ƒç®—æ³•ï¼Œå³åœ¨ç‰¹å¾ç©ºé—´ä¸Šæ‰§è¡Œé€’å½’çš„äºŒå…ƒåˆ†å‰²ï¼Œå†³ç­–æ ‘ç”±èŠ‚ç‚¹å’Œæœ‰å‘è¾¹ç»„æˆã€‚å†…éƒ¨èŠ‚ç‚¹è¡¨ç¤ºä¸€ä¸ªç‰¹å¾æˆ–è€…å±æ€§ï¼Œå¶å­ç»“ç‚¹è¡¨ç¤ºä¸€ä¸ªåˆ†ç±»ã€‚ä½¿ç”¨å†³ç­–æ ‘è¿›è¡Œåˆ†ç±»æ—¶ï¼Œå°†å®ä¾‹åˆ†é…åˆ°å¶èŠ‚ç‚¹çš„ç±»ä¸­ï¼Œè¯¥å¶èŠ‚ç‚¹æ‰€å±çš„ç±»å°±æ˜¯è¯¥èŠ‚ç‚¹çš„åˆ†ç±»ã€‚</p><p>å†³ç­–æ ‘å¯ä»¥è¡¨ç¤ºç»™å®šç‰¹å¾æ¡ä»¶ä¸‹ï¼Œç±»åˆ«çš„æ¡ä»¶æ¦‚ç‡åˆ†å¸ƒã€‚å°†ç‰¹å¾ç©ºé—´åˆ’åˆ†ä¸ºäº’ä¸ç›¸äº¤çš„å•å…ƒ<span class="math inline">\(S_1,S_2,â€¦,S_m\)</span>ã€‚è®¾æŸä¸ªå•å…ƒ<span class="math inline">\(S_i\)</span>å†…éƒ¨æœ‰<span class="math inline">\(N_i\)</span>ä¸ªæ ·æœ¬ç‚¹ï¼Œåˆ™å®ƒå®šä¹‰äº†ä¸€ä¸ªæ¡ä»¶æ¦‚ç‡åˆ†å¸ƒ<span class="math inline">\(P(y=c_k/X)\)</span>, <span class="math inline">\(X\in S_i\)</span>; <span class="math inline">\(c_k,k=1,2,â€¦,K\)</span>ä¸ºç¬¬<span class="math inline">\(k\)</span>ä¸ªåˆ†ç±»ã€‚</p><ul><li>æ¯ä¸ªå•å…ƒå¯¹åº”äºå†³ç­–æ ‘çš„ä¸€æ¡è·¯å¾„</li><li>æ‰€æœ‰å•å…ƒçš„æ¡ä»¶æ¦‚ç‡åˆ†å¸ƒæ„æˆäº†å†³ç­–æ ‘æ‰€ä»£è¡¨çš„æ¡ä»¶æ¦‚ç‡åˆ†å¸ƒ</li><li>åœ¨å•å…ƒ<span class="math inline">\(S_i\)</span>å†…éƒ¨æœ‰<span class="math inline">\(N_i\)</span>ä¸ªæ ·æœ¬ç‚¹ï¼Œä½†æ˜¯æ•´ä¸ªå•å…ƒéƒ½å±äºç±»<span class="math inline">\(\hat{c}_k\)</span>ã€‚å…¶ä¸­ï¼Œ<span class="math inline">\(\hat{c}_k=\arg_{c_k}\max P(y=c_k/X)\)</span>, <span class="math inline">\(X\in S_i\)</span>ã€‚å³å•å…ƒ<span class="math inline">\(S_i\)</span>å†…éƒ¨çš„<span class="math inline">\(N_i\)</span>ä¸ªæ ·æœ¬ç‚¹ï¼Œå“ªä¸ªåˆ†ç±»å ä¼˜ï¼Œåˆ™æ•´ä¸ªå•å…ƒéƒ½å±äºè¯¥ç±»ã€‚</li></ul><h2 id="æ„å»ºå†³ç­–æ ‘çš„æ­¥éª¤">æ„å»ºå†³ç­–æ ‘çš„æ­¥éª¤</h2><p>æ„å»ºå†³ç­–æ ‘é€šå¸¸åŒ…æ‹¬ä¸‰ä¸ªæ­¥éª¤ï¼š</p><ol type="1"><li>ç‰¹å¾é€‰æ‹©</li><li>å†³ç­–æ ‘ç”Ÿæˆ</li><li>å†³ç­–æ ‘å‰ªæ</li></ol><p>å‡è®¾ç»™å®šè®­ç»ƒé›†<span class="math inline">\(D=\{(\vec{x}_1,y_1),(\vec{x}_2,y_2),â€¦,(\vec{x}_N,y_1N,\}\)</span>ï¼Œå…¶ä¸­<span class="math inline">\(\vec{x}_i=(x_i^{(1)},x_i^{(2)},â€¦,x_i^{(n)})\)</span>ä¸ºè¾“å…¥å®ä¾‹ï¼Œ<span class="math inline">\(n\)</span>ä¸ºç‰¹å¾ä¸ªæ•°ï¼›<span class="math inline">\(y_i\in \{1,2,â€¦,K\}\)</span>ä¸ºç±»æ ‡è®°ï¼Œ<span class="math inline">\(i=1,2,â€¦,N\)</span>ï¼›<span class="math inline">\(N\)</span>ä¸ºæ ·æœ¬å®¹é‡ã€‚æ„å»ºå†³ç­–æ ‘çš„ç›®æ ‡æ˜¯ï¼Œæ ¹æ®ç»™å®šçš„è®­ç»ƒæ•°æ®é›†å­¦ä¹ ä¸€ä¸ªå†³ç­–æ ‘æ¨¡å‹ã€‚</p><p>æ„å»ºå†³ç­–æ ‘é€šå¸¸æ˜¯å°†æ­£åˆ™åŒ–çš„æå¤§ä¼¼ç„¶å‡½æ•°ä½œä¸ºæŸå¤±å‡½æ•°ï¼Œå…¶å­¦ä¹ ç›®æ ‡æ˜¯æŸå¤±å‡½æ•°ä¸ºç›®æ ‡å‡½æ•°çš„æœ€å°åŒ–ã€‚æ„å»ºå†³ç­–æ ‘çš„ç®—æ³•é€šå¸¸æ˜¯é€’å½’åœ°é€‰æ‹©æœ€ä¼˜ç‰¹å¾ï¼Œå¹¶æ ¹æ®è¯¥ç‰¹å¾å¯¹è®­ç»ƒæ•°æ®è¿›è¡Œåˆ†å‰²ï¼Œå…¶æ­¥éª¤å¦‚ä¸‹ï¼š</p><ol type="1"><li>æ„å»ºæ ¹èŠ‚ç‚¹ï¼Œæ‰€æœ‰è®­ç»ƒæ ·æœ¬éƒ½ä½äºæ ¹èŠ‚ç‚¹</li><li>é€‰æ‹©ä¸€ä¸ªæœ€ä¼˜ç‰¹å¾ã€‚é€šè¿‡è¯¥ç‰¹å¾å°†è®­ç»ƒæ•°æ®åˆ†å‰²æˆå­é›†ï¼Œç¡®ä¿å„ä¸ªå­é›†æœ‰æœ€å¥½çš„åˆ†ç±»ï¼Œä½†è¦è€ƒè™‘ä¸‹åˆ—ä¸¤ç§æƒ…å†µï¼š<ol type="1"><li>è‹¥å­é›†å·²èƒ½å¤Ÿè¢«è¾ƒå¥½åœ°åˆ†ç±»ï¼Œåˆ™æ„å»ºå¶èŠ‚ç‚¹ï¼Œå¹¶å°†è¯¥å­é›†åˆ’åˆ†åˆ°å¯¹åº”çš„å¶èŠ‚ç‚¹å»</li><li>è‹¥æŸä¸ªå­é›†ä¸èƒ½è¢«è¾ƒå¥½åœ°åˆ†ç±»ï¼Œåˆ™å¯¹è¯¥å­é›†ç»§ç»­åˆ’åˆ†</li></ol></li><li>é€’å½’ç›´è‡³æ‰€æœ‰è®­ç»ƒæ ·æœ¬éƒ½è¢«è¾ƒå¥½åœ°åˆ†ç±»ï¼Œæˆ–è€…æ²¡æœ‰åˆé€‚çš„ç‰¹å¾ä¸ºæ­¢</li></ol><p>é€šè¿‡è¯¥æ­¥éª¤ç”Ÿæˆçš„å†³ç­–æ ‘å¯¹è®­ç»ƒæ ·æœ¬æœ‰å¾ˆå¥½çš„åˆ†ç±»èƒ½åŠ›ï¼Œä½†æˆ‘ä»¬éœ€è¦çš„æ˜¯å¯¹æœªçŸ¥æ ·æœ¬çš„åˆ†ç±»èƒ½åŠ›ã€‚å› æ­¤é€šå¸¸éœ€è¦å¯¹å·²ç”Ÿæˆçš„å†³ç­–æ ‘è¿›è¡Œå‰ªæï¼Œä»è€Œä½¿å¾—å†³ç­–æ ‘å…·æœ‰æ›´å¥½çš„æ³›åŒ–èƒ½åŠ›ã€‚å‰ªæè¿‡ç¨‹æ˜¯å»æ‰è¿‡äºç»†åˆ†çš„å¶èŠ‚ç‚¹ï¼Œä»è€Œæé«˜æ³›åŒ–èƒ½åŠ›ã€‚</p><h3 id="ç‰¹å¾é€‰æ‹©">ç‰¹å¾é€‰æ‹©</h3><p>ç‰¹å¾é€‰æ‹©å°±æ˜¯é€‰å–æœ‰è¾ƒå¼ºåˆ†ç±»èƒ½åŠ›çš„ç‰¹å¾ã€‚åˆ†ç±»èƒ½åŠ›é€šè¿‡ä¿¡æ¯å¢ç›Šæˆ–è€…ä¿¡æ¯å¢ç›Šæ¯”æ¥åˆ»ç”»ã€‚é€‰æ‹©ç‰¹å¾çš„æ ‡å‡†å°±æ˜¯æ‰¾å‡ºå±€éƒ¨æœ€ä¼˜çš„ç‰¹å¾ä½œä¸ºåˆ¤æ–­è¿›è¡Œåˆ‡åˆ†ï¼Œå–å†³äºåˆ‡åˆ†åèŠ‚ç‚¹æ•°æ®é›†åˆä¸­ç±»åˆ«çš„æœ‰åºç¨‹åº¦(çº¯åº¦)ï¼Œåˆ’åˆ†åçš„åˆ†åŒºæ•°æ®è¶Šçº¯ï¼Œåˆ‡åˆ†è§„åˆ™è¶Šåˆé€‚ã€‚è¡¡é‡èŠ‚ç‚¹æ•°æ®é›†åˆçš„çº¯åº¦æœ‰ï¼šç†µã€åŸºå°¼ç³»æ•°å’Œæ–¹å·®ã€‚ç†µå’ŒåŸºå°¼ç³»æ•°æ˜¯é’ˆå¯¹åˆ†ç±»çš„ï¼Œæ–¹å·®æ˜¯é’ˆå¯¹å›å½’çš„ã€‚</p><h4 id="ç†µ">ç†µ</h4><p>å…ˆç»™å‡ºç†µ(entropy)çš„å®šä¹‰ï¼Œè®¾Xæ˜¯ä¸€ä¸ªç¦»æ•£å‹éšæœºå˜é‡ï¼Œå…¶æ¦‚ç‡åˆ†å¸ƒä¸º</p><p><span class="math display">\[P(X=\vec{x}_i)=p_i,i=1,2,â€¦,n\]</span></p><p>åˆ™éšæœºå˜é‡<span class="math inline">\(X\)</span>çš„ç†µä¸ºï¼š</p><p><span class="math display">\[H(X)=-\sum_{i=1}^n p_i \log p_i\]</span></p><p>å…¶ä¸­ï¼Œå®šä¹‰<span class="math inline">\(0\log 0=0\)</span>ã€‚</p><p>å½“éšæœºå˜é‡<span class="math inline">\(X\)</span>åªå–ä¸¤ä¸ªå€¼æ—¶ï¼Œ<span class="math inline">\(X\)</span>çš„åˆ†å¸ƒä¸ºï¼š</p><p><span class="math display">\[P(X=1)=p \\ P(X=0)=1-p,0â‰¤pâ‰¤1\]</span></p><p>æ­¤æ—¶ç†µä¸ºï¼š<span class="math inline">\(H(P)=-p\log p-(1-p)\log (1-p), 0â‰¤pâ‰¤1\)</span></p><ul><li>å½“<span class="math inline">\(p=0\)</span>æˆ–è€…<span class="math inline">\(p=1\)</span>æ—¶ï¼Œç†µæœ€å°(ä¸º0)ï¼Œæ­¤æ—¶éšæœºå˜é‡ä¸ç¡®å®šæ€§æœ€å°</li><li>å½“<span class="math inline">\(p=0.5\)</span>æ—¶ï¼Œç†µæœ€å¤§(ä¸º1)ï¼Œæ­¤æ—¶éšæœºå˜é‡ä¸ç¡®å®šæ€§æœ€å¤§</li></ul><p>è®¾éšæœºå˜é‡<span class="math inline">\((X,Y)\)</span>ï¼Œå…¶è”åˆæ¦‚ç‡åˆ†å¸ƒä¸ºï¼š<span class="math inline">\(P(X=\vec{x}_i,Y=y_j)=p_{ij}\)</span>, <span class="math inline">\(i=1,2,â€¦,n\)</span>; <span class="math inline">\(j=1,2,â€¦,m\)</span>ã€‚åˆ™æ¡ä»¶ç†µ<span class="math inline">\(H(Y/X)\)</span>å®šä¹‰ä¸ºï¼š</p><p><span class="math display">\[H(Y/X)=\sum_{i=1}^n P_X(X=\vec{x}_i)H(Y/X=\vec{x}_i)\]</span></p><p>å…¶ä¸­ï¼Œ<span class="math inline">\(P_X(X=\vec{x}_i)=\sum_YP(X=\vec{x}_i,Y)\)</span></p><ul><li>å½“ç†µä¸­çš„æ¦‚ç‡ç”±æ•°æ®ä¼°è®¡å¾—åˆ°æ—¶ï¼Œç§°ä¹‹ä¸ºç»éªŒç†µ</li><li>å½“æ¡ä»¶ç†µä¸­çš„æ¦‚ç‡ç”±æ•°æ®ä¼°è®¡å¾—åˆ°æ—¶ï¼Œç§°ä¹‹ä¸ºç»éªŒæ¡ä»¶ç†µ</li></ul><h4 id="ä¿¡æ¯å¢ç›Š">ä¿¡æ¯å¢ç›Š</h4><p>å¯¹äºæ•°æ®é›†<span class="math inline">\(D\)</span>ï¼Œæˆ‘ä»¬é€šè¿‡<span class="math inline">\(H(Y)\)</span>æ¥åˆ»ç”»æ•°æ®é›†<span class="math inline">\(D\)</span>çš„ä¸ç¡®å®šç¨‹åº¦ã€‚å½“æ•°æ®é›†<span class="math inline">\(D\)</span>ä¸­çš„æ‰€æœ‰æ ·æœ¬éƒ½æ˜¯åŒä¸€ç±»åˆ«æ—¶ï¼Œ<span class="math inline">\(H(Y)=0\)</span>ã€‚ä¹Ÿå°†<span class="math inline">\(H(Y)\)</span>è®°ä½œ<span class="math inline">\(H(D)\)</span>ã€‚ç»™å®šç‰¹å¾<span class="math inline">\(A\)</span>å’Œè®­ç»ƒæ•°æ®é›†<span class="math inline">\(D\)</span>ï¼Œå®šä¹‰ä¿¡æ¯å¢ç›Š<span class="math inline">\(g(D,A)\)</span>ä¸ºï¼š<span class="math inline">\(g(D,A)=H(D)-H(D/A)\)</span>ã€‚</p><p>ä¿¡æ¯å¢ç›Šåˆ»ç”»çš„æ˜¯ç”±äºç‰¹å¾<span class="math inline">\(A\)</span>è€Œä½¿å¾—å¯¹æ•°æ®é›†<span class="math inline">\(D\)</span>çš„åˆ†ç±»çš„ä¸ç¡®å®šæ€§å‡å°‘çš„ç¨‹åº¦ã€‚æ„å»ºå†³ç­–æ ‘é€‰æ‹©ä¿¡æ¯å¢ç›Šå¤§çš„ç‰¹å¾æ¥åˆ’åˆ†æ•°æ®é›†ã€‚</p><p>è¿™é‡Œç»™å‡ºè®¡ç®—ä¿¡æ¯å¢ç›Šçš„ç®—æ³•ã€‚å‡è®¾è®­ç»ƒæ•°æ®é›†ä¸º<span class="math inline">\(D\)</span>ï¼Œ<span class="math inline">\(N\)</span>ä¸ºå…¶è®­ç»ƒæ•°æ®é›†å®¹é‡ã€‚å‡è®¾æœ‰<span class="math inline">\(K\)</span>ä¸ªç±»åˆ«ä¾æ¬¡ä¸º<span class="math inline">\(c_k,k=1,2,â€¦,K\)</span>ã€‚è®¾<span class="math inline">\(|C_k|\)</span>ä¸ºå±äºç±»<span class="math inline">\(c_k\)</span>çš„æ ·æœ¬ä¸ªæ•°ã€‚</p><p>è®¾ç‰¹å¾<span class="math inline">\(A\)</span>æ˜¯ç¦»æ•£çš„ï¼Œä¸”æœ‰<span class="math inline">\(n\)</span>ä¸ªä¸åŒçš„å–å€¼ï¼š<span class="math inline">\(\{a_1,a_2,â€¦,a_n\}\)</span>ï¼Œæ ¹æ®ç‰¹å¾<span class="math inline">\(A\)</span>çš„å–å€¼å°†<span class="math inline">\(D\)</span>åˆ’åˆ†å‡º<span class="math inline">\(n\)</span>ä¸ªå­é›†ï¼š<span class="math inline">\(D_1,D_2,â€¦,D_n\)</span>ï¼Œ<span class="math inline">\(N_i\)</span>ä¸ºå¯¹åº”çš„<span class="math inline">\(D_i\)</span>ä¸­çš„æ ·æœ¬ä¸ªæ•°ã€‚</p><p>è®¾é›†åˆ<span class="math inline">\(D_i\)</span>ä¸­å±äºç±»<span class="math inline">\(c_k\)</span>çš„æ ·æœ¬é›†åˆä¸º<span class="math inline">\(D_{ik}\)</span>ï¼Œå…¶å®¹é‡ä¸º<span class="math inline">\(N_{ik}\)</span>ï¼Œä¿¡æ¯å¢ç›Šç®—æ³•å¦‚ä¸‹ï¼š</p><ul><li>è¾“å…¥ï¼š<ul><li>è®­ç»ƒæ•°æ®é›†<span class="math inline">\(D\)</span></li><li>ç‰¹å¾<span class="math inline">\(A\)</span></li></ul></li><li>è¾“å‡ºï¼šä¿¡æ¯å¢ç›Š<span class="math inline">\(g(D,A)\)</span></li><li>ç®—æ³•æ­¥éª¤<ul><li>è®¡ç®—æ•°æ®é›†<span class="math inline">\(D\)</span>çš„ç»éªŒç†µ<span class="math inline">\(H(D)\)</span>ã€‚å®ƒå°±æ˜¯è®­ç»ƒæ•°æ®é›†<span class="math inline">\(D\)</span>ä¸­ï¼Œåˆ†ç±»<span class="math inline">\(Y\)</span>çš„æ¦‚ç‡ä¼°è®¡<span class="math inline">\(\hat{P}(Y=c_k)=\frac{|C_k|}{N}\)</span>è®¡ç®—å¾—åˆ°çš„ç»éªŒç†µã€‚<span class="math display">\[H(D)=-\sum_{k=1}^K\frac{|C_k|}{N}\log \frac{|C_k|}{N}\]</span></li><li>è®¡ç®—ç‰¹å¾<span class="math inline">\(A\)</span>å¯¹äºæ•°æ®é›†<span class="math inline">\(D\)</span>çš„ç»éªŒæ¡ä»¶ç†µ<span class="math inline">\(H(D/A)\)</span>ã€‚å®ƒä½¿ç”¨äº†ç‰¹å¾<span class="math inline">\(A\)</span>çš„æ¦‚ç‡ä¼°è®¡ï¼š<span class="math inline">\(\hat{P}(X^{(A)}=a_i)=\frac{N_i}{N}\)</span>ï¼Œä»¥åŠç»éªŒæ¡ä»¶ç†µï¼š<span class="math inline">\(\hat{H}(D/X^{(A)}=a_i)=\sum_{k=1}^K-(\frac{N_{ik}}{N_i}\log \frac{N_{ik}}{N_i})\)</span>ï¼ˆå…¶ä¸­ä½¿ç”¨äº†æ¡ä»¶æ¦‚ç‡ä¼°è®¡<span class="math inline">\(\hat{P}(Y=c_k/X^{(A)}=a_i)=\frac{N_{ik}}{N_i}\)</span>ï¼Œæ„ä¹‰æ˜¯ï¼šåœ¨å­é›†<span class="math inline">\(D_i\)</span>ä¸­<span class="math inline">\(Y\)</span>çš„åˆ†å¸ƒï¼‰<span class="math display">\[H(D/A)=\sum_{i=1}^n\frac{N_i}{N}\sum_{k=1}^K-(\frac{N_{ik}}{N_i}\log \frac{N_{ik}}{N_i})\]</span></li><li>è®¡ç®—ä¿¡æ¯å¢ç›Š<span class="math display">\[g(D,A)=H(D)-H(D/A)\]</span></li></ul></li></ul><p>ç†µè¶Šå¤§ï¼Œåˆ™è¡¨ç¤ºè¶Šæ··ä¹±ï¼›ç†µè¶Šå°ï¼Œåˆ™è¡¨ç¤ºè¶Šæœ‰åºã€‚å› æ­¤ä¿¡æ¯å¢ç›Šè¡¨ç¤ºæ··ä¹±çš„å‡å°‘ç¨‹åº¦ï¼ˆæœ‰åºçš„å¢åŠ ç¨‹åº¦ï¼‰ã€‚</p><p>ä»¥ä¿¡æ¯å¢ç›Šä½œä¸ºåˆ’åˆ†è®­ç»ƒé›†çš„ç‰¹å¾é€‰å–æ–¹æ¡ˆï¼Œå­˜åœ¨åå‘äºé€‰å–å€¼è¾ƒå¤šçš„ç‰¹å¾çš„é—®é¢˜ã€‚å…¬å¼ï¼š</p><p><span class="math display">\[g(D,A)=H(D)-H(D/A)=H(D)-\sum_{i=1}^n\frac{N_i}{N}\sum_{k=1}^K-(\frac{N_{ik}}{N_i}\log \frac{N_{ik}}{N_i})\]</span></p><h4 id="ä¿¡æ¯å¢ç›Šæ¯”">ä¿¡æ¯å¢ç›Šæ¯”</h4><p>åœ¨æé™æƒ…å†µä¸‹ï¼Œç‰¹å¾<span class="math inline">\(A\)</span>å°†æ¯ä¸€ä¸ªæ ·æœ¬ä¸€ä¸€å¯¹åº”åˆ°å¯¹åº”çš„èŠ‚ç‚¹å½“ä¸­å»çš„æ—¶å€™(æ¯ä¸ªèŠ‚ç‚¹ä¸­æœ‰ä¸”ä»…æœ‰ä¸€ä¸ªæ ·æœ¬)ï¼Œæ­¤æ—¶<span class="math inline">\(\frac{N_{ik}}{N_i}=1,i=1,2,â€¦,n\)</span>ï¼Œæ¡ä»¶ç†µéƒ¨åˆ†ä¸º0ã€‚è€Œæ¡ä»¶ç†µçš„æœ€å°å€¼ä¸º0ï¼Œè¿™æ„å‘³ç€è¯¥æƒ…å†µä¸‹çš„ä¿¡æ¯å¢ç›Šè¾¾åˆ°äº†æœ€å¤§å€¼ã€‚ç„¶è€Œï¼Œæˆ‘ä»¬çŸ¥é“è¿™ä¸ªç‰¹å¾<span class="math inline">\(A\)</span>æ˜¾ç„¶ä¸æ˜¯æœ€ä½³çš„é€‰æ‹©ã€‚</p><p>å¯ä»¥é€šè¿‡å®šä¹‰ä¿¡æ¯å¢ç›Šæ¯”æ¥è§£å†³ã€‚ç‰¹å¾<span class="math inline">\(A\)</span>å¯¹è®­ç»ƒé›†<span class="math inline">\(D\)</span>å¯¹ä¿¡æ¯å¢ç›Šæ¯”<span class="math inline">\(g_R(D,A)\)</span>å®šä¹‰ä¸ºï¼š<span class="math display">\[g_R(D,A)=\frac{g(D,A)}{H_A(D)}\\ H_A(D)=-\sum_{i=1}^n\frac{N_i}{N} \log \frac{N_i}{N}\]</span></p><p><span class="math inline">\(H_A(D)\)</span>åˆ»ç”»äº†ç‰¹å¾<span class="math inline">\(A\)</span>å¯¹è®­ç»ƒé›†<span class="math inline">\(D\)</span>å¯¹åˆ†è¾¨èƒ½åŠ›ã€‚ä½†æ˜¯è¿™ä¸è¡¨å¾å®ƒå¯¹ç±»åˆ«çš„åˆ†è¾¨èƒ½åŠ›ã€‚æ¯”å¦‚<span class="math inline">\(A\)</span>å°†<span class="math inline">\(D\)</span>åˆ‡åˆ†æˆäº†2å—<span class="math inline">\(D_1\)</span>å’Œ<span class="math inline">\(D_2\)</span>ï¼Œé‚£ä¹ˆå¾ˆæœ‰å¯èƒ½<span class="math inline">\(H(D)=H(D_1)=H(D_2)\)</span>ï¼ˆå¦‚æ¯ä¸ªå­é›†<span class="math inline">\(D_i\)</span>ä¸­å„ç±»åˆ«æ ·æœ¬çš„æ¯”ä¾‹ä¸<span class="math inline">\(D\)</span>ä¸­å„ç±»åˆ«æ ·æœ¬çš„æ¯”ä¾‹ç›¸åŒï¼‰ã€‚</p><h3 id="å†³ç­–æ ‘ç”Ÿæˆ">å†³ç­–æ ‘ç”Ÿæˆ</h3><p>åŸºç¡€çš„å†³ç­–æ ‘ç”Ÿæˆç®—æ³•ä¸­ï¼Œå…¸å‹çš„æœ‰ID3ç”Ÿæˆç®—æ³•å’ŒC4.5ç”Ÿæˆç®—æ³•ï¼Œå®ƒä»¬ç”Ÿæˆæ ‘çš„è¿‡ç¨‹å¤§è‡´ç›¸ä¼¼ã€‚ID3æ˜¯é‡‡ç”¨çš„ä¿¡æ¯å¢ç›Šä½œä¸ºç‰¹å¾é€‰æ‹©çš„åº¦é‡ï¼Œè€ŒC4.5åˆ™é‡‡ç”¨ä¿¡æ¯å¢ç›Šæ¯”ã€‚</p><h4 id="id3ç”Ÿæˆç®—æ³•">ID3ç”Ÿæˆç®—æ³•</h4><p>ID3ç”Ÿæˆç®—æ³•åº”ç”¨ä¿¡æ¯å¢ç›Šå‡†åˆ™é€‰æ‹©ç‰¹å¾ï¼Œå…¶ç®—æ³•æè¿°å¦‚ä¸‹ï¼š</p><ul><li>è¾“å…¥ï¼š<ul><li>è®­ç»ƒæ•°æ®é›†<span class="math inline">\(D\)</span></li><li>ç‰¹å¾é›†<span class="math inline">\(A\)</span></li><li>ç‰¹å¾ä¿¡æ¯å¢ç›Šé˜ˆå€¼<span class="math inline">\(\varepsilon &gt;0\)</span></li></ul></li><li>è¾“å‡ºï¼šå†³ç­–æ ‘<span class="math inline">\(T\)</span></li><li>ç®—æ³•æ­¥éª¤<ul><li>è‹¥<span class="math inline">\({D}\)</span>ä¸­æ‰€æœ‰å®ä¾‹å‡å±äºåŒä¸€ç±»<span class="math inline">\({c_k}\)</span>ï¼Œåˆ™<span class="math inline">\({T}\)</span>ä¸ºå•èŠ‚ç‚¹æ ‘ï¼Œå¹¶å°†<span class="math inline">\(c_k\)</span>ä½œä¸ºè¯¥èŠ‚ç‚¹çš„åæ ‡è®°ï¼Œè¿”å›<span class="math inline">\(T\)</span>ã€‚è¿™æ˜¯ä¸€ç§ç‰¹æ®Šæƒ…å†µï¼š<span class="math inline">\(D\)</span>çš„åˆ†ç±»é›†åˆåªæœ‰ä¸€ä¸ªåˆ†ç±»ã€‚</li><li>è‹¥<span class="math inline">\(A=\phi\)</span>ï¼Œåˆ™<span class="math inline">\(T\)</span>ä¸ºå•èŠ‚ç‚¹æ ‘ï¼Œå°†<span class="math inline">\(D\)</span>ä¸­å®ä¾‹æ•°æœ€å¤§çš„ç±»<span class="math inline">\(c_k\)</span>ä½œä¸ºè¯¥èŠ‚ç‚¹çš„ç±»æ ‡è®°ï¼Œè¿”å›<span class="math inline">\(T\)</span>ï¼ˆå³å¤šæ•°è¡¨å†³ï¼‰ã€‚è¿™ä¹Ÿæ˜¯ä¸€ç§ç‰¹æ®Šæƒ…å†µï¼š<span class="math inline">\(D\)</span>çš„ç‰¹å¾é›†åˆä¸ºç©ºã€‚</li><li>å¦åˆ™è®¡ç®—<span class="math inline">\(g(D,A_i)\)</span>ï¼Œå…¶ä¸­<span class="math inline">\(A_i \in A\)</span>ä¸ºç‰¹å¾é›†åˆä¸­çš„å„ä¸ªç‰¹å¾ï¼Œé€‰æ‹©ä¿¡æ¯å¢ç›Šæœ€å¤§çš„ç‰¹å¾$ A_g $ã€‚</li><li>åˆ¤æ–­<span class="math inline">\({A_g}\)</span>çš„ä¿¡æ¯å¢ç›Š<ul><li>è‹¥<span class="math inline">\({g(D,A_g)&lt; \varepsilon}\)</span>ï¼Œåˆ™ç½®<span class="math inline">\({T}\)</span>ä¸ºå•èŠ‚ç‚¹æ ‘ï¼Œå°†<span class="math inline">\({D}\)</span>ä¸­å®ä¾‹æ•°æœ€å¤§çš„ç±»<span class="math inline">\({c_k}\)</span>ä½œä¸ºè¯¥èŠ‚ç‚¹çš„ç±»æ ‡è®°ï¼Œè¿”å›<span class="math inline">\({T}\)</span>ã€‚<ul><li>å¦‚æœä¸è®¾ç½®ç‰¹å¾ä¿¡æ¯å¢ç›Šçš„ä¸‹é™ï¼Œåˆ™å¯èƒ½ä¼šä½¿æ¯ä¸ªå¶å­éƒ½åªæœ‰ä¸€ä¸ªæ ·æœ¬ç‚¹ï¼Œä»è€Œåˆ’åˆ†å¾—å¤ªç»†</li></ul></li><li>è‹¥<span class="math inline">\({g(D,A_g)â‰¥ \varepsilon}\)</span>ï¼Œåˆ™å¯¹<span class="math inline">\({A_g}\)</span>ç‰¹å¾å¯¹æ¯ä¸ªå¯èƒ½å–å€¼<span class="math inline">\({a_i}\)</span>ï¼Œæ ¹æ®<span class="math inline">\({A_g=a_i}\)</span>å°†<span class="math inline">\({D}\)</span>åˆ’åˆ†ä¸ºè‹¥å¹²ä¸ªéç©ºå­é›†<span class="math inline">\({D_i}\)</span>ï¼Œå°†<span class="math inline">\({D_i}\)</span>ä¸­å®ä¾‹æ•°æœ€å¤§çš„ç±»ä½œä¸ºæ ‡è®°ï¼Œæ„å»ºå­èŠ‚ç‚¹ï¼Œç”±å­èŠ‚ç‚¹åŠå…¶å­èŠ‚ç‚¹æ„æˆæ ‘<span class="math inline">\({T}\)</span>ï¼Œè¿”å›<span class="math inline">\({T}\)</span>ã€‚</li></ul></li><li>å¯¹ç¬¬<span class="math inline">\(i\)</span>ä¸ªå­èŠ‚ç‚¹ï¼Œä»¥<span class="math inline">\(D_i\)</span>ä¸ºè®­ç»ƒé›†ï¼Œä»¥<span class="math inline">\(A-\{A_g\}\)</span>ä¸ºç‰¹å¾é›†ï¼Œé€’å½’åœ°è°ƒç”¨å‰é¢çš„æ­¥éª¤ï¼Œå¾—åˆ°å­æ ‘<span class="math inline">\(T_i\)</span>ï¼Œè¿”å›<span class="math inline">\(T_i\)</span>ã€‚</li></ul></li></ul><h4 id="c4.5ç”Ÿæˆç®—æ³•">C4.5ç”Ÿæˆç®—æ³•</h4><p>C4.5ç”Ÿæˆç®—æ³•åº”ç”¨ä¿¡æ¯å¢ç›Šæ¯”æ¥é€‰æ‹©ç‰¹å¾ï¼Œå…¶ç®—æ³•æè¿°å¦‚ä¸‹ï¼š</p><ul><li>è¾“å…¥<ul><li>è®­ç»ƒæ•°æ®é›†<span class="math inline">\(D\)</span></li><li>ç‰¹å¾é›†<span class="math inline">\(A\)</span></li><li>ç‰¹å¾ä¿¡æ¯å¢ç›Šæ¯”çš„é˜ˆå€¼<span class="math inline">\(\varepsilon &gt;0\)</span></li></ul></li><li>è¾“å‡ºï¼šå†³ç­–æ ‘<span class="math inline">\(T\)</span></li><li>ç®—æ³•æ­¥éª¤<ul><li>è‹¥<span class="math inline">\(D\)</span>ä¸­æ‰€æœ‰å®ä¾‹å‡å±äºåŒä¸€ç±»<span class="math inline">\(c_k\)</span>ï¼Œåˆ™<span class="math inline">\(T\)</span>ä¸ºå•èŠ‚ç‚¹æ ‘ï¼Œå¹¶å°†<span class="math inline">\(c_k\)</span>ä½œä¸ºè¯¥èŠ‚ç‚¹çš„åæ ‡è®°ï¼Œè¿”å›<span class="math inline">\(T\)</span>ã€‚è¿™æ˜¯ä¸€ç§ç‰¹æ®Šæƒ…å†µï¼š<span class="math inline">\(D\)</span>çš„åˆ†ç±»é›†åˆåªæœ‰ä¸€ä¸ªåˆ†ç±»ã€‚</li><li>è‹¥<span class="math inline">\({A=\phi }\)</span>ï¼Œåˆ™<span class="math inline">\(T\)</span>ä¸ºå•èŠ‚ç‚¹æ ‘ï¼Œå°†<span class="math inline">\(D\)</span>ä¸­å®ä¾‹æ•°æœ€å¤§çš„ç±»<span class="math inline">\(c_k\)</span>ä½œä¸ºè¯¥èŠ‚ç‚¹çš„ç±»æ ‡è®°ï¼Œè¿”å›<span class="math inline">\(T\)</span>ï¼ˆå³å¤šæ•°è¡¨å†³ï¼‰ã€‚è¿™ä¹Ÿæ˜¯ä¸€ç§ç‰¹æ®Šæƒ…å†µï¼š<span class="math inline">\(D\)</span>çš„ç‰¹å¾é›†åˆä¸ºç©ºã€‚</li><li>å¦åˆ™è®¡ç®—<span class="math inline">\(g_R(D,A_i)\)</span>ï¼Œå…¶ä¸­<span class="math inline">\(A_i \in A\)</span>ä¸ºç‰¹å¾é›†åˆä¸­çš„å„ä¸ªç‰¹å¾ï¼Œé€‰æ‹©ä¿¡æ¯å¢ç›Šæ¯”æœ€å¤§çš„ç‰¹å¾<span class="math inline">\(A_g\)</span>ã€‚</li><li>åˆ¤æ–­<span class="math inline">\(A_g\)</span>çš„ä¿¡æ¯å¢ç›Šæ¯”<ul><li>è‹¥<span class="math inline">\({g_R(D,A_g)&lt;\varepsilon }\)</span>ï¼Œåˆ™ç½®<span class="math inline">\(T\)</span>ä¸ºå•èŠ‚ç‚¹æ ‘ï¼Œå°†<span class="math inline">\(D\)</span>ä¸­å®ä¾‹æ•°æœ€å¤§çš„ç±»<span class="math inline">\(c_k\)</span>ä½œä¸ºè¯¥èŠ‚ç‚¹çš„ç±»æ ‡è®°(å¤šæ•°è¡¨å†³)ï¼Œè¿”å›<span class="math inline">\(T\)</span>ã€‚</li><li>è‹¥<span class="math inline">\({g_R(D,A_g)â‰¥\varepsilon }\)</span>ï¼Œåˆ™å¯¹<span class="math inline">\(A_g\)</span>ç‰¹å¾å¯¹æ¯ä¸ªå¯èƒ½å–å€¼<span class="math inline">\(a_i\)</span>ï¼Œæ ¹æ®<span class="math inline">\(A_g=a_i\)</span>å°†<span class="math inline">\(D\)</span>åˆ’åˆ†ä¸ºè‹¥å¹²ä¸ªéç©ºå­é›†<span class="math inline">\(D_i\)</span>ï¼Œå°†<span class="math inline">\(D_i\)</span>ä¸­å®ä¾‹æ•°æœ€å¤§çš„ç±»ä½œä¸ºæ ‡è®°(å¤šæ•°è¡¨å†³)ï¼Œæ„å»ºå­èŠ‚ç‚¹ï¼Œç”±å­èŠ‚ç‚¹åŠå…¶å­èŠ‚ç‚¹æ„æˆæ ‘<span class="math inline">\(T\)</span>ï¼Œè¿”å›<span class="math inline">\(T\)</span>ã€‚</li></ul></li><li>å¯¹ç¬¬<span class="math inline">\(i\)</span>ä¸ªå­èŠ‚ç‚¹ï¼Œä»¥<span class="math inline">\(D_i\)</span>ä¸ºè®­ç»ƒé›†ï¼Œä»¥<span class="math inline">\(A-\{A_g\}\)</span>ä¸ºç‰¹å¾é›†ï¼Œé€’å½’åœ°è°ƒç”¨å‰é¢çš„æ­¥éª¤ï¼Œå¾—åˆ°å­æ ‘<span class="math inline">\(T_i\)</span>ï¼Œè¿”å›<span class="math inline">\(T_i\)</span>ã€‚</li></ul></li></ul><h4 id="è¯´æ˜">è¯´æ˜</h4><ul><li>C4.5ç®—æ³•ç»§æ‰¿äº†ID3ç®—æ³•çš„ä¼˜ç‚¹ï¼Œå¹¶åœ¨ä»¥ä¸‹å‡ æ–¹é¢å¯¹ID3ç®—æ³•è¿›è¡Œäº†æ”¹è¿›ï¼š<ul><li>ç”¨ä¿¡æ¯å¢ç›Šç‡æ¥é€‰æ‹©å±æ€§ï¼Œå…‹æœäº†ç”¨ä¿¡æ¯å¢ç›Šé€‰æ‹©å±æ€§æ—¶åå‘é€‰æ‹©å–å€¼å¤šçš„å±æ€§çš„ä¸è¶³</li><li>åœ¨æ ‘æ„é€ è¿‡ç¨‹ä¸­è¿›è¡Œå‰ªæ</li><li>èƒ½å¤Ÿå®Œæˆå¯¹è¿ç»­å±æ€§çš„ç¦»æ•£åŒ–å¤„ç†</li><li>èƒ½å¤Ÿå¯¹ä¸å®Œæ•´æ•°æ®è¿›è¡Œå¤„ç†</li></ul></li><li>C4.5ç®—æ³•ä¼˜ç‚¹ï¼šäº§ç”Ÿçš„åˆ†ç±»è§„åˆ™æ˜“äºç†è§£ï¼Œå‡†ç¡®ç‡è¾ƒé«˜ã€‚ç¼ºç‚¹ï¼šåœ¨æ„é€ æ ‘è¿‡ç¨‹ä¸­ï¼Œéœ€è¦å¯¹æ•°æ®é›†è¿›è¡Œå¤šæ¬¡å¯¹é¡ºåºæ‰«æå’Œæ’åºï¼Œå› è€Œå¯¼è‡´äº†ç®—æ³•çš„ä½æ•ˆã€‚æ­¤å¤–ï¼ŒC4.5åªé€‚åˆäºèƒ½å¤Ÿé©»ç•™äºå†…å­˜çš„æ•°æ®é›†ï¼Œå½“è®­ç»ƒé›†å¤§å¾—æ— æ³•åœ¨å†…å­˜å®¹çº³æ—¶ç¨‹åºæ— æ³•è¿è¡Œã€‚</li><li>å†³ç­–æ ‘å¯èƒ½åªæ˜¯ç”¨åˆ°ç‰¹å¾é›†ä¸­çš„éƒ¨åˆ†ç‰¹å¾</li><li>C4.5å’ŒID3ä¸¤ä¸ªç®—æ³•åªæœ‰æ ‘çš„ç”Ÿæˆç®—æ³•ï¼Œç”Ÿæˆçš„æ ‘å®¹æ˜“äº§ç”Ÿè¿‡æ‹Ÿåˆã€‚å³å¯¹è®­ç»ƒé›†åŒ¹é…å¾ˆå¥½ï¼Œä½†æ˜¯é¢„æµ‹æµ‹è¯•é›†æ•ˆæœè¾ƒå·®ã€‚</li></ul><h3 id="å†³ç­–æ ‘å‰ªæ">å†³ç­–æ ‘å‰ªæ</h3><p>å†³ç­–æ ‘éœ€è¦å‰ªæçš„åŸå› ï¼šå†³ç­–æ ‘ç”Ÿæˆç®—æ³•ç”Ÿæˆçš„æ ‘å¯¹è®­ç»ƒæ•°æ®çš„é¢„æµ‹å¾ˆå‡†ç¡®ï¼Œä½†æ˜¯å¯¹äºæœªçŸ¥çš„æ•°æ®åˆ†ç±»å´å¾ˆå·®ï¼Œè¿™å°±äº§ç”Ÿè¿‡æ‹Ÿåˆçš„ç°è±¡ã€‚å‘ç”Ÿè¿‡æ‹Ÿåˆæ˜¯ç”±äºå†³ç­–æ ‘å¤ªå¤æ‚ï¼Œè§£å†³è¿‡æ‹Ÿåˆçš„æ–¹æ³•å°±æ˜¯æ§åˆ¶æ¨¡å‹çš„å¤æ‚åº¦ï¼Œå¯¹äºå†³ç­–æ ‘æ¥è¯´å°±æ˜¯ç®€åŒ–æ¨¡å‹ï¼Œç§°ä¸ºå‰ªæã€‚</p><p>å†³ç­–æ ‘å‰ªæè¿‡ç¨‹æ˜¯ä»å·²ç”Ÿæˆçš„å†³ç­–æ ‘ä¸Šè£æ‰ä¸€äº›å­æ ‘æˆ–è€…å¶èŠ‚ç‚¹ã€‚å‰ªæçš„ç›®æ ‡æ˜¯é€šè¿‡æå°åŒ–å†³ç­–æ ‘çš„æ•´ä½“æŸå¤±å‡½æ•°æˆ–ä»£ä»·å‡½æ•°æ¥å®ç°çš„ã€‚</p><p>å†³ç­–æ ‘å‰ªæçš„ç›®çš„æ˜¯é€šè¿‡å‰ªææ¥æé«˜æ³›åŒ–èƒ½åŠ›ã€‚å‰ªæçš„æ€è·¯å°±æ˜¯ä¸­å†³ç­–æ ‘å¯¹è®­ç»ƒæ•°æ®çš„é¢„æµ‹è¯¯å·®å’Œæ•°æ®å¤æ‚åº¦ä¹‹é—´æ‰¾åˆ°ä¸€ä¸ªå¹³è¡¡ã€‚</p><p>è®¾æ ‘<span class="math inline">\(T\)</span>çš„å¶èŠ‚ç‚¹ä¸ªæ•°ä¸º<span class="math inline">\(|T_f|\)</span>ï¼Œ<span class="math inline">\(t\)</span>ä¸ºæ ‘çš„å¶èŠ‚ç‚¹ï¼Œè¯¥å¶èŠ‚ç‚¹æœ‰<span class="math inline">\(N_t\)</span>ä¸ªæ ·æœ¬ç‚¹ï¼Œå…¶ä¸­å±äº<span class="math inline">\(c_k\)</span>ç±»çš„æ ·æœ¬ç‚¹æœ‰<span class="math inline">\(N_tk\)</span>ï¼Œ<span class="math inline">\(k=1,2,â€¦,K\)</span>ä¸ªã€‚åˆ™æœ‰ï¼š<span class="math inline">\(\sum_{k=1}^KN_{tk}=N_t\)</span>ã€‚</p><p>ä»¤<span class="math inline">\(H(t)\)</span>ä¸ºå¶èŠ‚ç‚¹<span class="math inline">\(t\)</span>ä¸Šçš„ç»éªŒç†µï¼Œ<span class="math inline">\(\alpha â‰¥0\)</span>ä¸ºå‚æ•°ï¼Œåˆ™å†³ç­–æ ‘<span class="math inline">\(T\)</span>çš„æŸå¤±å‡½æ•°å®šä¹‰ä¸ºï¼š</p><p><span class="math display">\[C_{\alpha }(T)=\sum_{t=1}^{|T_f|}N_tH(t)+\alpha |T_f|H(t)=-\sum_{k=1}^K\frac{N_{tk}}{N_t}\log \frac{N_{tk}}{N_t}\]</span></p><p>ä»¤ï¼š</p><p><span class="math display">\[C(T)=\sum_{t=1}^{|T_f|}N_tH(t)=-\sum_{t=1}^{|T_f|}\sum_{k=1}^KN_{tk}\log \frac{N_{tk}}{N_t}\]</span></p><p>åˆ™ï¼š<span class="math inline">\(C_{\alpha }(T)=C(T)+\alpha |T_f|\)</span>ï¼Œå…¶ä¸­<span class="math inline">\(\alpha |T_f|\)</span>ä¸ºæ­£åˆ™åŒ–é¡¹ï¼Œ<span class="math inline">\(C(T)\)</span>è¡¨ç¤ºé¢„æµ‹è¯¯å·®ã€‚</p><ul><li><span class="math inline">\(C(T)=0\)</span>æ„å‘³ç€<span class="math inline">\(N_{tk}=N_t\)</span>ï¼Œå³æ¯ä¸ªèŠ‚ç‚¹<span class="math inline">\(t\)</span>å†…çš„æ ·æœ¬éƒ½æ˜¯çº¯çš„ï¼ˆå•ä¸€çš„åˆ†ç±»ï¼‰ã€‚</li><li>å†³ç­–æ ‘åˆ’åˆ†å¾—è¶Šç»†è‡´ï¼Œåˆ™<span class="math inline">\(T\)</span>çš„å¶å­èŠ‚ç‚¹è¶Šå¤šï¼Œ<span class="math inline">\(|T_f|\)</span>è¶Šå¤§ï¼›<span class="math inline">\(|T_f|\)</span>å°äºç­‰äºæ ·æœ¬é›†çš„æ•°é‡ï¼Œå½“å–ç­‰å·æ—¶ï¼Œæ ‘<span class="math inline">\(T\)</span>çš„æ¯ä¸ªå¶å­èŠ‚ç‚¹åªæœ‰ä¸€ä¸ªæ ·æœ¬ç‚¹ã€‚</li><li>å‚æ•°<span class="math inline">\(\alpha\)</span>æ§åˆ¶é¢„æµ‹è¯¯å·®ä¸æ¨¡å‹å¤æ‚åº¦ä¹‹é—´çš„å…³ç³»<ul><li>è¾ƒå¤§çš„<span class="math inline">\(\alpha\)</span>ä¼šé€‰æ‹©è¾ƒç®€å•çš„æ¨¡å‹</li><li>è¾ƒå°çš„<span class="math inline">\(\alpha\)</span>ä¼šé€‰æ‹©è¾ƒå¤æ‚çš„æ¨¡å‹</li><li><span class="math inline">\(\alpha =0\)</span>åªè€ƒè™‘è®­ç»ƒæ•°æ®ä¸æ¨¡å‹çš„æ‹Ÿåˆç¨‹åº¦ï¼Œä¸è€ƒè™‘æ¨¡å‹å¤æ‚åº¦</li></ul></li></ul><p>å‰ªæç®—æ³•æè¿°å¦‚ä¸‹ï¼š</p><ul><li>è¾“å…¥ï¼š<ul><li>ç”Ÿæˆæ ‘<span class="math inline">\(T\)</span></li><li>å‚æ•°<span class="math inline">\({\alpha}\)</span></li></ul></li><li>è¾“å‡ºï¼šå‰ªææ ‘<span class="math inline">\(T_{\alpha}\)</span></li><li>ç®—æ³•æ­¥éª¤å¦‚ä¸‹<ul><li>è®¡ç®—æ¯ä¸ªèŠ‚ç‚¹çš„ç»éªŒç†µ</li><li>é€’å½’åœ°ä»æ ‘çš„å¶èŠ‚ç‚¹å‘ä¸Šå›é€€<ul><li>è®¾ä¸€ç»„å¶èŠ‚ç‚¹å›é€€åˆ°çˆ¶èŠ‚ç‚¹ä¹‹å‰ä¸ä¹‹åçš„æ•´æ£µæ ‘åˆ†åˆ«ä¸º<span class="math inline">\(T_t\)</span>ä¸<span class="math inline">\(T_t&#39;\)</span>ï¼Œå¯¹åº”çš„æŸå¤±å‡½æ•°å€¼åˆ†åˆ«ä¸º<span class="math inline">\(C_{\alpha }(T_t)\)</span>ä¸<span class="math inline">\(C_{\alpha }(T_t&#39;)\)</span>ã€‚è‹¥<span class="math inline">\(C_{\alpha }(T_t&#39;)â‰¤C_{\alpha }(T_t)\)</span>ï¼Œåˆ™è¿›è¡Œå‰ªæå¹¶å°†çˆ¶èŠ‚ç‚¹å˜æˆæ–°çš„å¶èŠ‚ç‚¹ã€‚</li></ul></li><li>é€’å½’è¿›è¡Œä¸Šä¸€æ­¥ï¼Œç›´åˆ°ä¸èƒ½ç»§ç»­ä¸ºæ­¢ï¼Œå¾—åˆ°æŸå¤±å‡½æ•°æœ€å°çš„å­æ ‘<span class="math inline">\(T_{\alpha}\)</span></li></ul></li></ul><h2 id="cartç®—æ³•">CARTç®—æ³•</h2><p>åˆ†ç±»ä¸å›å½’æ ‘(Classfification And Regression Tree, CART)æ¨¡å‹ä¹Ÿæ˜¯ä¸€ç§å†³ç­–æ ‘æ¨¡å‹ï¼Œå®ƒå³å¯ç”¨äºåˆ†ç±»ï¼Œä¹Ÿå¯ç”¨äºå›å½’ã€‚å…¶å­¦ä¹ ç®—æ³•åˆ†ä¸ºä¸¤æ­¥ï¼š</p><ol type="1"><li>å†³ç­–æ ‘ç”Ÿæˆï¼šç”¨è®­ç»ƒæ¨¡å‹ç”Ÿæˆå†³ç­–æ ‘ï¼Œç”Ÿæˆæ ‘å°½å¯èƒ½åœ°å¤§</li><li>å†³ç­–æ ‘å‰ªæï¼šåŸºäºæŸå¤±å‡½æ•°æœ€å°åŒ–çš„æ ‡å‡†ï¼Œç”¨éªŒè¯æ•°æ®å¯¹ç”Ÿæˆçš„å†³ç­–æ ‘å‰ªæ</li></ol><p>åˆ†ç±»ä¸å›å½’æ ‘æ¨¡å‹é‡‡ç”¨ä¸åŒçš„æœ€ä¼˜åŒ–ç­–ç•¥ã€‚CARTå›å½’ç”Ÿæˆæ ‘ç”¨å¹³æ–¹è¯¯å·®æœ€å°åŒ–ç­–ç•¥ï¼ŒCARTåˆ†ç±»ç”Ÿæˆæ ‘é‡‡ç”¨åŸºå°¼æŒ‡æ•°æœ€å°åŒ–ç­–ç•¥ã€‚</p><h3 id="cartå›å½’æ ‘">CARTå›å½’æ ‘</h3><p>ç»™å®šè®­ç»ƒæ•°æ®é›†<span class="math inline">\(D=\{(\vec{x}_1,y_1),(\vec{x}_2,y_2),â€¦,(\vec{x}_N,y_N)\}\)</span>, <span class="math inline">\(y_i\in R\)</span>ã€‚è®¾å·²ç»å°†è¾“å…¥ç©ºé—´åˆ’åˆ†ä¸º<span class="math inline">\(M\)</span>ä¸ªå•å…ƒ<span class="math inline">\(R_1,R_2,â€¦,R_M\)</span>ï¼Œä¸”åœ¨å•å…ƒ<span class="math inline">\(R_m\)</span>ä¸Šè¾“å‡ºå€¼ä¸º<span class="math inline">\(c_m\)</span>, <span class="math inline">\(m=1,2,â€¦,M\)</span>ã€‚åˆ™å›å½’æ ‘æ¨¡å‹ä¸ºï¼š</p><p><span class="math display">\[f(\vec{x})=\sum_{m=1}^Mc_mI(\vec{x}\in R_m)\]</span></p><p>å…¶ä¸­ï¼Œ<span class="math inline">\(I(Â·)\)</span>ä¸ºç¤ºæ€§å‡½æ•°ã€‚</p><p>å¦‚æœç»™å®šè¾“å…¥ç©ºé—´çš„ä¸€ä¸ªåˆ’åˆ†ï¼Œåˆ™å›å½’æ ‘åœ¨è®­ç»ƒæ•°æ®é›†ä¸Šçš„è¯¯å·®ï¼ˆå¹³æ–¹è¯¯å·®ï¼‰ä¸ºï¼š</p><p><span class="math display">\[\sum_{\vec{x}_i\in R_m}(y_i-f(\vec{x}))^2\]</span></p><p>åŸºäºå¹³æ–¹è¯¯å·®æœ€å°çš„å‡†åˆ™ï¼Œå¯ä»¥æ±‚è§£å‡ºæ¯ä¸ªå•å…ƒä¸Šçš„æœ€ä¼˜è¾“å‡ºå€¼<span class="math inline">\(\hat{c}_m\)</span>ï¼š<span class="math inline">\(\hat{c}_m=ave(y_i | \vec{x}_i \in R_m)\)</span>ã€‚å®ƒå°±æ˜¯<span class="math inline">\(R_m\)</span>ä¸Šæ‰€æœ‰è¾“å…¥æ ·æœ¬å¯¹åº”çš„è¾“å‡º<span class="math inline">\(y_i\)</span>çš„å¹³å‡å€¼ã€‚</p><p>ç°åœ¨éœ€è¦æ‰¾åˆ°æœ€ä½³çš„åˆ’åˆ†ï¼Œä½¿å¾—è¯¥åˆ’åˆ†å¯¹åº”çš„å›å½’æ ‘çš„å¹³æ–¹è¯¯å·®åœ¨æ‰€æœ‰åˆ’åˆ†ä¸­æœ€å°ã€‚è®¾<span class="math inline">\(\vec{x}_i=(,x_i^{(1)},x_i^{(2)},â€¦,x_i^{(k)})\)</span>ï¼Œå³è¾“å…¥ä¸º<span class="math inline">\(k\)</span>ç»´ã€‚é€‰æ‹©ç¬¬<span class="math inline">\(j\)</span>ç»´<span class="math inline">\(x_i^{(j)}\)</span>ï¼Œå®ƒçš„å–å€¼<span class="math inline">\(s\)</span>ä½œä¸ºåˆ‡åˆ†å˜é‡å’Œåˆ‡åˆ†ç‚¹ã€‚å®šä¹‰ä¸¤ä¸ªåŒºåŸŸï¼š</p><p><span class="math display">\[R_1(j,s)=\{\vec{x}|x^{(j)}â‰¤s\} \\ R_2(j,s)=\{\vec{x}|x^{(j)}&gt;s\}\]</span></p><p>ç„¶åå¯»æ±‚æœ€ä¼˜åˆ‡åˆ†å˜é‡<span class="math inline">\(j\)</span>å’Œæœ€ä¼˜åˆ‡åˆ†ç‚¹<span class="math inline">\(s\)</span>ã€‚å³æ±‚è§£ï¼š</p><p><span class="math display">\[\min_{j,s}[\min_{c_1}\sum_{x_i\in R_1(j,s)}(y_i-c_1)^2+\min_{c_2}\sum_{x_i\in R_2(j,s)}(y_i-c_2)^2]\]</span></p><p>å¯¹äºç»™å®šçš„ç»´åº¦<span class="math inline">\(j\)</span>å¯ä»¥æ‰¾åˆ°æœ€ä¼˜åˆ‡åˆ†ç‚¹<span class="math inline">\(s\)</span>ã€‚åŒæ—¶:</p><p><span class="math display">\[\hat{c}_1=ave(y_i|\vec{x}_i\in R_1(j,s)) \\ \hat{c}_2=ave(y_i|\vec{x}_i\in R_2(j,s))\]</span></p><p>é—®é¢˜æ˜¯å¦‚ä½•æ±‚è§£<span class="math inline">\(j\)</span>ï¼šé¦–å…ˆéå†æ‰€æœ‰ç»´åº¦ï¼Œæ‰¾åˆ°æœ€ä¼˜åˆ‡åˆ†ç»´åº¦<span class="math inline">\(j\)</span>ï¼›ç„¶åå¯¹è¯¥ç»´åº¦æ‰¾åˆ°æœ€ä¼˜åˆ‡åˆ†ç‚¹<span class="math inline">\(s\)</span>æ„æˆä¸€ä¸ª<span class="math inline">\((j,s)\)</span>å¯¹ï¼Œå¹¶å°†è¾“å…¥ç©ºé—´åˆ’åˆ†ä¸ºä¸¤ä¸ªåŒºåŸŸã€‚ç„¶ååœ¨å­åŒºåŸŸä¸­é‡å¤åˆ’åˆ†è¿‡ç¨‹ï¼Œç›´åˆ°æ»¡è¶³åœæ­¢æ¡ä»¶ä¸ºæ­¢ã€‚è¿™æ ·çš„å›å½’æ ‘ç§°ä¸ºæœ€å°äºŒä¹˜å›å½’æ ‘ã€‚</p><p>æœ€å°äºŒä¹˜å›å½’æ ‘ç”Ÿæˆç®—æ³•æè¿°å¦‚ä¸‹ï¼š</p><ul><li>è¾“å…¥<ul><li>è®­ç»ƒæ•°æ®é›†<span class="math inline">\(D\)</span></li><li>åœæ­¢è®¡ç®—æ¡ä»¶</li></ul></li><li>è¾“å‡ºï¼šCARTå›å½’æ ‘<span class="math inline">\(f(\vec{x})\)</span></li><li>ç®—æ³•æ­¥éª¤<ul><li>é€‰æ‹©æ•°æ®é›†<span class="math inline">\(D\)</span>çš„æœ€ä¼˜åˆ‡åˆ†ç»´åº¦<span class="math inline">\(j\)</span>å’Œåˆ‡åˆ†ç‚¹<span class="math inline">\(s\)</span>ï¼Œå³æ±‚è§£ï¼š<span class="math display">\[\min_{j,s}[\min_{c_1}\sum_{x_i\in R_1(j,s)}(y_i-c_1)^2+\min_{c_2}\sum_{x_i\in R_2(j,s)}(y_i-c_2)^2]\]</span><ul><li>æ±‚è§£æ–¹æ³•ï¼šéå†<span class="math inline">\(j,s\)</span>æ‰¾åˆ°ä½¿ä¸Šå¼æœ€å°çš„<span class="math inline">\((j,s)\)</span>å¯¹</li></ul></li><li>ç”¨é€‰å®šçš„<span class="math inline">\((j,s)\)</span>åˆ’åˆ†åŒºåŸŸå¹¶å†³å®šç›¸åº”çš„è¾“å‡ºå€¼ï¼š<span class="math display">\[R_1(j,s)=\{\vec{x}|x^{(j)}â‰¤s\} \\ R_2(j,s)=\{\vec{x}|x^{(j)}&gt;s\} \\ \hat{c}_1=ave(y_i|\vec{x}_i\in R_1(j,s)) \\ \hat{c}_2=ave(y_i|\vec{x}_i\in R_2(j,s))\]</span></li><li>å¯¹å­åŒºåŸŸ<span class="math inline">\(R_1,R_2\)</span>é€’å½’åœ°è°ƒç”¨ä¸Šé¢ä¸¤æ­¥ï¼Œç›´åˆ°æ»¡è¶³åœæ­¢æ¡ä»¶ä¸ºæ­¢</li><li>å°†è¾“å…¥ç©ºé—´åˆ’åˆ†ä¸º<span class="math inline">\(M\)</span>ä¸ªåŒºåŸŸ<span class="math inline">\(R_1,R_2,â€¦,R_m\)</span>ï¼Œç”Ÿæˆå†³ç­–æ ‘ï¼š<span class="math display">\[f(\vec{x})=\sum_{m=1}^M\hat{c_m}I(\vec{x}\in R_m)\]</span></li></ul></li></ul><p>é€šå¸¸çš„åœæ­¢æ¡ä»¶ä¸ºä¸‹åˆ—æ¡ä»¶ä¹‹ä¸€ï¼š</p><ul><li>èŠ‚ç‚¹ä¸­æ ·æœ¬ä¸ªæ•°å°äºé¢„å®šå€¼</li><li>æ ·æœ¬é›†çš„å¹³æ–¹è¯¯å·®å°äºé¢„å®šå€¼</li><li>æ²¡æœ‰æ›´å¤šçš„ç‰¹å¾</li></ul><h3 id="cartåˆ†ç±»æ ‘">CARTåˆ†ç±»æ ‘</h3><p>å‡è®¾æœ‰<span class="math inline">\(K\)</span>ä¸ªåˆ†ç±»ï¼Œæ ·æœ¬ç‚¹å±äºç¬¬<span class="math inline">\(k\)</span>ç±»çš„æ¦‚ç‡ä¸º<span class="math inline">\(p_k=P(Y=c_k)\)</span>ã€‚å®šä¹‰æ¦‚ç‡åˆ†å¸ƒçš„åŸºå°¼æŒ‡æ•°ä¸ºï¼š</p><p><span class="math display">\[Gini(p)=\sum_{k=1}^Kp_k(1-p_k)=1-\sum_{k=1}^Kp_k^2\]</span></p><p>å¯¹äºç»™å®šçš„æ ·æœ¬é›†åˆ<span class="math inline">\(D\)</span>ï¼Œè®¾å±äºç±»<span class="math inline">\(c_k\)</span>çš„æ ·æœ¬å­é›†ä¸º<span class="math inline">\(C_k\)</span>ï¼Œåˆ™åŸºå°¼æŒ‡æ•°ä¸ºï¼š</p><p><span class="math display">\[Gini(D)=1-\sum_{k=1}^K(\frac{|C_k|}{|D|})^2\]</span></p><p>ç»™å®šç‰¹å¾<span class="math inline">\(A\)</span>,æ ¹æ®å…¶æ˜¯å¦å–æŸä¸€ä¸ªå¯èƒ½å€¼<span class="math inline">\(a\)</span>ï¼Œæ ·æœ¬é›†<span class="math inline">\(D\)</span>è¢«åˆ†ä¸ºä¸¤ä¸ªå­é›†<span class="math inline">\(D_1\)</span>å’Œ<span class="math inline">\(D_2\)</span>ï¼Œå…¶ä¸­ï¼š</p><p><span class="math display">\[D_1=\{(\vec{x},y)\in D|\vec{x}^{(A)}=a\}\\D_2=\{(\vec{x},y)\in D|\vec{x}^{(A)}â‰ a\}=D-D_1\]</span></p><p>å®šä¹‰<span class="math inline">\(Gini(D,A)\)</span>ï¼š</p><p><span class="math display">\[Gini(D,A)=\frac{|D_1|}{|D|}Gini(D_1)+\frac{|D_2|}{|D|}Gini(D_2)\]</span></p><p>å®ƒè¡¨ç¤ºåœ¨ç‰¹å¾<span class="math inline">\(A\)</span>çš„æ¡ä»¶ä¸‹ï¼Œé›†åˆ<span class="math inline">\(D\)</span>çš„åŸºå°¼æŒ‡æ•°ã€‚</p><p>å¯¹äºæœ€ç®€å•çš„äºŒé¡¹åˆ†å¸ƒï¼Œè®¾<span class="math inline">\(P(X=1)=p,P(X=0)=1-p\)</span>ï¼Œå…¶åŸºå°¼ç³»æ•°å’Œç†µä¸€æ ·ï¼Œä¹Ÿæ˜¯ç”¨äºåº¦é‡ä¸ç¡®å®šæ€§ã€‚å¯¹äºæ ·æœ¬é›†<span class="math inline">\(D\)</span>ï¼Œ<span class="math inline">\(Gini(D)\)</span>è¶Šå°è¯´æ˜æ ·æœ¬è¶Šå±äºåŒä¸€ç±»ã€‚</p><p>CARTåˆ†ç±»æ ‘é‡‡ç”¨åŸºå°¼æŒ‡æ•°é€‰æ‹©æœ€ä¼˜ç‰¹å¾ï¼ŒCARTåˆ†ç±»æ ‘çš„ç”Ÿæˆç®—æ³•å¦‚ä¸‹ï¼š</p><ul><li>è¾“å…¥<ul><li>è®­ç»ƒæ•°æ®é›†<span class="math inline">\(D\)</span></li><li>åœæ­¢è®¡ç®—æ¡ä»¶</li></ul></li><li>è¾“å‡ºï¼šCARTå†³ç­–æ ‘</li><li>ç®—æ³•æ­¥éª¤<ul><li>å¯¹æ¯ä¸ªç‰¹å¾<span class="math inline">\(A\)</span>ï¼Œä»¥åŠå®ƒå¯èƒ½çš„æ¯ä¸ªå€¼<span class="math inline">\(a\)</span>ï¼Œè®¡ç®—<span class="math inline">\(Gini(D,A)\)</span>ã€‚</li><li>é€‰å–æœ€ä¼˜ç‰¹å¾å’Œæœ€ä¼˜åˆ‡åˆ†ç‚¹ï¼šåœ¨æ‰€æœ‰ç‰¹å¾<span class="math inline">\(A\)</span>ä»¥åŠæ‰€æœ‰çš„åˆ‡åˆ†ç‚¹<span class="math inline">\(a\)</span>ä¸­ï¼ŒåŸºå°¼æŒ‡æ•°æœ€å°çš„<span class="math inline">\(A\)</span>å’Œ<span class="math inline">\(a\)</span>å°±æ˜¯æœ€ä¼˜ç‰¹å¾å’Œæœ€ä¼˜åˆ‡åˆ†ç‚¹ã€‚æ ¹æ®æœ€ä¼˜ç‰¹å¾å’Œæœ€ä¼˜åˆ‡åˆ†ç‚¹å°†è®­ç»ƒé›†<span class="math inline">\(D\)</span>åˆ‡åˆ†æˆä¸¤ä¸ªå­èŠ‚ç‚¹ã€‚</li><li>å¯¹ä¸¤ä¸ªå­èŠ‚ç‚¹é€’å½’è°ƒç”¨ä¸Šé¢ä¸¤æ­¥ï¼Œç›´åˆ°æ»¡è¶³åœæ­¢æ¡ä»¶ä¸ºæ­¢ã€‚</li><li>æœ€ç»ˆç”ŸæˆCARTå†³ç­–æ ‘ã€‚</li></ul></li></ul><p>é€šå¸¸çš„åœæ­¢æ¡ä»¶ä¸ºä¸‹åˆ—æ¡ä»¶ä¹‹ä¸€ï¼š</p><ul><li>èŠ‚ç‚¹ä¸­æ ·æœ¬ä¸ªæ•°å°äºé¢„å®šå€¼</li><li>æ ·æœ¬é›†çš„åŸºå°¼æŒ‡æ•°å°äºé¢„å®šå€¼</li><li>æ²¡æœ‰æ›´å¤šçš„ç‰¹å¾</li></ul><h3 id="cartå‰ªæ">CARTå‰ªæ</h3><p>CARTå‰ªææ˜¯ä»ç”Ÿæˆæ ‘å¼€å§‹å‰ªæ‰ä¸€äº›å­æ ‘ï¼Œä½¿å¾—å†³ç­–æ ‘å˜å°ã€‚å‰ªæè¿‡ç¨‹ç”±ä¸¤æ­¥ç»„æˆï¼ˆå‡è®¾åˆå§‹çš„ç”Ÿæˆæ ‘ä¸º<span class="math inline">\(T_0\)</span>ï¼‰ï¼š</p><ol type="1"><li>ä»<span class="math inline">\(T_0\)</span>å¼€å§‹ä¸æ–­å‰ªæï¼ŒçŸ¥é“å‰ªæˆä¸€æ£µå•èŠ‚ç‚¹çš„æ ‘ã€‚è¿™äº›å‰ªææ ‘å½¢æˆä¸€ä¸ªå‰ªææ ‘åºåˆ—<span class="math inline">\(\{T_0,T_1,â€¦,T_n\}\)</span>ã€‚</li><li>ä»è¿™ä¸ªå‰ªææ ‘åºåˆ—ä¸­æŒ‘é€‰å‡ºæœ€ä¼˜å‰ªææ ‘ã€‚æ–¹æ³•ï¼šé€šè¿‡äº¤å‰éªŒè¯æ³•ä½¿ç”¨éªŒè¯æ•°æ®é›†å¯¹å‰ªææ ‘åºåˆ—è¿›è¡Œæµ‹è¯•ã€‚</li></ol><p>ç»™å‡ºå†³ç­–æ ‘çš„æŸå¤±å‡½æ•°ä¸ºï¼š<span class="math inline">\({C_{\alpha }(T)=C(T)+\alpha |T|}\)</span>ã€‚å…¶ä¸­<span class="math inline">\({C(T)}\)</span>ä¸ºå†³ç­–æ ‘å¯¹è®­ç»ƒæ•°æ®çš„é¢„æµ‹è¯¯å·®ï¼›<span class="math inline">\({|T|}\)</span>ä¸ºå†³ç­–æ ‘çš„å¶èŠ‚ç‚¹ä¸ªæ•°ã€‚</p><p>å¯¹å›ºå®šçš„<span class="math inline">\(\alpha\)</span>ï¼Œå­˜åœ¨ä½¿<span class="math inline">\(C_{\alpha }(T)\)</span>æœ€å°çš„æ ‘ã€‚ä»¤å…¶ä¸º<span class="math inline">\(T_{\alpha}\)</span>ï¼Œå¯ä»¥è¯æ˜<span class="math inline">\(T_{\alpha}\)</span>æ˜¯å”¯ä¸€çš„ã€‚</p><ul><li>å½“<span class="math inline">\(\alpha\)</span>å¤§æ—¶ï¼Œ<span class="math inline">\(C_{\alpha }(T)\)</span>åå°ï¼ˆå³å†³ç­–æ ‘æ¯”è¾ƒç®€å•ï¼‰ã€‚</li><li>å½“<span class="math inline">\(\alpha\)</span>å°æ—¶ï¼Œ<span class="math inline">\(C_{\alpha }(T)\)</span>åå¤§ï¼ˆå³å†³ç­–æ ‘æ¯”è¾ƒå¤æ‚ï¼‰ã€‚</li><li>å½“<span class="math inline">\(\alpha =0\)</span>æ—¶ï¼Œç”Ÿæˆæ ‘å°±æ˜¯æœ€ä¼˜çš„ã€‚</li><li>å½“<span class="math inline">\(\alpha = âˆ\)</span>æ—¶ï¼Œæ ¹ç»„æˆçš„ä¸€ä¸ªå•èŠ‚ç‚¹æ ‘å°±æ˜¯æœ€ä¼˜çš„ã€‚</li></ul><p>è€ƒè™‘ç”Ÿæˆæ ‘<span class="math inline">\(T_0\)</span>ã€‚å¯¹<span class="math inline">\(T_0\)</span>å†…ä»»æ„èŠ‚ç‚¹<span class="math inline">\(t\)</span>ï¼Œä»¥<span class="math inline">\(t\)</span>ä¸ºå•èŠ‚ç‚¹æ ‘(è®°ä½œ<span class="math inline">\(\tilde{t}\)</span>)çš„æŸå¤±å‡½æ•°ä¸ºï¼š<span class="math inline">\(C_{\alpha}(\tilde{t})=C(\tilde{t})+\alpha\)</span>ï¼Œä»¥<span class="math inline">\(t\)</span>ä¸ºæ ¹çš„å­æ ‘<span class="math inline">\(T_t\)</span>çš„æŸå¤±å‡½æ•°ä¸ºï¼š<span class="math inline">\(C_{\alpha }(T_t)=C(T_t)+\alpha |T_t|\)</span>ã€‚å¯ä»¥è¯æ˜ï¼š</p><ul><li>å½“<span class="math inline">\(\alpha =0\)</span>åŠå……åˆ†å°æ—¶ï¼Œæœ‰<span class="math inline">\(C_{\alpha }(T_t)&lt;C_{\alpha}(\tilde{t})\)</span></li><li>å½“<span class="math inline">\(\alpha\)</span>å¢å¤§åˆ°æŸä¸ªå€¼æ—¶ï¼Œæœ‰<span class="math inline">\(C_{\alpha }(T_t)=C_{\alpha}(\tilde{t})\)</span></li><li>å½“<span class="math inline">\(\alpha\)</span>å†å¢å¤§æ—¶ï¼Œæœ‰<span class="math inline">\(C_{\alpha }(T_t)&gt;C_{\alpha}(\tilde{t})\)</span></li></ul><p>å› æ­¤ä»¤<span class="math inline">\(\alpha =\frac{C(\tilde{t})-C(T_t)}{|T_t|-1}\)</span>ï¼Œæ­¤æ—¶<span class="math inline">\(T_t\)</span>ä¸<span class="math inline">\(\tilde{t}\)</span>æœ‰ç›¸åŒçš„æŸå¤±å‡½æ•°å€¼ï¼Œä½†æ˜¯<span class="math inline">\(\tilde{t}\)</span>çš„å¶èŠ‚ç‚¹æ›´å°‘ã€‚äºæ˜¯å¯¹<span class="math inline">\(T_t\)</span>è¿›è¡Œå‰ªææˆä¸€æ£µå•èŠ‚ç‚¹æ ‘<span class="math inline">\(\tilde{t}\)</span>äº†ã€‚</p><p>å¯¹<span class="math inline">\(T_0\)</span>å†…éƒ¨å¯¹æ¯ä¸€ä¸ªèŠ‚ç‚¹<span class="math inline">\(t\)</span>ï¼Œå®šä¹‰<span class="math inline">\(g(t)=\frac{C(t)-C(T_t)}{|T_t|-1}\)</span>ã€‚è®¾<span class="math inline">\(T_0\)</span>å†…<span class="math inline">\(g(t)\)</span>æœ€å°çš„å­æ ‘ä¸º<span class="math inline">\(T_t^*\)</span>ï¼Œä»¤è¯¥æœ€å°å€¼çš„<span class="math inline">\(g(t)\)</span>ä¸º<span class="math inline">\(\tilde{\alpha}_1\)</span>ã€‚ä»<span class="math inline">\(T_0\)</span>å‰ªå»<span class="math inline">\(T_t^*\)</span>ï¼Œå³å¾—åˆ°å‰ªææ ‘<span class="math inline">\(T_1\)</span>ã€‚é‡å¤è¿™ç§è¿‡ç¨‹ï¼Œç›´åˆ°æ ¹èŠ‚ç‚¹å³å®Œæˆå‰ªæè¿‡ç¨‹ã€‚åœ¨æ­¤è¿‡ç¨‹ä¸­ä¸æ–­å¢åŠ <span class="math inline">\(\tilde{\alpha}_i\)</span>çš„å€¼ï¼Œä»è€Œç”Ÿæˆå‰ªææ ‘åºåˆ—ã€‚</p><p>CARTå‰ªæäº¤å‰éªŒè¯è¿‡ç¨‹æ˜¯é€šè¿‡éªŒè¯æ•°æ®é›†æ¥æµ‹è¯•å‰ªææ ‘åºåˆ—<span class="math inline">\(\{T_0,T_1,â€¦,T_n\}\)</span>ä¸­å„å‰ªææ ‘çš„ã€‚å¯¹äºCARTå›å½’æ ‘ï¼Œæ˜¯è€ƒå¯Ÿå‰ªææ ‘çš„å¹³æ–¹è¯¯å·®ï¼Œå¹³æ–¹è¯¯å·®æœ€å°çš„å†³ç­–æ ‘è¢«è®¤ä¸ºæ˜¯æœ€ä¼˜å†³ç­–æ ‘ã€‚å¯¹åº”CARTåˆ†ç±»æ ‘ï¼Œæ˜¯è€ƒå¯Ÿå‰ªææ ‘çš„åŸºå°¼æŒ‡æ•°ï¼ŒåŸºå°¼æŒ‡æ•°æœ€å°çš„å†³ç­–æ ‘è¢«è®¤ä¸ºæ˜¯æœ€ä¼˜å†³ç­–æ ‘ã€‚</p><p>CARTå‰ªæç®—æ³•çš„æè¿°å¦‚ä¸‹ï¼š</p><ul><li>è¾“å…¥ï¼šCARTç”Ÿæˆæ ‘<span class="math inline">\(T_0\)</span></li><li>è¾“å‡ºï¼šCARTå‰ªææ ‘<span class="math inline">\(T_{\alpha}\)</span></li><li>ç®—æ³•æ­¥éª¤<ul><li>ä»¤<span class="math inline">\(k=0,T=T_0,\alpha =âˆ\)</span></li><li>è‡ªä¸‹è€Œä¸Šåœ°å¯¹æ ‘<span class="math inline">\(T\)</span>å„å†…éƒ¨èŠ‚ç‚¹<span class="math inline">\(t\)</span>è®¡ç®—<span class="math inline">\(g(t)=\frac{C(t)-C(T_t)}{|T_t|-1}\)</span></li><li>å¯¹æ‰€æœ‰çš„å†…éƒ¨èŠ‚ç‚¹ï¼Œ<span class="math inline">\(\tilde{\alpha}_{k+1}=\min_t(g(t))\)</span>ï¼Œä»¤<span class="math inline">\(t^*=\arg \min_t(g(t))\)</span>ã€‚å¯¹å†…éƒ¨èŠ‚ç‚¹<span class="math inline">\(t^*\)</span>è¿›è¡Œå‰ªæå¾—åˆ°æ ‘<span class="math inline">\(T_{k+1}\)</span></li><li>ä»¤<span class="math inline">\(T=T_{k+1},k=k+1\)</span></li><li>è‹¥<span class="math inline">\(T\)</span>ä¸æ˜¯ç”±æ ¹èŠ‚ç‚¹å•ç‹¬æ„æˆçš„æ ‘ï¼Œåˆ™ç»§ç»­å‰é¢çš„æ­¥éª¤</li><li>é‡‡ç”¨äº¤å‰éªŒè¯æ³•åœ¨å‰ªææ ‘åºåˆ—<span class="math inline">\(T_0,T_1,â€¦,T_n\)</span>ä¸­é€‰å–æœ€ä¼˜å‰ªææ ‘<span class="math inline">\(T_{\alpha}\)</span></li></ul></li></ul><h2 id="è¿ç»­å€¼å’Œç¼ºå¤±å€¼çš„å¤„ç†">è¿ç»­å€¼å’Œç¼ºå¤±å€¼çš„å¤„ç†</h2><h3 id="è¿ç»­å€¼">è¿ç»­å€¼</h3><p>å­¦ä¹ ä»»åŠ¡ä¸­å¸¸å¸¸ä¼šé‡åˆ°è¿ç»­ç‰¹å¾ï¼Œå¦‚ä¸ªäººèº«é«˜ã€ä½“é‡ç­‰ç‰¹å¾å–å€¼å°±æ˜¯è¿ç»­å€¼ã€‚å¯ä»¥é€šè¿‡äºŒåˆ†æ³•(bi-partition)å¯¹è¿ç»­ç‰¹å¾è¿›è¡Œç¦»æ•£åŒ–å¤„ç†ã€‚</p><p>ç»™å®šæ ·æœ¬é›†<span class="math inline">\(D\)</span>å’Œè¿ç»­ç‰¹å¾<span class="math inline">\(A\)</span>ï¼Œå‡è®¾è¯¥ç‰¹å¾åœ¨<span class="math inline">\(D\)</span>ä¸Šå¯¹å–å€¼ä»å°åˆ°å¤§è¿›è¡Œæ’åˆ—ä¸º<span class="math inline">\(a_1,a_2,â€¦,a_M\)</span>ã€‚å¯ä»¥é€‰å–<span class="math inline">\(M-1\)</span>ä¸ªåˆ’åˆ†ç‚¹ï¼Œä¾æ¬¡ä¸ºï¼š<span class="math inline">\(\frac{a_1+a_2}{2},\frac{a_2+a_3}{2},â€¦,\frac{a_{M-1}+a_M}{2}\)</span>ã€‚ç„¶åå°±å¯ä»¥åƒç¦»æ•£ç‰¹å¾ä¸€æ ·æ¥è€ƒå¯Ÿè¿™äº›åˆ’åˆ†ç‚¹ï¼Œé€‰å–æœ€ä¼˜çš„åˆ’åˆ†ç‚¹è¿›è¡Œæ ·æœ¬é›†åˆçš„åˆ’åˆ†ã€‚è¿™ä¹Ÿæ˜¯C4.5ç®—æ³•é‡‡å–çš„æ–¹æ¡ˆã€‚</p><h3 id="ç¼ºå¤±å€¼">ç¼ºå¤±å€¼</h3><p>å­¦ä¹ ä»»åŠ¡ä¸­é‡åˆ°ä¸å®Œæ•´æ ·æœ¬ï¼Œå³æŸäº›æ ·æœ¬çš„æŸäº›ç‰¹å¾çš„å–å€¼ç¼ºå¤±ã€‚å¦‚æœç®€å•åœ°ä¸¢æ‰è¿™äº›ä¸å®Œæ•´çš„æ ·æœ¬å¯èƒ½ä¼šæµªè´¹å¤§é‡æœ‰æ•ˆçš„ä¿¡æ¯ã€‚</p><p>ç»™å®šè®­ç»ƒé›†<span class="math inline">\(D\)</span>å’Œç‰¹å¾<span class="math inline">\(A\)</span>ï¼Œä»¤<span class="math inline">\(\tilde{D}\)</span>è¡¨ç¤º<span class="math inline">\(D\)</span>ä¸­åœ¨ç‰¹å¾<span class="math inline">\(A\)</span>ä¸Šæ²¡æœ‰ç¼ºå¤±çš„æ ·æœ¬å­é›†ã€‚å‡å®šç‰¹å¾<span class="math inline">\(A\)</span>æœ‰<span class="math inline">\(M\)</span>ä¸ªå¯å–å€¼<span class="math inline">\(a_1,a_2,â€¦,a_M\)</span>ï¼Œä»¤<span class="math inline">\(\tilde{D}^i\)</span>è¡¨ç¤º<span class="math inline">\(\tilde{D}\)</span>ä¸­æœ€ç‰¹å¾<span class="math inline">\(A\)</span>ä¸Šå–å€¼ä¸º<span class="math inline">\(a_i\)</span>çš„æ ·æœ¬çš„å­é›†ï¼Œ<span class="math inline">\(\tilde{D}_k\)</span>è¡¨ç¤º<span class="math inline">\(\tilde{D}\)</span>ä¸­å±äºç¬¬<span class="math inline">\(k\)</span>ç±»çš„æ ·æœ¬å­é›†ï¼ˆä¸€å…±æœ‰<span class="math inline">\(K\)</span>ä¸ªåˆ†ç±»ï¼‰ï¼Œåˆ™æœ‰ï¼š</p><p><span class="math display">\[\tilde{D}=\bigcup_{k=1}^K\tilde{D}_k=\bigcup_{i=1}^M\tilde{D}^i\]</span></p><p>å‡å®šä¸ºæ¯ä¸ªæ ·æœ¬<span class="math inline">\(\vec{x}\)</span>èµ‹äºˆä¸€ä¸ªæƒé‡<span class="math inline">\(w_{\vec{x}}\)</span>ï¼Œå®šä¹‰ï¼š</p><p><span class="math display">\[\rho =\frac{\sum_{\vec{x}\in \hat{D}}w_{\vec{x}}}{\sum_{\vec{x}\in D}w_{\vec{x}}} \\ \tilde{p}_k=\frac{\sum_{\vec{x}\in \tilde{D}_k}w_{\vec{x}}}{\sum_{\vec{x}\in \tilde{D}}w_{\vec{x}}},k=1,2,â€¦,K \\ \tilde{r}_i=\frac{\sum_{\vec{x}\in \tilde{D}^i}w_{\vec{x}}}{\sum_{\vec{x}\in \tilde{D}}w_{\vec{x}}},i=1,2,â€¦,M\]</span></p><p>å…¶ç‰©ç†æ„ä¹‰å¦‚ä¸‹ï¼š</p><ul><li><span class="math inline">\(\rho\)</span>ï¼šè¡¨ç¤ºæ— ç¼ºå¤±å€¼æ ·æœ¬å æ€»ä½“æ ·æœ¬çš„æ¯”ä¾‹</li><li><span class="math inline">\(\tilde{p}_k\)</span>ï¼šè¡¨ç¤ºæ— ç¼ºå¤±å€¼æ ·æœ¬ä¸­ï¼Œç¬¬<span class="math inline">\(k\)</span>ç±»æ‰€å çš„æ¯”ä¾‹</li><li><span class="math inline">\(\tilde{r}_i\)</span>ï¼šè¡¨ç¤ºæ— ç¼ºå¤±å€¼æ ·æœ¬ä¸­ï¼Œåœ¨ç‰¹å¾<span class="math inline">\(A\)</span>ä¸Šå–å€¼ä¸º<span class="math inline">\(a_i\)</span>çš„æ ·æœ¬æ‰€å çš„æ¯”ä¾‹</li></ul><p>äºæ˜¯å¯ä»¥å°†ä¿¡æ¯å¢ç›Šçš„è®¡ç®—å…¬å¼ä¿®æ­£ä¸ºï¼š</p><p><span class="math display">\[g(D,A)=\rho \times g(\tilde{D},A)=\rho \times \lgroup H(\tilde{D})-\sum_{i=1}^M\tilde{r}_iH(\tilde{D}^i)\rgroup\]</span></p><p>å…¶ä¸­ï¼Œ<span class="math inline">\(H(\tilde{D})=-\sum_{k=1}^K\tilde{p}_k\log \tilde{p}_k\)</span>ã€‚</p><p>åœ¨é€šè¿‡ç‰¹å¾<span class="math inline">\(A\)</span>åˆ’åˆ†æ ·æœ¬<span class="math inline">\(\vec{x}\)</span>æ—¶ï¼Œè®©å®ƒä»¥ä¸åŒçš„æ¦‚ç‡åˆ†æ•£åˆ°ä¸åŒçš„å­èŠ‚ç‚¹ä¸­å»ï¼š</p><ul><li>å¦‚æœæ ·æœ¬åœ¨åˆ’åˆ†ç‰¹å¾ä¸Šçš„å–å€¼å·²çŸ¥ï¼Œåˆ™å°†å®ƒåˆ’å…¥ä¸å…¶å¯¹åº”çš„å­èŠ‚ç‚¹ï¼Œä¸”æƒå€¼åœ¨å­èŠ‚ç‚¹ä¸­ä¿æŒä¸º<span class="math inline">\(w_{\vec{x}}\)</span></li><li>å¦‚æœæ ·æœ¬åœ¨åˆ’åˆ†ç‰¹å¾ä¸Šçš„å–å€¼ç¼ºå¤±ï¼Œåˆ™å°†å®ƒåŒæ—¶åˆ’å…¥æ‰€æœ‰çš„å­èŠ‚ç‚¹ï¼Œä¸”åœ¨å­èŠ‚ç‚¹ä¸­è¯¥æ ·æœ¬çš„æƒå€¼è¿›è¡Œè°ƒæ•´ï¼šåœ¨ç‰¹å¾å–å€¼ä¸º<span class="math inline">\(a_i\)</span>å¯¹åº”çš„å­èŠ‚ç‚¹ä¸­ï¼Œè¯¥æ ·æœ¬çš„æƒå€¼è°ƒæ•´ä¸º<span class="math inline">\(\tilde{r}_i \times w_{\vec{x}}\)</span></li></ul><h1 id="pythonå®æˆ˜">Pythonå®æˆ˜</h1><p>scikit-learnä¸­æœ‰ä¸¤ç±»å†³ç­–æ ‘ï¼Œå‡é‡‡ç”¨ä¼˜åŒ–çš„CARTå†³ç­–æ ‘ç®—æ³•ã€‚</p><h2 id="å›å½’å†³ç­–æ ‘decisiontreeregressor">å›å½’å†³ç­–æ ‘(DecisionTreeRegressor)</h2><p>DecisionTreeRegressorå®ç°äº†å›å½’å†³ç­–æ ‘ï¼Œç”¨äºå›å½’é—®é¢˜ï¼š</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">class.sklearn.tree.DecisionTreeRegressor(criterion=&quot;mse&quot;,</span><br><span class="line">                 splitter=&quot;best&quot;,</span><br><span class="line">                 max_depth=None,</span><br><span class="line">                 min_samples_split=2,</span><br><span class="line">                 min_samples_leaf=1,</span><br><span class="line">                 min_weight_fraction_leaf=0.,</span><br><span class="line">                 max_features=None,</span><br><span class="line">                 random_state=None,</span><br><span class="line">                 max_leaf_nodes=None,</span><br><span class="line">                 min_impurity_decrease=0.,</span><br><span class="line">                 min_impurity_split=None,</span><br><span class="line">                 presort=False)</span><br></pre></td></tr></table></figure><p>å‚æ•°</p><ul><li>criterionï¼šå­—ç¬¦ä¸²ï¼ŒæŒ‡å®šåˆ‡åˆ†è´¨é‡çš„è¯„ä»·å‡†åˆ™ã€‚é»˜è®¤ä¸º'mse'ï¼Œä¸”åªæ”¯æŒè¯¥å­—ç¬¦ä¸²ï¼Œè¡¨ç¤ºå‡æ–¹è¯¯å·®ã€‚</li><li>splitterï¼šå­—ç¬¦ä¸²ï¼ŒæŒ‡å®šåˆ‡åˆ†åŸåˆ™<ul><li>'best'ï¼šé€‰æ‹©æœ€ä¼˜çš„åˆ‡åˆ†</li><li>'random'ï¼šéšæœºåˆ‡åˆ†</li></ul></li><li>max_depthï¼šæŒ‡å®šæ ‘çš„æœ€å¤§æ·±åº¦<ul><li>Noneï¼šè¡¨ç¤ºæ ‘çš„æ·±åº¦ä¸é™ï¼Œç›´åˆ°æ¯ä¸ªå¶å­éƒ½æ˜¯çº¯çš„ï¼Œå³å¶èŠ‚ç‚¹ä¸­æ‰€æœ‰æ ·æœ¬ç‚¹éƒ½å±äºä¸€ä¸ªç±»ï¼Œæˆ–è€…å¶å­ä¸­åŒ…å«å°äºmin_samples_splitä¸ªæ ·æœ¬ç‚¹</li></ul></li><li>min_samples_splitï¼šæ•´æ•°ï¼ŒæŒ‡å®šæ¯ä¸ªå†…éƒ¨èŠ‚ç‚¹ï¼ˆéå¶èŠ‚ç‚¹ï¼‰åŒ…å«çš„æœ€å°‘çš„æ ·æœ¬æ•°</li><li>min_samples_leafï¼šæ•´æ•°ï¼ŒæŒ‡å®šæ¯ä¸ªå¶èŠ‚ç‚¹åŒ…å«çš„æœ€å°‘æ ·æœ¬æ•°</li><li>min_weight_fraction_leafï¼šæµ®ç‚¹æ•°ï¼Œå¶èŠ‚ç‚¹ä¸­æ ·æœ¬çš„æœ€å°æƒé‡ç³»æ•°</li><li>max_featuresï¼šæŒ‡å®šå¯»æ‰¾best splitæ—¶è€ƒè™‘çš„ç‰¹å¾æ•°é‡ã€‚å¦‚æœå·²ç»è€ƒè™‘äº†max_featuresä¸ªç‰¹å¾ï¼Œä½†æ˜¯è¿˜æ²¡æœ‰æ‰¾åˆ°ä¸€ä¸ªæœ‰æ•ˆçš„åˆ‡åˆ†ï¼Œé‚£ä¹ˆè¿˜ä¼šç»§ç»­å¯»æ‰¾ä¸‹ä¸€ç‰¹å¾ï¼Œç›´åˆ°æ‰¾åˆ°ä¸€ä¸ªæœ‰æ•ˆçš„åˆ‡åˆ†ä¸ºæ­¢ã€‚<ul><li>æ•´æ•°ï¼šæ¯æ¬¡åˆ‡åˆ†åªè€ƒè™‘max_featuresä¸ªç‰¹å¾</li><li>æµ®ç‚¹æ•°ï¼šæ¯æ¬¡åˆ‡åˆ†åªè€ƒè™‘max_features * n_featuresä¸ªç‰¹å¾ï¼ˆmax_featuresæŒ‡å®šäº†ç™¾åˆ†æ¯”ï¼‰</li><li>'auto' æˆ–è€… 'sqrt'ï¼šmax_features = n_features</li><li>'log2'ï¼šmax_features = log2(n_features)</li><li>Noneï¼šmax_features = n_features</li></ul></li><li>random_state: ä¸€ä¸ªæ•´æ•°æˆ–è€…ä¸€ä¸ªRandomStateå®ä¾‹ï¼Œæˆ–è€…None<ul><li>å¦‚æœä¸ºæ•´æ•°ï¼Œåˆ™å®ƒæŒ‡å®šäº†éšæœºæ•°ç”Ÿæˆå™¨çš„ç§å­</li><li>å¦‚æœä¸ºRandomStateå®ä¾‹ï¼Œåˆ™æŒ‡å®šä¾‹éšæœºæ•°ç”Ÿæˆå™¨</li><li>å¦‚æœä¸ºNoneï¼Œåˆ™ä½¿ç”¨é»˜è®¤çš„éšæœºæ•°ç”Ÿæˆå™¨</li></ul></li><li>max_leaf_nodesï¼šæŒ‡å®šå¶èŠ‚ç‚¹çš„æœ€å¤§æ•°é‡<ul><li>Noneï¼šæ­¤æ—¶å¶èŠ‚ç‚¹æ•°é‡ä¸é™</li><li>æ•´æ•°ï¼šåˆ™max_depthè¢«å¿½ç•¥</li></ul></li><li>presortï¼šbooleanï¼ŒæŒ‡å®šæ˜¯å¦è¦æå‰æ’åºæ•°æ®ä»è€ŒåŠ é€Ÿå¯»æ‰¾æœ€ä¼˜åˆ‡åˆ†çš„è¿‡ç¨‹ã€‚è®¾ç½®ä¸ºTrueæ—¶ï¼Œå¯¹äºå¤§æ•°æ®é›†ä¼šå‡æ…¢æ€»ä½“çš„è®­ç»ƒè¿‡ç¨‹ï¼Œä½†æ˜¯å¯¹äºä¸€ä¸ªå°æ•°æ®é›†æˆ–è€…è®¾å®šäº†æœ€å¤§æ·±åº¦çš„æƒ…å†µä¸‹ï¼Œåˆ™ä¼šåŠ é€Ÿè®­ç»ƒè¿‡ç¨‹</li><li>class_weightï¼šä¸€ä¸ªå­—å…¸ã€å­—å…¸çš„åˆ—è¡¨ã€'balance'æˆ–è€…Noneï¼ŒæŒ‡å®šäº†åˆ†ç±»çš„æƒé‡ã€‚å½¢å¼ï¼š{class_label: weight}ã€‚å¦‚æœæä¾›äº†sample_weightå‚æ•°ï¼ˆfitæ–¹æ³•æä¾›ï¼‰ï¼Œåˆ™è¿™äº›æƒé‡éƒ½ä¼šä¹˜ä»¥sample_weightã€‚<ul><li>Noneï¼šæ¯ä¸ªåˆ†ç±»æƒé‡éƒ½ä¸º1</li><li>'balance'ï¼šåˆ†ç±»çš„æƒé‡æ˜¯æ ·æœ¬ä¸­å„åˆ†ç±»å‡ºç°çš„é¢‘ç‡çš„åæ¯”</li></ul></li></ul><p>å±æ€§</p><ul><li>feature_importances_ï¼šç»™å‡ºç‰¹å¾çš„é‡è¦ç¨‹åº¦ã€‚è¯¥å€¼è¶Šé«˜ï¼Œåˆ™è¯¥ç‰¹å¾è¶Šé‡è¦ã€‚ï¼ˆGini importanceï¼‰</li><li>max_features_ï¼šmax_featuresçš„æ¨æ–­å€¼</li><li>n_features_ï¼šå½“æ‰§è¡Œfitä¹‹åï¼Œç‰¹å¾çš„æ•°é‡</li><li>n_outputs_ï¼šå½“æ‰§è¡Œfitä¹‹åï¼Œè¾“å‡ºçš„æ•°é‡</li><li>tree_ï¼šä¸€ä¸ªTreeå¯¹è±¡ï¼Œå³åº•å±‚çš„å†³ç­–æ ‘</li></ul><p>æ–¹æ³•</p><ul><li>fit(X, y[, sample_weight, check_input, â€¦]): è®­ç»ƒæ¨¡å‹</li><li>predict(X[, check_input]): ç”¨æ¨¡å‹è¿›è¡Œé¢„æµ‹ï¼Œè¿”å›é¢„æµ‹å€¼</li><li>score(X, y[, sample_weight]): è¿”å›é¢„æµ‹æ€§èƒ½å¾—åˆ†<ul><li>è®¾é¢„æµ‹é›†ä¸º<span class="math inline">\(T_{test}\)</span>ï¼ŒçœŸå®å€¼ä¸º<span class="math inline">\(y_i\)</span>ï¼ŒçœŸå®å€¼çš„å‡å€¼ä¸º<span class="math inline">\(\overline{y}\)</span>ï¼Œé¢„æµ‹å€¼ä¸º<span class="math inline">\(\hat{y}_i\)</span>ï¼Œåˆ™ï¼š<span class="math display">\[score=1-\frac{\sum_{T_{test}}(y_i-\hat{y}_i)^2}{(y_i-\overline{y})^2}\]</span><ul><li>scoreä¸è¶…è¿‡1ï¼Œä½†æ˜¯å¯èƒ½ä¸ºè´Ÿå€¼ï¼ˆé¢„æµ‹æ•ˆæœå¤ªå·®ï¼‰ã€‚</li><li>scoreè¶Šå¤§ï¼Œé¢„æµ‹æ€§èƒ½è¶Šå¥½ã€‚</li></ul></li></ul></li></ul><p>é¦–å…ˆå¯¼å…¥åŒ…</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">import numpy as np</span><br><span class="line">from sklearn.tree import DecisionTreeRegressor</span><br><span class="line">from sklearn import model_selection</span><br></pre></td></tr></table></figure><p>ç»™å‡ºä¸€ä¸ªéšæœºäº§ç”Ÿçš„æ•°æ®é›†</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">def create_data(n):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    éšæœºäº§ç”Ÿæ•°æ®é›†</span><br><span class="line">    :param n: æ•°æ®é›†å®¹é‡</span><br><span class="line">    :return: ä¸€ä¸ªå…ƒç»„ï¼šè®­ç»ƒæ ·æœ¬é›†ã€æµ‹è¯•æ ·æœ¬é›†ã€è®­ç»ƒæ ·æœ¬é›†å¯¹åº”çš„å€¼ã€æµ‹è¯•æ ·æœ¬é›†å¯¹åº”çš„å€¼</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    np.random.seed(0)</span><br><span class="line">    X = 5 * np.random.rand(n, 1)</span><br><span class="line">    y = np.sin(X).ravel()</span><br><span class="line">    noise_num = int(n / 5)</span><br><span class="line">    y[::5] += 3 * (0.5 - np.random.rand(noise_num))</span><br><span class="line">    return model_selection.train_test_split(X, y, test_size=0.25, random_state=1)</span><br></pre></td></tr></table></figure><p>create_dataå‡½æ•°äº§ç”Ÿçš„æ•°æ®é›†æ˜¯åœ¨sin(x)å‡½æ•°åŸºç¡€ä¸Šæ·»åŠ äº†è‹¥å¹²ä¸ªéšæœºå™ªå£°äº§ç”Ÿçš„ã€‚xæ˜¯éšæœºåœ¨0ï½1ä¹‹é—´äº§ç”Ÿçš„ï¼Œyæ˜¯sin(x)ï¼Œå…¶ä¸­yæ¯éš”5ä¸ªç‚¹æ·»åŠ ä¸€ä¸ªéšæœºå™ªå£°ã€‚ç„¶åå°†æ•°æ®é›†éšæœºåˆ‡åˆ†æˆè®­ç»ƒé›†å’Œæµ‹è¯•é›†ã€‚æŒ‡å®šæµ‹è¯•é›†æ ·æœ¬å¤§å°ä¸ºåŸæ ·æœ¬ç‚¹0.25å€ã€‚</p><p>ç„¶åç»™å‡ºæµ‹è¯•å‡½æ•°</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">def demo_DecisionTreeRegressor(*data):</span><br><span class="line">    X_train, X_test, y_train, y_test = data</span><br><span class="line">    regr = DecisionTreeRegressor()</span><br><span class="line">    regr.fit(X_train, y_train)</span><br><span class="line">    print(&quot;Training score: %f&quot; % regr.score(X_train, y_train))</span><br><span class="line">    print(&quot;Testing score: %f&quot; % regr.score(X_test, y_test))</span><br><span class="line">    # ç»˜å›¾</span><br><span class="line">    fig = plt.figure()</span><br><span class="line">    ax = fig.add_subplot(1, 1, 1)</span><br><span class="line">    X = np.arange(0.0, 5.0, 0.01)[:, np.newaxis]</span><br><span class="line">    Y = regr.predict(X)</span><br><span class="line">    ax.scatter(X_train, y_train, label=&quot;train sample&quot;, c=&apos;g&apos;)</span><br><span class="line">    ax.scatter(X_test, y_test, label=&quot;test sample&quot;, c=&apos;r&apos;)</span><br><span class="line">    ax.plot(X, Y, label=&quot;predict_value&quot;, linewidth=2, alpha=0.5)</span><br><span class="line">    ax.set_xlabel(&quot;data&quot;)</span><br><span class="line">    ax.set_ylabel(&quot;target&quot;)</span><br><span class="line">    ax.set_title(&quot;Decision Tree Regression&quot;)</span><br><span class="line">    ax.legend(framealpha=0.5)</span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure><p>åœ¨demo_DecisionTreeRegressorä¸­ï¼Œç»™å‡ºäº†å¯¹xä¸Šæ¯ä¸ªç‚¹çš„é¢„æµ‹å€¼ï¼ˆè€ƒè™‘åˆ°è¿ç»­å€¼æœ‰æ— ç©·å¤šï¼Œé‡‡å–çš„æ–¹å¼æ˜¯[0, 5]ä¹‹é—´ï¼Œæ­¥é•¿ä¸º0.01ï¼‰ã€‚è°ƒç”¨è¯¥å‡½æ•°ï¼š</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">X_train, X_test, y_train, y_test = create_data(100)</span><br><span class="line">demo_DecisionTreeRegressor(X_train, X_test, y_train, y_test)</span><br></pre></td></tr></table></figure><p>è¾“å‡ºå¦‚ä¸‹ï¼š</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Training score: 1.000000</span><br><span class="line">Testing score: 0.789107</span><br></pre></td></tr></table></figure><p><img src="/images/MachineLearning/DecisionTree/20190726_ML_DecisionTreeRegressor.png"></p><p>å¯ä»¥çœ‹åˆ°å¯¹äºè®­ç»ƒæ ·æœ¬çš„æ‹Ÿåˆç›¸å½“å¥½ï¼Œä½†æ˜¯å¯¹äºæµ‹è¯•æ ·æœ¬çš„æ‹Ÿåˆå°±å·®å¼ºäººæ„ã€‚</p><p>æ¥ä¸‹æ¥ï¼Œæ£€éªŒéšæœºåˆ’åˆ†ä¸æœ€ä¼˜åˆ’åˆ†çš„å½±å“ï¼š</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">def demo_DecisionTreeRegressor_splitter(*data):</span><br><span class="line">    X_train, X_test, y_train, y_test = data</span><br><span class="line">    splitters = [&apos;best&apos;, &apos;random&apos;]</span><br><span class="line">    for splitter in splitters:</span><br><span class="line">        regr = DecisionTreeRegressor(splitter=splitter)</span><br><span class="line">        regr.fit(X_train, y_train)</span><br><span class="line">        print(&quot;Splitter %s&quot; % splitter)</span><br><span class="line">        print(&quot;Training score: %f&quot; % regr.score(X_train, y_train))</span><br><span class="line">        print(&quot;Testing score: %f&quot; % regr.score(X_test, y_test))</span><br></pre></td></tr></table></figure><p>è¿è¡Œç»“æœå¦‚ä¸‹ï¼š</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">Splitter best</span><br><span class="line">Training score: 1.000000</span><br><span class="line">Testing score: 0.789107</span><br><span class="line">Splitter random</span><br><span class="line">Training score: 1.000000</span><br><span class="line">Testing score: 0.778989</span><br></pre></td></tr></table></figure><p>å¯ä»¥çœ‹åˆ°å¯¹äºæœ¬é—®é¢˜ï¼Œæœ€ä¼˜åˆ’åˆ†é¢„æµ‹æ€§èƒ½è¾ƒå¼ºï¼Œä½†æ˜¯ç›¸å·®ä¸å¤§ã€‚è€Œå¯¹äºè®­ç»ƒé›†çš„æ‹Ÿåˆï¼ŒäºŒè€…éƒ½æ‹Ÿåˆå¾—ç›¸å½“å¥½ã€‚</p><p>æœ€åè€ƒå¯Ÿå†³ç­–æ ‘æ·±åº¦çš„å½±å“ã€‚å†³ç­–æ ‘çš„æ·±åº¦å¯¹åº”ç€æ ‘çš„å¤æ‚åº¦ã€‚å†³ç­–æ ‘è¶Šæ·±ï¼Œåˆ™æ¨¡å‹è¶Šå¤æ‚ã€‚</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">def demo_DecisionTreeRegressor_depth(*data, maxdepth):</span><br><span class="line">    X_train, X_test, y_train, y_test = data</span><br><span class="line">    depths = np.arange(1, maxdepth)</span><br><span class="line">    training_scores = []</span><br><span class="line">    testing_scores = []</span><br><span class="line">    for depth in depths:</span><br><span class="line">        regr = DecisionTreeRegressor(max_depth=depth)</span><br><span class="line">        regr.fit(X_train, y_train)</span><br><span class="line">        training_scores.append(regr.score(X_train, y_train))</span><br><span class="line">        testing_scores.append(regr.score(X_test, y_test))</span><br><span class="line">    # ç»˜å›¾</span><br><span class="line">    fig = plt.figure()</span><br><span class="line">    ax = fig.add_subplot(1, 1, 1)</span><br><span class="line">    ax.plot(depths, training_scores, label=&quot;training score&quot;)</span><br><span class="line">    ax.plot(depths, testing_scores, label=&quot;testing score&quot;)</span><br><span class="line">    ax.set_xlabel(&quot;maxdepth&quot;)</span><br><span class="line">    ax.set_ylabel(&quot;score&quot;)</span><br><span class="line">    ax.set_title(&quot;Decision Tree Regression&quot;)</span><br><span class="line">    ax.legend(framealpha=0.5)</span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure><p>è°ƒç”¨è¯¥å‡½æ•°</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">X_train, X_test, y_train, y_test = create_data(100)</span><br><span class="line">demo_DecisionTreeRegressor_depth(X_train, X_test, y_train, y_test, maxdepth=20)</span><br></pre></td></tr></table></figure><p>è¿è¡Œç»“æœï¼š</p><p><img src="/images/MachineLearning/DecisionTree/20190726_ML_DecisionTreeRegressor_Depth.png"></p><p>å¯ä»¥çœ‹åˆ°éšç€æ ‘æ·±åº¦çš„åŠ æ·±ï¼Œæ¨¡å‹å¯¹è®­ç»ƒé›†å’Œé¢„æµ‹é›†çš„æ‹Ÿåˆéƒ½åœ¨æé«˜ã€‚ç”±äºæ ·æœ¬åªæœ‰100ä¸ªï¼Œå› æ­¤ç†è®ºä¸ŠäºŒå‰æ ‘æœ€æ·±ä¸º<span class="math inline">\(\log_2(100)=6.65\)</span>ã€‚å³æ ‘æ·±åº¦ä¸º7ä¹‹åï¼Œå†ä¹Ÿæ— æ³•åˆ’åˆ†äº†ï¼ˆæ¯ä¸ªå­èŠ‚ç‚¹éƒ½åªæœ‰ä¸€ä¸ªèŠ‚ç‚¹ï¼‰ã€‚</p><p>ç»˜åˆ¶ä¸åŒæ·±åº¦çš„å†³ç­–æ ‘ï¼š</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">def demo_DecisionTreeRegressor_depth_plot(*data):</span><br><span class="line">    X_train, X_test, y_train, y_test = data</span><br><span class="line">    depths = [1, 3, 7]</span><br><span class="line">    fig = plt.figure()</span><br><span class="line">    ax = fig.add_subplot(1, 1, 1)</span><br><span class="line">    for depth in depths:</span><br><span class="line">        regr = DecisionTreeRegressor(max_depth=depth)</span><br><span class="line">        regr.fit(X_train, y_train)</span><br><span class="line">        print(&quot;Training score: %f&quot; % regr.score(X_train, y_train))</span><br><span class="line">        print(&quot;Testing score: %f&quot; % regr.score(X_test, y_test))</span><br><span class="line">        X = np.arange(0.0, 5.0, 0.01)[:, np.newaxis]</span><br><span class="line">        Y = regr.predict(X)</span><br><span class="line">        ax.plot(X, Y, label=&quot;predict_value_max_depth=%d&quot; % depth, linewidth=2, alpha=0.5)</span><br><span class="line">    ax.scatter(X_train, y_train, label=&quot;train sample&quot;, c=&apos;g&apos;)</span><br><span class="line">    ax.scatter(X_test, y_test, label=&quot;test sample&quot;, c=&apos;r&apos;)</span><br><span class="line">    ax.set_xlabel(&quot;data&quot;)</span><br><span class="line">    ax.set_ylabel(&quot;target&quot;)</span><br><span class="line">    ax.set_title(&quot;Decision Tree Regression&quot;)</span><br><span class="line">    ax.legend(framealpha=0.5)</span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure><p>ç»“æœï¼š</p><p><img src="/images/MachineLearning/DecisionTree/20190726_ML_DecisionTreeRegressor_Depth_Plot.png"></p><p>å¯ä»¥çœ‹åˆ°ï¼Œæ·±åº¦è¶Šå°çš„å†³ç­–æ ‘è¶Šç®€å•ï¼Œå®ƒå°†ç‰¹å¾ç©ºé—´åˆ’åˆ†çš„æŠ˜çº¿è¶Šå°‘ã€‚æ·±åº¦è¶Šæ·±çš„å†³ç­–æ ‘è¶Šå¤æ‚ï¼Œå®ƒå°†ç‰¹å¾ç©ºé—´åˆ’åˆ†çš„æŠ˜çº¿è¶Šå¤šï¼ˆè¶Šæ›²æŠ˜ï¼‰ã€‚</p><h2 id="åˆ†ç±»å†³ç­–æ ‘decisiontreeclassifier">åˆ†ç±»å†³ç­–æ ‘(DecisionTreeClassifier)</h2><p>DecisionTreeClassifierå®ç°äº†åˆ†ç±»å†³ç­–æ ‘ï¼Œç”¨äºåˆ†ç±»é—®é¢˜ï¼š</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">class sklearn.tree.DecisionTreeClassifier(criterion=&quot;gini&quot;,</span><br><span class="line">                 splitter=&quot;best&quot;,</span><br><span class="line">                 max_depth=None,</span><br><span class="line">                 min_samples_split=2,</span><br><span class="line">                 min_samples_leaf=1,</span><br><span class="line">                 min_weight_fraction_leaf=0.,</span><br><span class="line">                 max_features=None,</span><br><span class="line">                 random_state=None,</span><br><span class="line">                 max_leaf_nodes=None,</span><br><span class="line">                 min_impurity_decrease=0.,</span><br><span class="line">                 min_impurity_split=None,</span><br><span class="line">                 class_weight=None,</span><br><span class="line">                 presort=False)</span><br></pre></td></tr></table></figure><p>å‚æ•°</p><ul><li>criterionï¼šå­—ç¬¦ä¸²ï¼ŒæŒ‡å®šåˆ‡åˆ†è´¨é‡çš„è¯„ä»·å‡†åˆ™ã€‚<ul><li>'gini'ï¼šåˆ‡åˆ†æ—¶è¯„ä»·å‡†åˆ™æ˜¯Giniç³»æ•°</li><li>'entropy'ï¼šåˆ‡åˆ†æ—¶è¯„ä»·å‡†åˆ™æ˜¯ç†µ</li></ul></li><li>splitterï¼šå­—ç¬¦ä¸²ï¼ŒæŒ‡å®šåˆ‡åˆ†åŸåˆ™<ul><li>'best'ï¼šé€‰æ‹©æœ€ä¼˜çš„åˆ‡åˆ†</li><li>'random'ï¼šéšæœºåˆ‡åˆ†</li></ul></li><li>max_depthï¼šæŒ‡å®šæ ‘çš„æœ€å¤§æ·±åº¦<ul><li>Noneï¼šè¡¨ç¤ºæ ‘çš„æ·±åº¦ä¸é™ï¼Œç›´åˆ°æ¯ä¸ªå¶å­éƒ½æ˜¯çº¯çš„ï¼Œå³å¶èŠ‚ç‚¹ä¸­æ‰€æœ‰æ ·æœ¬ç‚¹éƒ½å±äºä¸€ä¸ªç±»ï¼Œæˆ–è€…å¶å­ä¸­åŒ…å«å°äºmin_samples_splitä¸ªæ ·æœ¬ç‚¹</li></ul></li><li>min_samples_splitï¼šæ•´æ•°ï¼ŒæŒ‡å®šæ¯ä¸ªå†…éƒ¨èŠ‚ç‚¹ï¼ˆéå¶èŠ‚ç‚¹ï¼‰åŒ…å«çš„æœ€å°‘çš„æ ·æœ¬æ•°</li><li>min_samples_leafï¼šæ•´æ•°ï¼ŒæŒ‡å®šæ¯ä¸ªå¶èŠ‚ç‚¹åŒ…å«çš„æœ€å°‘æ ·æœ¬æ•°</li><li>min_weight_fraction_leafï¼šæµ®ç‚¹æ•°ï¼Œå¶èŠ‚ç‚¹ä¸­æ ·æœ¬çš„æœ€å°æƒé‡ç³»æ•°</li><li>max_featuresï¼šæŒ‡å®šå¯»æ‰¾best splitæ—¶è€ƒè™‘çš„ç‰¹å¾æ•°é‡ã€‚å¦‚æœå·²ç»è€ƒè™‘äº†max_featuresä¸ªç‰¹å¾ï¼Œä½†æ˜¯è¿˜æ²¡æœ‰æ‰¾åˆ°ä¸€ä¸ªæœ‰æ•ˆçš„åˆ‡åˆ†ï¼Œé‚£ä¹ˆè¿˜ä¼šç»§ç»­å¯»æ‰¾ä¸‹ä¸€ç‰¹å¾ï¼Œç›´åˆ°æ‰¾åˆ°ä¸€ä¸ªæœ‰æ•ˆçš„åˆ‡åˆ†ä¸ºæ­¢ã€‚<ul><li>æ•´æ•°ï¼šæ¯æ¬¡åˆ‡åˆ†åªè€ƒè™‘max_featuresä¸ªç‰¹å¾</li><li>æµ®ç‚¹æ•°ï¼šæ¯æ¬¡åˆ‡åˆ†åªè€ƒè™‘max_features * n_featuresä¸ªç‰¹å¾ï¼ˆmax_featuresæŒ‡å®šäº†ç™¾åˆ†æ¯”ï¼‰</li><li>'auto' æˆ–è€… 'sqrt'ï¼šmax_features = sqrt(n_features)</li><li>'log2'ï¼šmax_features = log2(n_features)</li><li>Noneï¼šmax_features = n_features</li></ul></li><li>random_state: ä¸€ä¸ªæ•´æ•°æˆ–è€…ä¸€ä¸ªRandomStateå®ä¾‹ï¼Œæˆ–è€…None<ul><li>å¦‚æœä¸ºæ•´æ•°ï¼Œåˆ™å®ƒæŒ‡å®šäº†éšæœºæ•°ç”Ÿæˆå™¨çš„ç§å­</li><li>å¦‚æœä¸ºRandomStateå®ä¾‹ï¼Œåˆ™æŒ‡å®šä¾‹éšæœºæ•°ç”Ÿæˆå™¨</li><li>å¦‚æœä¸ºNoneï¼Œåˆ™ä½¿ç”¨é»˜è®¤çš„éšæœºæ•°ç”Ÿæˆå™¨</li></ul></li><li>max_leaf_nodesï¼šæŒ‡å®šå¶èŠ‚ç‚¹çš„æœ€å¤§æ•°é‡<ul><li>Noneï¼šæ­¤æ—¶å¶èŠ‚ç‚¹æ•°é‡ä¸é™</li><li>æ•´æ•°ï¼šåˆ™max_depthè¢«å¿½ç•¥</li></ul></li><li>presortï¼šbooleanï¼ŒæŒ‡å®šæ˜¯å¦è¦æå‰æ’åºæ•°æ®ä»è€ŒåŠ é€Ÿå¯»æ‰¾æœ€ä¼˜åˆ‡åˆ†çš„è¿‡ç¨‹ã€‚è®¾ç½®ä¸ºTrueæ—¶ï¼Œå¯¹äºå¤§æ•°æ®é›†ä¼šå‡æ…¢æ€»ä½“çš„è®­ç»ƒè¿‡ç¨‹ï¼Œä½†æ˜¯å¯¹äºä¸€ä¸ªå°æ•°æ®é›†æˆ–è€…è®¾å®šäº†æœ€å¤§æ·±åº¦çš„æƒ…å†µä¸‹ï¼Œåˆ™ä¼šåŠ é€Ÿè®­ç»ƒè¿‡ç¨‹</li><li>class_weightï¼šä¸€ä¸ªå­—å…¸ã€å­—å…¸çš„åˆ—è¡¨ã€'balance'æˆ–è€…Noneï¼ŒæŒ‡å®šäº†åˆ†ç±»çš„æƒé‡ã€‚å½¢å¼ï¼š{class_label: weight}ã€‚å¦‚æœæä¾›äº†sample_weightå‚æ•°ï¼ˆfitæ–¹æ³•æä¾›ï¼‰ï¼Œåˆ™è¿™äº›æƒé‡éƒ½ä¼šä¹˜ä»¥sample_weightã€‚<ul><li>Noneï¼šæ¯ä¸ªåˆ†ç±»æƒé‡éƒ½ä¸º1</li><li>'balance'ï¼šåˆ†ç±»çš„æƒé‡æ˜¯æ ·æœ¬ä¸­å„åˆ†ç±»å‡ºç°çš„é¢‘ç‡çš„åæ¯”</li></ul></li></ul><p>å±æ€§</p><ul><li>classes_ï¼šåˆ†ç±»çš„æ ‡ç­¾å€¼</li><li>feature_importances_ï¼šç»™å‡ºç‰¹å¾çš„é‡è¦ç¨‹åº¦ã€‚è¯¥å€¼è¶Šé«˜ï¼Œåˆ™è¯¥ç‰¹å¾è¶Šé‡è¦ã€‚ï¼ˆGini importanceï¼‰</li><li>max_features_ï¼šmax_featuresçš„æ¨æ–­å€¼</li><li>n_classes_ï¼šç»™å‡ºåˆ†ç±»çš„æ•°é‡</li><li>n_features_ï¼šå½“æ‰§è¡Œfitä¹‹åï¼Œç‰¹å¾çš„æ•°é‡</li><li>n_outputs_ï¼šå½“æ‰§è¡Œfitä¹‹åï¼Œè¾“å‡ºçš„æ•°é‡</li><li>tree_ï¼šä¸€ä¸ªTreeå¯¹è±¡ï¼Œå³åº•å±‚çš„å†³ç­–æ ‘</li></ul><p>æ–¹æ³•</p><ul><li>fit(X, y[, sample_weight, check_input, â€¦]): è®­ç»ƒæ¨¡å‹</li><li>predict(X[, check_input]): ç”¨æ¨¡å‹è¿›è¡Œé¢„æµ‹ï¼Œè¿”å›é¢„æµ‹å€¼</li><li>predict_log_proba(X): è¿”å›ä¸€ä¸ªæ•°ç»„ï¼Œæ•°ç»„çš„å…ƒç´ ä¾æ¬¡æ˜¯Xé¢„æµ‹ä¸ºå„ä¸ªç±»åˆ«çš„æ¦‚ç‡çš„å¯¹æ•°å€¼</li><li>predict_proba(X): è¿”å›ä¸€ä¸ªæ•°ç»„ï¼Œæ•°ç»„çš„å…ƒç´ ä¾æ¬¡æ˜¯Xé¢„æµ‹ä¸ºå„ä¸ªç±»åˆ«çš„æ¦‚ç‡å€¼</li><li>score(X, y[, sample_weight]): è¿”å›åœ¨(X, y)ä¸Šé¢„æµ‹çš„å‡†ç¡®ç‡</li></ul><p>é¦–å…ˆå¯¼å…¥åŒ…</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">import numpy as np</span><br><span class="line">from sklearn.tree import DecisionTreeClassifier</span><br><span class="line">from sklearn import model_selection</span><br><span class="line">from sklearn import datasets</span><br></pre></td></tr></table></figure><p>é‡‡ç”¨é¸¢å°¾èŠ±æ•°æ®é›†ã€‚è¯¥æ•°æ®é›†ä¸€å…±æœ‰150ä¸ªæ•°æ®ï¼Œè¿™äº›æ•°æ®åˆ†ä¸º3ç±»(setosa, versicolor, virginica)ï¼Œæ¯ç±»50ä¸ªæ•°æ®ã€‚æ¯ä¸ªæ•°æ®åŒ…å«4ä¸ªå±æ€§ï¼šsepalé•¿åº¦ã€sepalå®½åº¦ã€petalé•¿åº¦ã€petalå®½åº¦ã€‚</p><p>é¦–å…ˆåŠ è½½æ•°æ®ï¼š</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">def load_data():</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    é‡‡ç”¨åˆ†å±‚é‡‡æ ·</span><br><span class="line">    :return: </span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    iris = datasets.load_iris()</span><br><span class="line">    X_train = iris.data</span><br><span class="line">    y_train = iris.target</span><br><span class="line">    return model_selection.train_test_split(X_train, y_train, test_size=0.25, random_state=0, stratify=y_train)</span><br></pre></td></tr></table></figure><p>ç„¶åï¼Œç»™å‡ºä½¿ç”¨DecisionTreeClassifierè¿›è¡Œåˆ†ç±»çš„å‡½æ•°</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">def demo_DecisionTreeClassifier(*data):</span><br><span class="line">    X_train, X_test, y_train, y_test = data</span><br><span class="line">    clf = DecisionTreeClassifier()</span><br><span class="line">    clf.fit(X_train, y_train)</span><br><span class="line">    print(&quot;Training score: %f&quot; % clf.score(X_train, y_train))</span><br><span class="line">    print(&quot;Testing score: %f&quot; % clf.score(X_test, y_test))</span><br></pre></td></tr></table></figure><p>æ‰§è¡Œç»“æœï¼š</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Training score: 1.000000</span><br><span class="line">Testing score: 0.973684</span><br></pre></td></tr></table></figure><p>å¯ä»¥çœ‹åˆ°å¯¹è®­ç»ƒæ•°æ®é›†å®Œå…¨æ‹Ÿåˆï¼Œå¯¹æµ‹è¯•æ•°æ®é›†æ‹Ÿåˆç²¾åº¦é«˜è¾¾97.3684%ã€‚</p><p>ç°åœ¨è€ƒå¯Ÿè¯„ä»·åˆ‡åˆ†è´¨é‡çš„è¯„ä»·å‡†åˆ™criterionå¯¹äºåˆ†ç±»æ€§èƒ½çš„å½±å“ï¼š</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">def demo_DecisionTreeClassifier_criterion(*data):</span><br><span class="line">    X_train, X_test, y_train, y_test = data</span><br><span class="line">    criterions = [&apos;gini&apos;, &apos;entropy&apos;]</span><br><span class="line">    for criterion in criterions:</span><br><span class="line">        clf = DecisionTreeClassifier(criterion=criterion)</span><br><span class="line">        clf.fit(X_train, y_train)</span><br><span class="line">        print(&quot;criterion: %s&quot; % criterion)</span><br><span class="line">        print(&quot;Training score: %f&quot; % clf.score(X_train, y_train))</span><br><span class="line">        print(&quot;Testing score: %f&quot; % clf.score(X_test, y_test))</span><br></pre></td></tr></table></figure><p>ç»“æœï¼š</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">criterion: gini</span><br><span class="line">Training score: 1.000000</span><br><span class="line">Testing score: 0.973684</span><br><span class="line">criterion: entropy</span><br><span class="line">Training score: 1.000000</span><br><span class="line">Testing score: 0.921053</span><br></pre></td></tr></table></figure><p>å¯ä»¥çœ‹åˆ°å¯¹äºæœ¬é—®é¢˜äºŒè€…å¯¹äºè®­ç»ƒé›†çš„æ‹Ÿåˆéƒ½éå¸¸å®Œç¾ï¼Œå¯¹åº”æµ‹è¯•é›†çš„é¢„æµ‹éƒ½è¾ƒé«˜ï¼Œä½†æ˜¯ç¨æœ‰ä¸åŒï¼Œä½¿ç”¨Giniç³»æ•°çš„ç­–ç•¥é¢„æµ‹æ€§èƒ½é«˜ã€‚</p><p>æ¥ä¸‹æ¥ï¼Œæ£€éªŒéšæœºåˆ’åˆ†ä¸æœ€ä¼˜åˆ’åˆ†çš„å½±å“ï¼š</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">def demo_DecisionTreeClassifier_splitter(*data):</span><br><span class="line">    X_train, X_test, y_train, y_test = data</span><br><span class="line">    splitters = [&apos;best&apos;, &apos;random&apos;]</span><br><span class="line">    for splitter in splitters:</span><br><span class="line">        clf = DecisionTreeClassifier(splitter=splitter)</span><br><span class="line">        clf.fit(X_train, y_train)</span><br><span class="line">        print(&quot;splitter: %s&quot; % splitter)</span><br><span class="line">        print(&quot;Training score: %f&quot; % clf.score(X_train, y_train))</span><br><span class="line">        print(&quot;Testing score: %f&quot; % clf.score(X_test, y_test))</span><br></pre></td></tr></table></figure><p>è¿è¡Œç»“æœï¼š</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">splitter: best</span><br><span class="line">Training score: 1.000000</span><br><span class="line">Testing score: 0.947368</span><br><span class="line">splitter: random</span><br><span class="line">Training score: 1.000000</span><br><span class="line">Testing score: 0.973684</span><br></pre></td></tr></table></figure><p>æœ€åè€ƒå¯Ÿå†³ç­–æ ‘æ·±åº¦çš„å½±å“ï¼š</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">def demo_DecisionTreeClassifier_depth(*data, maxdepth):</span><br><span class="line">    X_train, X_test, y_train, y_test = data</span><br><span class="line">    depths = np.arange(1, maxdepth)</span><br><span class="line">    training_scores = []</span><br><span class="line">    testing_scores = []</span><br><span class="line">    for depth in depths:</span><br><span class="line">        clf = DecisionTreeClassifier(max_depth=depth)</span><br><span class="line">        clf.fit(X_train, y_train)</span><br><span class="line">        training_scores.append(clf.score(X_train, y_train))</span><br><span class="line">        testing_scores.append(clf.score(X_test, y_test))</span><br><span class="line">    # ç»˜å›¾</span><br><span class="line">    fig = plt.figure()</span><br><span class="line">    ax = fig.add_subplot(1, 1, 1)</span><br><span class="line">    ax.plot(depths, training_scores, label=&quot;training score&quot;, marker=&apos;o&apos;)</span><br><span class="line">    ax.plot(depths, testing_scores, label=&quot;testing score&quot;, marker=&apos;*&apos;)</span><br><span class="line">    ax.set_xlabel(&quot;maxdepth&quot;)</span><br><span class="line">    ax.set_ylabel(&quot;score&quot;)</span><br><span class="line">    ax.set_title(&quot;Decision Tree Classification&quot;)</span><br><span class="line">    ax.legend(framealpha=0.5, loc=&apos;best&apos;)</span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure><p>è°ƒç”¨è¯¥å‡½æ•°ï¼š</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">X_train, X_test, y_train, y_test = load_data()</span><br><span class="line">demo_DecisionTreeClassifier_depth(X_train, X_test, y_train, y_test, maxdepth=100)</span><br></pre></td></tr></table></figure><p>è¿è¡Œç»“æœï¼š</p><p><img src="/images/MachineLearning/DecisionTree/20190727_ML_DecisionTreeClassifier_Depth.png"></p><p>å¯ä»¥çœ‹åˆ°éšç€æ ‘æ·±åº¦çš„å¢åŠ ï¼Œæ¨¡å‹å¯¹è®­ç»ƒé›†å’Œé¢„æµ‹é›†çš„æ‹Ÿåˆéƒ½åœ¨æé«˜ã€‚è¿™é‡Œè®­ç»ƒæ•°æ®é›†å¤§å°ä»…ä¸º150ï¼Œä¸è€ƒè™‘ä»»åŠ¡æ¡ä»¶ï¼Œåªéœ€è¦ä¸€æ£µæ·±åº¦ä¸º<span class="math inline">\(\log_2150 â‰¤8\)</span>çš„äºŒå‰æ ‘å°±èƒ½å¤Ÿå®Œå…¨æ‹Ÿåˆæ•°æ®ï¼Œä½¿å¾—æ¯ä¸ªå¶å­ç»“ç‚¹æœ€å¤šåªæœ‰ä¸€ä¸ªæ ·æœ¬ã€‚è€ƒè™‘åˆ°å†³ç­–æ ‘ç®—æ³•ä¸­çš„æå‰ç»ˆæ­¢æ¡ä»¶ï¼Œåˆ™æ ‘çš„æ·±åº¦å°äº8ã€‚</p><h2 id="å†³ç­–å›¾">å†³ç­–å›¾</h2><p>å½“è®­ç»ƒå®Œä¸€æ£µå†³ç­–æ ‘æ—¶ï¼Œå¯ä»¥é€šè¿‡sklearn.tree.export_graphviz(classifier, out_file)æ¥å°†å†³ç­–æ ‘è½¬åŒ–æˆGraphvizæ ¼å¼çš„æ–‡ä»¶ã€‚å¯¹ä¸Šé¢DecisionTreeClassifierä¾‹å­ï¼Œä½¿ç”¨export_graphvizå‡½æ•°å¦‚ä¸‹ï¼š</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">def demo_export_graphviz(*data, filename):</span><br><span class="line">    X_train, X_test, y_train, y_test = data</span><br><span class="line">    clf = DecisionTreeClassifier()</span><br><span class="line">    clf.fit(X_train, y_train)</span><br><span class="line">    export_graphviz(clf, filename)</span><br></pre></td></tr></table></figure><p>è°ƒç”¨ï¼š</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">X_train, X_test, y_train, y_test = load_data()</span><br><span class="line">demo_export_graphviz(X_train, X_test, y_train, y_test, filename=&quot;out_DecisionTreeClassifier&quot;)</span><br></pre></td></tr></table></figure><blockquote><p>è¿™é‡Œéœ€è¦å®‰è£…Graphvizç¨‹åºã€‚Graphvizæ˜¯è´å°”å®éªŒå®¤å¼€å‘çš„ä¸€ä¸ªå¼€æºå·¥å…·åŒ…ï¼Œç”¨äºç»˜åˆ¶ç»“æ„åŒ–çš„å›¾å½¢ç½‘ç»œã€‚é€šè¿‡<code>brew install graphviz</code>å®‰è£…ã€‚</p></blockquote><p>ç„¶åé€šè¿‡Graphvizçš„dotå·¥å…·ï¼Œåœ¨ç»ˆç«¯ä¸­è¿›å…¥æ–‡ä»¶å­˜æ”¾æ–‡ä»¶å¤¹ï¼Œç„¶åè¿è¡Œå‘½ä»¤<code>dot -Tpng out_DecisionTreeClassifier -o out_DecisionTreeClassifier.png</code>æ¥ç”Ÿæˆpngæ ¼å¼çš„å†³ç­–å›¾ã€‚å…¶ä¸­-TæŒ‡å®šäº†è¾“å‡ºæ–‡ä»¶çš„æ ¼å¼ï¼Œ-oæŒ‡å®šäº†è¾“å‡ºæ–‡ä»¶åã€‚</p><p><img src="/images/MachineLearning/DecisionTree/20190726_ML_ExportGraphviz.png"></p>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;æ¦‚è¿°&quot;&gt;æ¦‚è¿°&lt;/h1&gt;
&lt;p&gt;å†³ç­–æ ‘(decision tree)æ˜¯åŠŸèƒ½å¼ºå¤§è€Œä¸”å¾ˆå—æ¬¢è¿çš„åˆ†ç±»å’Œé¢„æµ‹æ–¹æ³•ï¼Œå®ƒæ˜¯ä¸€ç§æœ‰ç›‘ç£çš„å­¦ä¹ ç®—æ³•ï¼Œä»¥æ ‘çŠ¶å›¾ä¸ºåŸºç¡€ï¼Œå…¶è¾“å‡ºç»“æœä¸ºä¸€ç³»åˆ—ç®€å•å®ç”¨çš„è§„åˆ™ã€‚å†³ç­–æ ‘å°±æ˜¯ä¸€ç³»åˆ—çš„if-thenäºè¯­å¥ï¼Œå¯ä»¥ç”¨äºåˆ†ç±»é—®é¢˜ï¼Œä¹Ÿå¯ä»¥ç”¨äºå›å½’é—®é¢˜ã€‚&lt;/p&gt;
&lt;p&gt;å†³ç­–æ ‘æ¨¡å‹åŸºäºç‰¹å¾å¯¹å®ä¾‹è¿›è¡Œåˆ†ç±»ï¼Œå®ƒæ˜¯ä¸€ç§æ ‘çŠ¶ç»“æ„ã€‚ä¼˜ç‚¹æ˜¯å¯è¯»æ€§å¼ºï¼Œåˆ†ç±»é€Ÿåº¦å¿«ã€‚å­¦ä¹ å†³ç­–æ ‘æ—¶ï¼Œé€šå¸¸é‡‡ç”¨æŸå¤±å‡½æ•°æœ€å°åŒ–åŸåˆ™ã€‚&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;æœ¬ç« ä¸­ï¼Œè®­ç»ƒé›†ç”¨Dè¡¨ç¤ºï¼ŒTè¡¨ç¤ºä¸€æ£µå†³ç­–æ ‘ã€‚&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="Machine Learning" scheme="http://yoursite.com/categories/Machine-Learning/"/>
    
    
      <category term="machine learning" scheme="http://yoursite.com/tags/machine-learning/"/>
    
      <category term="python" scheme="http://yoursite.com/tags/python/"/>
    
      <category term="sklearn" scheme="http://yoursite.com/tags/sklearn/"/>
    
      <category term="decision tree" scheme="http://yoursite.com/tags/decision-tree/"/>
    
  </entry>
  
  <entry>
    <title>MachineLearning Chapter-1 Linear Model</title>
    <link href="http://yoursite.com/2019/07/24/MachineLearning-Chapter-1-Linear-Model/"/>
    <id>http://yoursite.com/2019/07/24/MachineLearning-Chapter-1-Linear-Model/</id>
    <published>2019-07-24T08:02:02.000Z</published>
    <updated>2019-07-28T06:25:03.011Z</updated>
    
    <content type="html"><![CDATA[<h1 id="æ¦‚è¿°">æ¦‚è¿°</h1><p>å¯¹äºæ ·æœ¬<span class="math inline">\(\stackrel{\rightarrow}{x}\)</span>ï¼Œç”¨åˆ—å‘é‡è¡¨ç¤ºè¯¥æ ·æœ¬<span class="math inline">\(\stackrel{\rightarrow}{x}={(x^{(1)},x^{(2)},â€¦,x^{(n)})}^{T}\)</span>ã€‚æ ·æœ¬æœ‰<span class="math inline">\(n\)</span>ç§ç‰¹å¾ï¼Œç”¨<span class="math inline">\(x^{(i)}\)</span>æ¥è¡¨ç¤ºæ ·æœ¬çš„ç¬¬<span class="math inline">\(i\)</span>ä¸ªç‰¹å¾ã€‚</p><p>çº¿æ€§æ¨¡å‹(linear model)çš„å½¢å¼ä¸ºï¼š <span class="math display">\[f(\stackrel{\rightarrow}{x})=\stackrel{\rightarrow}{w}Â·\stackrel{\rightarrow}{x}+b\]</span></p><p>å…¶ä¸­<span class="math inline">\(\stackrel{\rightarrow}{w}={(w^{(1)},w^{(2)},â€¦,w^{(n)})}^{T}\)</span>ä¸ºæ¯ä¸ªç‰¹å¾å¯¹åº”çš„æƒé‡ç”Ÿæˆçš„æƒé‡å‘é‡ã€‚æƒé‡å‘é‡ç›´è§‚åœ°è¡¨è¾¾äº†æ¯ä¸ªç‰¹å¾åœ¨é¢„æµ‹ä¸­çš„é‡è¦æ€§ã€‚</p><p>çº¿æ€§æ¨¡å‹å…¶å®å°±æ˜¯ä¸€ç³»åˆ—ä¸€æ¬¡ç‰¹å¾çš„çº¿æ€§ç»„åˆï¼Œåœ¨äºŒç»´å±‚é¢æ˜¯ä¸€æ¡ç›´çº¿ï¼Œä¸‰ç»´å±‚é¢åˆ™æ˜¯ä¸€ä¸ªå¹³é¢ï¼Œä»¥æ­¤ç±»æ¨åˆ°<span class="math inline">\(n\)</span>ç»´ç©ºé—´ï¼Œè¿™æ ·å¯ä»¥ç†è§£ä¸ºå¹¿ä¹‰çº¿æ€§æ¨¡å‹ã€‚</p><p>å¸¸è§çš„å¹¿ä¹‰çº¿æ€§æ¨¡å‹åŒ…æ‹¬å²­å›å½’ã€lassoå›å½’ã€Elastic Netã€é€»è¾‘å›å½’ã€çº¿æ€§åˆ¤åˆ«åˆ†æç­‰ã€‚ <a id="more"></a></p><h1 id="ç®—æ³•">ç®—æ³•</h1><h2 id="æ™®é€šçº¿æ€§å›å½’">æ™®é€šçº¿æ€§å›å½’</h2><p>çº¿æ€§å›å½’æ˜¯ä¸€ç§å›å½’åˆ†ææŠ€æœ¯ï¼Œå›å½’åˆ†ææœ¬è´¨ä¸Šå°±æ˜¯æ‰¾å‡ºå› å˜é‡å’Œè‡ªå˜é‡ä¹‹é—´çš„è”ç³»ã€‚å›å½’åˆ†æçš„å› å˜é‡åº”è¯¥æ˜¯è¿ç»­å˜é‡ï¼Œå¦‚æœå› å˜é‡ä¸ºç¦»æ•£å˜é‡ï¼Œåˆ™é—®é¢˜è½¬åŒ–ä¸ºåˆ†ç±»é—®é¢˜ï¼Œå›å½’åˆ†ææ˜¯ä¸€ä¸ªç›‘ç£å­¦ä¹ çš„é—®é¢˜ã€‚</p><p>ç»™å®šæ•°æ®é›†<span class="math inline">\(T=\{(\stackrel{\rightarrow}{x}_1,y_1),(\stackrel{\rightarrow}{x}_2,y_2),â€¦,(\stackrel{\rightarrow}{x}_N,y_N)\}\)</span>, <span class="math inline">\(\stackrel{\rightarrow}{x}_i\in X\subseteq R^n\)</span>, <span class="math inline">\(\stackrel{\rightarrow}{y}_i\in Y\subseteq R\)</span>, <span class="math inline">\(i=1,2,â€¦,N\)</span>ã€‚å…¶ä¸­<span class="math inline">\(\stackrel{\rightarrow}{x}={(x^{(1)},x^{(2)},â€¦,x^{(n)})}^{T}\)</span>ã€‚éœ€è¦å­¦ä¹ çš„æ¨¡å‹ä¸ºï¼š <span class="math display">\[f(\stackrel{\rightarrow}{x})=\stackrel{\rightarrow}{w}Â·\stackrel{\rightarrow}{x}+b\]</span></p><p>å³ï¼šæ ¹æ®å·²çŸ¥çš„æ•°æ®é›†<span class="math inline">\(T\)</span>æ¥è®¡ç®—å‚æ•°<span class="math inline">\(\stackrel{\rightarrow}{w}\)</span>å’Œ<span class="math inline">\(b\)</span>ã€‚</p><p>å¯¹äºç»™å®šçš„æ ·æœ¬<span class="math inline">\(\stackrel{\rightarrow}{x}_i\)</span>ï¼Œå…¶é¢„æµ‹å€¼ä¸º<span class="math inline">\(\hat{y}_i=f(\stackrel{\rightarrow}{x}_i)=\stackrel{\rightarrow}{w}Â·\stackrel{\rightarrow}{x}+b\)</span>ã€‚é‡‡ç”¨å¹³æ–¹æŸå¤±å‡½æ•°ï¼Œåœ¨è®­ç»ƒé›†<span class="math inline">\(T\)</span>ä¸Šï¼Œæ¨¡å‹çš„æŸå¤±å‡½æ•°ä¸ºï¼š <span class="math display">\[L(f)=\sum_{i=1}^{N}(\hat{y}_i-y_i)^2=\sum_{i=1}^{N}(\stackrel{\rightarrow}{w}Â·\stackrel{\rightarrow}{x}+b-y_i)^2\]</span></p><p>æˆ‘ä»¬çš„ç›®æ ‡æ˜¯æŸå¤±å‡½æ•°æœ€å°åŒ–ï¼Œå³ï¼š <span class="math display">\[(\stackrel{\rightarrow}{w}^*,b^*)=\arg\min_{\stackrel{\rightarrow}{w},b}\sum_{i=1}^{N}(\stackrel{\rightarrow}{w}Â·\stackrel{\rightarrow}{x}+b-y_i)^2\]</span></p><p>å¯ä»¥åˆ©ç”¨æ¢¯åº¦ä¸‹é™æ³•æ¥æ±‚è§£ä¸Šè¿°æœ€ä¼˜åŒ–é—®é¢˜çš„æ•°å€¼è§£ã€‚åœ¨ä½¿ç”¨æ¢¯åº¦ä¸‹é™æ³•çš„æ—¶å€™ï¼Œè¦æ³¨æ„ç‰¹å¾å½’ä¸€åŒ–(Feature Scaling)ï¼Œè¿™ä¹Ÿæ˜¯è®¸å¤šæœºå™¨å­¦ä¹ æ¨¡å‹éƒ½è¦æ³¨æ„çš„é—®é¢˜ã€‚ç‰¹å¾å½’ä¸€åŒ–å¯ä»¥æœ‰æ•ˆåœ°æå‡æ¨¡å‹çš„æ”¶æ•›é€Ÿåº¦å’Œæ¨¡å‹ç²¾åº¦ã€‚</p><p>ä¸Šè¿°æœ€ä¼˜åŒ–é—®é¢˜å®é™…ä¸Šæ˜¯æœ‰è§£æè§£çš„ï¼Œå¯ä»¥ç”¨æœ€å°äºŒä¹˜æ³•æ¥æ±‚è§£è§£æè§£ï¼Œè¯¥é—®é¢˜ç§°ä¸ºå¤šå…ƒçº¿æ€§å›å½’(multivariate linear regression)ã€‚</p><p>ä»¤ï¼š <span class="math display">\[\vec{\tilde{w}}=(w^{(1)},w^{(2)},â€¦,w^{(n)},b)^T=(\vec{w}^T,b)^T\\\vec{\tilde{x}}=(x^{(1)},x^{(2)},â€¦,x^{(n)},1)^T=(\vec{x}^T,1)^T\\\vec{y}=(y_1,y_2,â€¦,y_N)^T\]</span></p><p>åˆ™æœ‰ï¼š <span class="math display">\[\sum_{i=1}^{N}(\stackrel{\rightarrow}{w}Â·\stackrel{\rightarrow}{x}+b-y_i)^2={(\vec{y}-(\vec{\tilde{x}}_1,\vec{\tilde{x}}_2,â€¦,\vec{\tilde{x}}_N)^T\vec{\tilde{w}})}^T(\vec{y}-(\vec{\tilde{x}}_1,\vec{\tilde{x}}_2,â€¦,\vec{\tilde{x}}_N)^T\vec{\tilde{w}})\]</span></p><p>ä»¤ï¼š <span class="math display">\[\vec{x}=(\vec{\tilde{x}}_1,\vec{\tilde{x}}_2,â€¦,\vec{\tilde{x}}_N)^T=\begin{bmatrix}\vec{\tilde{x}}_1^T\\\vec{\tilde{x}}_2^T\\â€¦\\\vec{\tilde{x}}_N^T\end{bmatrix}=\begin{bmatrix}x_1^{(1)} &amp; x_1^{(2)} &amp; â€¦ &amp; x_1^{(n)} &amp; 1\\x_2^{(1)} &amp; x_2^{(2)} &amp; â€¦ &amp; x_2^{(n)} &amp; 1\\â€¦ &amp; â€¦ &amp; â€¦ &amp; â€¦ &amp; 1\\x_N^{(1)} &amp; x_N^{(2)} &amp; â€¦ &amp; x_N^{(n)} &amp; 1\end{bmatrix}\]</span></p><p>åˆ™ï¼š <span class="math display">\[\vec{\tilde{w}}^*=\arg\min_{\vec{\tilde{w}}}(\vec{y}-\vec{x}\vec{\tilde{w}})^T(\vec{y}-\vec{x}\vec{\tilde{w}})\]</span></p><p>ä»¤<span class="math inline">\(E_{\vec{\tilde{w}}}=(\vec{y}-\vec{x}\vec{\tilde{w}})^T(\vec{y}-\vec{x}\vec{\tilde{w}})\)</span>ï¼Œæ±‚å®ƒçš„æå°å€¼ã€‚å¯¹<span class="math inline">\(\vec{\tilde{w}}\)</span>æ±‚å¯¼ä»¤å¯¼æ•°ä¸ºé›¶ï¼Œå¾—åˆ°è§£æè§£ï¼š <span class="math display">\[\frac{\partial E_{\vec{\tilde{w}}}}{\partial \vec{\tilde{w}}}=2\vec{x}^T(\vec{x}\vec{\tilde{w}}-\vec{y})=\vec{0}\Longrightarrow \vec{x}^T\vec{x}\vec{\tilde{w}}=\vec{x}^T\vec{y}\]</span></p><ul><li>å½“<span class="math inline">\(\vec{x}^T\vec{x}\)</span>ä¸ºæ»¡ç§©çŸ©é˜µæˆ–è€…æ­£å®šçŸ©é˜µæ—¶ï¼Œå¯å¾—:<span class="math display">\[\vec{\tilde{w}}^*=(\vec{x}^T\vec{x})^{-1}\vec{x}^T\vec{y}\]</span>äºæ˜¯å¤šå…ƒçº¿æ€§å›å½’æ¨¡å‹ä¸ºï¼š<span class="math display">\[f(\vec{\tilde{x}}_i)=\vec{\tilde{x}}^T_i\vec{\tilde{w}}^*\]</span></li><li>å½“<span class="math inline">\(\vec{x}^T\vec{x}\)</span>ä¸æ˜¯æ»¡ç§©çŸ©é˜µæ—¶ã€‚æ¯”å¦‚<span class="math inline">\(N&lt;n\)</span>ï¼ˆæ ·æœ¬æ•°é‡å°äºç‰¹å¾ç§ç±»çš„æ•°é‡ï¼‰ï¼Œæ ¹æ®<span class="math inline">\(\vec{x}\)</span>çš„ç§©å°äºç­‰äº<span class="math inline">\((N,n)\)</span>ä¸­çš„æœ€å°å€¼ï¼Œå³å°äºç­‰äº<span class="math inline">\(N\)</span>ï¼ˆçŸ©é˜µçš„ç§©ä¸€å®šå°äºç­‰äºçŸ©é˜µçš„è¡Œæ•°å’Œåˆ—æ•°ï¼‰ï¼›è€ŒçŸ©é˜µ<span class="math inline">\(\vec{x}^T\vec{x}\)</span>æ˜¯<span class="math inline">\(n\times n\)</span>å¤§å°çš„ï¼Œå®ƒçš„ç§©ä¸€å®šå°äºç­‰äº<span class="math inline">\(N\)</span>ï¼Œå› æ­¤ä¸æ˜¯æ»¡ç§©çŸ©é˜µã€‚æ­¤æ—¶å­˜åœ¨å¤šä¸ªè§£æè§£ã€‚å¸¸è§çš„åšæ³•æ˜¯å¼•å…¥æ­£åˆ™åŒ–é¡¹ï¼Œå¦‚<span class="math inline">\(L_1\)</span>æ­£åˆ™åŒ–æˆ–è€…<span class="math inline">\(L_2\)</span>æ­£åˆ™åŒ–ï¼Œä»¥<span class="math inline">\(L_2\)</span>æ­£åˆ™åŒ–ä¸ºä¾‹ï¼š<span class="math display">\[\vec{\tilde{w}}^*=\arg\min_{\vec{\tilde{w}}}[(\vec{y}-\vec{x}\vec{\tilde{w}})^T(\vec{y}-\vec{x}\vec{\tilde{w}})+\lambda||\vec{\tilde{w}}||_2^2]\]</span>å…¶ä¸­ï¼Œ<span class="math inline">\(\lambda &gt;0\)</span>è°ƒæ•´æ­£åˆ™åŒ–é¡¹ä¸å‡æ–¹è¯¯å·®çš„æ¯”ä¾‹ï¼›<span class="math inline">\(||â€¦||_2\)</span>ä¸º<span class="math inline">\(L_2\)</span>èŒƒæ•°ã€‚</li></ul><p>æ ¹æ®ä¸Šè¿°åŸç†ï¼Œæˆ‘ä»¬å¾—åˆ°å¤šå…ƒçº¿æ€§å›å½’ç®—æ³•ï¼š</p><p>è¾“å…¥ï¼šæ•°æ®é›† <span class="math inline">\(T=\{(\stackrel{\rightarrow}{x}_1,y_1),(\stackrel{\rightarrow}{x}_2,y_2),â€¦,(\stackrel{\rightarrow}{x}_N,y_N)\}\)</span>, <span class="math inline">\(\stackrel{\rightarrow}{x}_i\in X\subseteq R^n\)</span>, <span class="math inline">\(\stackrel{\rightarrow}{y}_i\in Y\subseteq R\)</span>, <span class="math inline">\(i=1,2,â€¦,N\)</span>ï¼Œæ­£åˆ™åŒ–é¡¹ç³»æ•°<span class="math inline">\(\lambda &gt;0\)</span>ã€‚</p><p>è¾“å‡ºï¼š<span class="math display">\[f(\stackrel{\rightarrow}{x})=\stackrel{\rightarrow}{w}Â·\stackrel{\rightarrow}{x}+b\]</span></p><p>ç®—æ³•æ­¥éª¤ï¼š</p><p>ä»¤ï¼š<span class="math display">\[\vec{\tilde{w}}=(w^{(1)},w^{(2)},â€¦,w^{(n)},b)^T=(\vec{w}^T,b)^T\\\vec{\tilde{x}}=(x^{(1)},x^{(2)},â€¦,x^{(n)},1)^T=(\vec{x}^T,1)^T\\\vec{y}=(y_1,y_2,â€¦,y_N)^T\]</span>è®¡ç®—<span class="math display">\[\vec{x}=(\vec{\tilde{x}}_1,\vec{\tilde{x}}_2,â€¦,\vec{\tilde{x}}_N)^T=\begin{bmatrix}\vec{\tilde{x}}_1^T\\\vec{\tilde{x}}_2^T\\â€¦\\\vec{\tilde{x}}_N^T\end{bmatrix}=\begin{bmatrix}x_1^{(1)} &amp; x_1^{(2)} &amp; â€¦ &amp; x_1^{(n)} &amp; 1\\x_2^{(1)} &amp; x_2^{(2)} &amp; â€¦ &amp; x_2^{(n)} &amp; 1\\â€¦ &amp; â€¦ &amp; â€¦ &amp; â€¦ &amp; 1\\x_N^{(1)} &amp; x_N^{(2)} &amp; â€¦ &amp; x_N^{(n)} &amp; 1\end{bmatrix}\]</span></p><p>æ±‚è§£ï¼š<span class="math display">\[\vec{\tilde{w}}^*=\arg\min_{\vec{\tilde{w}}}[(\vec{y}-\vec{x}\vec{\tilde{w}})^T(\vec{y}-\vec{x}\vec{\tilde{w}})+\lambda||\vec{\tilde{w}}||_2^2]\]</span></p><p>æœ€ç»ˆå¾—åˆ°æ¨¡å‹ï¼š<span class="math display">\[f(\vec{\tilde{x}}_i)=\vec{\tilde{x}}^T_i\vec{\tilde{w}}^*\]</span></p><h2 id="å¹¿ä¹‰çº¿æ€§æ¨¡å‹">å¹¿ä¹‰çº¿æ€§æ¨¡å‹</h2><p>è€ƒè™‘å•è°ƒå¯å¯¼å‡½æ•°<span class="math inline">\(h(Â·)\)</span>ï¼Œä»¤<span class="math inline">\(h(y)=\vec{w}^T\vec{x}+b\)</span>ï¼Œè¿™æ ·å¾—åˆ°çš„æ¨¡å‹ç§°ä¸ºå¹¿ä¹‰çº¿æ€§æ¨¡å‹(generalized linear model)ã€‚</p><p>å¹¿ä¹‰çº¿æ€§æ¨¡å‹çš„ä¸€ä¸ªå…¸å‹ä¾‹å­å°±æ˜¯å¯¹æ•°çº¿æ€§å›å½’ã€‚å½“<span class="math inline">\(h(Â·)=\ln{(Â·)}\)</span>æ—¶å½“å¹¿ä¹‰çº¿æ€§æ¨¡å‹å°±æ˜¯å¯¹æ•°çº¿æ€§å›å½’ï¼Œå³<span class="math display">\[\ln{y}=\vec{w}^T\vec{x}+b\]</span></p><p>å®ƒæ˜¯é€šè¿‡<span class="math inline">\(\exp(\vec{w}^T\vec{x}+b)\)</span>æ‹Ÿåˆ<span class="math inline">\(y\)</span>çš„ã€‚å®ƒè™½ç„¶ç§°ä¸ºå¹¿ä¹‰çº¿æ€§å›å½’ï¼Œä½†å®è´¨ä¸Šæ˜¯éçº¿æ€§çš„ã€‚</p><h2 id="é€»è¾‘å›å½’">é€»è¾‘å›å½’</h2><p>ä¸Šè¿°å†…å®¹éƒ½æ˜¯åœ¨ç”¨çº¿æ€§æ¨¡å‹è¿›è¡Œå›å½’å­¦ä¹ ï¼Œè€Œçº¿æ€§æ¨¡å‹ä¹Ÿå¯ä»¥ç”¨äºåˆ†ç±»ã€‚è€ƒè™‘äºŒç±»åˆ†ç±»é—®é¢˜ï¼Œç»™å®šæ•°æ®é›†<span class="math inline">\(T=\{(\stackrel{\rightarrow}{x}_1,y_1),(\stackrel{\rightarrow}{x}_2,y_2),â€¦,(\stackrel{\rightarrow}{x}_N,y_N)\}\)</span>, <span class="math inline">\(\stackrel{\rightarrow}{x}_i\in X\subseteq R^n\)</span>, <span class="math inline">\(\stackrel{\rightarrow}{y}_i\in Y=\{0,1\},\)</span><span class="math inline">\(i=1,2,â€¦,N\)</span>ï¼Œå…¶ä¸­<span class="math inline">\(\stackrel{\rightarrow}{x}_i={(x_i^{(1)},x_i^{(2)},â€¦,x_i^{(n)})}^{T}\)</span>ã€‚æˆ‘ä»¬éœ€è¦çŸ¥é“<span class="math inline">\(P(y/ \vec{x})\)</span>ï¼Œè¿™é‡Œç”¨æ¡ä»¶æ¦‚ç‡çš„åŸå› æ˜¯ï¼šé¢„æµ‹çš„æ—¶å€™éƒ½æ˜¯å·²çŸ¥<span class="math inline">\(\vec{x}\)</span>ï¼Œç„¶åéœ€è¦åˆ¤æ–­æ­¤æ—¶å¯¹åº”çš„<span class="math inline">\(y\)</span>å€¼ã€‚</p><p>è€ƒè™‘åˆ°<span class="math inline">\(\vec{w}Â·\vec{x}+b\)</span>å–å€¼æ˜¯è¿ç»­çš„ï¼Œå› æ­¤å®ƒä¸èƒ½æ‹Ÿåˆç¦»æ•£å˜é‡ã€‚å¯ä»¥è€ƒè™‘ç”¨å®ƒæ¥æ‹Ÿåˆæ¡ä»¶æ¦‚ç‡<span class="math inline">\(P(y/\vec{x})\)</span>ï¼Œå› ä¸ºæ¦‚ç‡çš„å–å€¼ä¹Ÿæ˜¯è¿ç»­çš„ã€‚ä½†æ˜¯å¯¹äº<span class="math inline">\(\vec{w}\neq \vec{0}\)</span>ï¼ˆè‹¥ç­‰äºé›¶å‘é‡åˆ™æ²¡æœ‰æ±‚è§£çš„ä»·å€¼ï¼‰ï¼Œ<span class="math inline">\(\vec{w}Â·\vec{x}+b\)</span>çš„å–å€¼æ˜¯ä»<span class="math inline">\(-\infty \thicksim +\infty\)</span>ï¼Œä¸ç¬¦åˆæ¦‚ç‡å–å€¼ä¸º<span class="math inline">\(0\thicksim 1\)</span>ï¼Œå› æ­¤è€ƒè™‘é‡‡ç”¨å¹¿ä¹‰çº¿æ€§æ¨¡å‹ï¼Œæœ€ç†æƒ³çš„æ˜¯å•ä½é˜¶è·ƒå‡½æ•°ï¼š<span class="math display">\[P(y=1/\vec{x})=\left\{\begin{aligned}0,z&lt;0\\0.5,z=0\\1,z&gt;0\end{aligned}\right.,z=\vec{w}Â·\vec{x}+b\]</span></p><p>ä½†æ˜¯é˜¶è·ƒå‡½æ•°ä¸æ»¡è¶³å•è°ƒå¯å¯¼çš„æ€§è´¨ï¼Œé€€è€Œæ±‚å…¶æ¬¡ï¼Œæˆ‘ä»¬éœ€è¦æ‰¾ä¸€ä¸ªå¯å¯¼çš„ã€ä¸é˜¶è·ƒå‡½æ•°ç›¸ä¼¼çš„å‡½æ•°ã€‚å¯¹æ•°æ¦‚ç‡å‡½æ•°(logistic function)å°±æ˜¯è¿™æ ·ä¸€ä¸ªæ›¿ä»£å‡½æ•°ï¼š<span class="math display">\[P(y=1/\vec{x})=\frac{1}{1+e^{-z}},z=\vec{w}Â·\vec{x}+b\]</span></p><p>ç”±äº<span class="math inline">\(P(y=0/\vec{x})=1-P(y=1/\vec{x})\)</span>ï¼Œåˆ™æœ‰ï¼š<span class="math inline">\(\ln{\frac{P(y=1/\vec{x})}{P(y=0/\vec{x})}}=z=\vec{w}Â·\vec{x}+b\)</span>ã€‚æ¯”å€¼<span class="math inline">\(\frac{P(y=1/\vec{x})}{P(y=0/\vec{x})}\)</span>è¡¨ç¤ºæ ·æœ¬ä¸ºæ­£ä¾‹çš„å¯èƒ½æ€§æ¯”åä¾‹çš„å¯èƒ½æ€§ï¼Œç§°ä¸ºæ¦‚ç‡(odds)ï¼Œåæ˜ æ ·æœ¬ä½œä¸ºæ­£ä¾‹çš„ç›¸å¯¹å¯èƒ½æ€§ã€‚æ¦‚ç‡å¤§å¯¹æ•°ç§°ä¸ºå¯¹æ•°æ¦‚ç‡(log oddsï¼Œä¹Ÿç§°ä¸ºlogit)ã€‚</p><p>ä¸‹é¢ç»™å‡ºé€»è¾‘å›å½’æ¨¡å‹å‚æ•°ä¼°è®¡ï¼šç»™å®šè®­ç»ƒæ•°æ®é›†<span class="math inline">\(T=\{(\stackrel{\rightarrow}{x}_1,y_1),(\stackrel{\rightarrow}{x}_2,y_2),â€¦,(\stackrel{\rightarrow}{x}_N,y_N)\}\)</span>ï¼Œå…¶ä¸­<span class="math inline">\(\vec{x}_i \in R^n,y_i \in \{0,1\}\)</span>ã€‚æ¨¡å‹ä¼°è®¡çš„åŸç†ï¼šç”¨æå¤§ä¼¼ç„¶ä¼°è®¡æ³•ä¼°è®¡æ¨¡å‹å‚æ•°ã€‚</p><p>ä¸ºäº†ä¾¿äºè®¨è®ºï¼Œæˆ‘ä»¬å°†å‚æ•°<span class="math inline">\(b\)</span>å¸æ”¶è¿›<span class="math inline">\(\vec{w}\)</span>ä¸­ï¼Œä»¤ï¼š<span class="math display">\[\vec{\tilde{w}}={(w^{(1)},w^{(2)},â€¦,w^{(n)},b)}^{T}\in R^{n+1}\\\vec{\tilde{x}}={(x^{(1)},x^{(2)},â€¦,x^{(n)},1)}^{T}\in R^{n+1}\]</span></p><p>ä»¤<span class="math inline">\(P(Y=1/\vec{\tilde{x}})=\pi (\vec{\tilde{x}})=\frac{\exp (\vec{\tilde{w}}Â·\vec{\tilde{x}})}{1+\exp (\vec{\tilde{w}}Â·\vec{\tilde{x}})}\)</span>,<span class="math inline">\(P(Y= 0/\vec{\tilde{x}})=1-\pi (\vec{\tilde{x}})\)</span>ï¼Œåˆ™ä¼¼ç„¶å‡½æ•°ä¸ºï¼š<span class="math display">\[\prod_{i=1}^N[\pi (\vec{\tilde{x}}_i)]^{y_i}[1-\pi (\vec{\tilde{x}}_i)]^{1-y_i}\]</span></p><p>å¯¹æ•°ä¼¼ç„¶å‡½æ•°ä¸ºï¼š<span class="math display">\[L(\vec{\tilde{w}})=\sum_{i=1}^N[y_i\log \pi (\vec{\tilde{x}}_i)+(1-y_i)\log (1-\pi (\vec{\tilde{x}}_i)]\\=\sum_{i=1}^N[y_i\log \frac{\pi (\vec{\tilde{x}}_i)}{1-\pi (\vec{\tilde{x}}_i)}+\log(1-\pi (\vec{\tilde{x}}_i))]\]</span></p><p>åˆç”±äº<span class="math inline">\(\pi (\vec{\tilde{x}}_i)=\frac{\exp (\vec{\tilde{w}}Â·\vec{\tilde{x}})}{1+\exp (\vec{\tilde{w}}Â·\vec{\tilde{x}})}\)</span>ï¼Œå› æ­¤ï¼š<span class="math display">\[L(\vec{\tilde{w}})=\sum_{i=1}^N[y_i(\vec{\tilde{w}}Â·\vec{\tilde{x}}_i)-\log (1+\exp(\vec{\tilde{w}}Â·\vec{\tilde{x}}_i))]\]</span></p><p>å¯¹<span class="math inline">\(L(\vec{\tilde{w}})\)</span>æ±‚æå¤§å€¼ï¼Œå¾—åˆ°<span class="math inline">\(\vec{\tilde{w}}\)</span>çš„ä¼°è®¡å€¼ã€‚è®¾ä¼°è®¡å€¼ä¸º<span class="math inline">\(\vec{\tilde{w}}^{*}\)</span>ï¼Œåˆ™é€»è¾‘å›å½’æ¨¡å‹ä¸ºï¼š<span class="math display">\[P(Y=1/X=\vec{\tilde{x}})=\frac{\exp (\vec{\tilde{w}}^{*} Â·\vec{\tilde{x}})}{1+\exp(\vec{\tilde{w}}^{*}Â·\vec{\tilde{x}})}\\P(Y=0/X=\vec{\tilde{x}})=\frac{1}{1+\exp(\vec{\tilde{w}}^{*}Â·\vec{\tilde{x}})}\]</span></p><blockquote><p>é€šå¸¸ç”¨æ¢¯åº¦ä¸‹é™æ³•æˆ–è€…æ‹Ÿç‰›é¡¿æ³•æ¥æ±‚è§£è¯¥æœ€å¤§å€¼é—®é¢˜</p></blockquote><p>ä»¥ä¸Šè®¨è®ºçš„éƒ½æ˜¯äºŒç±»åˆ†ç±»çš„é€»è¾‘å›å½’æ¨¡å‹ï¼Œå¯ä»¥æ¨å¹¿åˆ°å¤šç±»åˆ†ç±»é€»è¾‘å›å½’æ¨¡å‹ã€‚è®¾ç¦»æ•£æ€§éšæœºå˜é‡Yçš„å–å€¼é›†åˆä¸ºï¼š<span class="math inline">\(\{1,2,â€¦,K\}\)</span>ï¼Œåˆ™å¤šç±»åˆ†ç±»é€»è¾‘å›å½’æ¨¡å‹ä¸ºï¼š<span class="math display">\[P(Y=k/\vec{\tilde{x}})=\frac{\exp (\vec{\tilde{w}}_k Â·\vec{\tilde{x}})}{1+\sum_{k=1}^{K-1}\exp(\vec{\tilde{w}}_kÂ·\vec{\tilde{x}})},k=1,2,â€¦,K-1\\P(Y=K/\vec{\tilde{x}})=\frac{1}{1+\sum_{k=1}^{K-1}\exp(\vec{\tilde{w}}_kÂ·\vec{\tilde{x}})},\vec{\tilde{x}}\in R^{n+1},\vec{\tilde{w}}_k\in R^{n+1}\]</span></p><p>å…¶å‚æ•°ä¼°è®¡æ–¹æ³•ç±»ä¼¼äºŒç±»åˆ†ç±»é€»è¾‘å›å½’æ¨¡å‹ã€‚</p><h2 id="çº¿æ€§åˆ¤åˆ«åˆ†æ">çº¿æ€§åˆ¤åˆ«åˆ†æ</h2><p>çº¿æ€§åˆ¤åˆ«åˆ†æ(Linear Discriminant Analysis, LDA)çš„æ€æƒ³ï¼š</p><ul><li>è®­ç»ƒæ—¶ï¼šè®¾æ³•å°†è®­ç»ƒæ ·æœ¬æŠ•å½±åˆ°ä¸€æ¡ç›´çº¿ä¸Šï¼Œä½¿å¾—åŒç±»æ ·æœ¬çš„æŠ•å½±ç‚¹å°½å¯èƒ½åœ°æ¥è¿‘ã€å¼‚ç±»æ ·æœ¬çš„æŠ•å½±ç‚¹å°½å¯èƒ½åœ°è¿œç¦»ã€‚è¦å­¦ä¹ çš„å°±æ˜¯è¿™æ ·ä¸€æ¡ç›´çº¿ã€‚</li><li>é¢„æµ‹æ—¶ï¼šå°†å¾…é¢„æµ‹æ ·æœ¬æŠ•å½±åˆ°å­¦ä¹ åˆ°ç›´çº¿ä¸Šï¼Œæ ¹æ®å®ƒçš„æŠ•å½±ç‚¹çš„ä½ç½®æ¥åˆ¤å®šå®ƒçš„ç±»åˆ«ã€‚</li></ul><p>è€ƒè™‘äºŒç±»åˆ†ç±»é—®é¢˜ï¼Œç»™å®šæ•°æ®é›†<span class="math inline">\(T=\{(\stackrel{\rightarrow}{x}_1,y_1),(\stackrel{\rightarrow}{x}_2,y_2),â€¦,(\stackrel{\rightarrow}{x}_N,y_N)\}\)</span>, <span class="math inline">\(\stackrel{\rightarrow}{x}_i\in X\subseteq R^n\)</span>, <span class="math inline">\(\stackrel{\rightarrow}{y}_i\in Y=\{0,1\}\)</span>, <span class="math inline">\(i=1,2,â€¦,N\)</span>ï¼Œå…¶ä¸­<span class="math inline">\(\stackrel{\rightarrow}{x}_i={(x_i^{(1)},x_i^{(2)},â€¦,x_i^{(n)})}^{T}\)</span>ã€‚</p><ul><li>è®¾<span class="math inline">\(T_0\)</span>è¡¨ç¤ºç±»åˆ«ä¸º0çš„æ ·ä¾‹çš„é›†åˆï¼Œè¿™äº›æ ·ä¾‹çš„å‡å€¼å‘é‡ä¸º<span class="math inline">\(\stackrel{\rightarrow}{\mu}_0={(\mu_0^{(1)},\mu_0^{(2)},â€¦,\mu_0^{(n)})}^{T}\)</span>ï¼Œè¿™äº›æ ·ä¾‹çš„ç‰¹å¾ä¹‹é—´åæ–¹å·®çŸ©é˜µä¸º<span class="math inline">\(\sum_0\)</span>ï¼ˆåæ–¹å·®çŸ©é˜µå¤§å°ä¸º<span class="math inline">\(n\times n\)</span>ï¼‰ã€‚</li><li>è®¾<span class="math inline">\(T_1\)</span>è¡¨ç¤ºç±»åˆ«ä¸º1çš„æ ·ä¾‹çš„é›†åˆï¼Œè¿™äº›æ ·ä¾‹çš„å‡å€¼å‘é‡ä¸º<span class="math inline">\(\stackrel{\rightarrow}{\mu}_1={(\mu_1^{(1)},\mu_1^{(2)},â€¦,\mu_1^{(n)})}^{T}\)</span>ï¼Œè¿™äº›æ ·ä¾‹çš„ç‰¹å¾ä¹‹é—´åæ–¹å·®çŸ©é˜µä¸º<span class="math inline">\(\sum_1\)</span>ï¼ˆåæ–¹å·®çŸ©é˜µå¤§å°ä¸º<span class="math inline">\(n\times n\)</span>ï¼‰ã€‚</li></ul><p>å‡å®šç›´çº¿ä¸º<span class="math inline">\(y=\vec{w}^T\vec{x}\)</span>ï¼ˆè¿™é‡Œçœç•¥äº†<span class="math inline">\(b\)</span>ï¼Œå› ä¸ºè€ƒå¯Ÿçš„æ˜¯æ ·æœ¬ç‚¹åœ¨ç›´çº¿ä¸Šçš„æŠ•å½±ï¼Œæ€»å¯ä»¥å¹³è¡Œç§»åŠ¨ç›´çº¿åˆ°åŸç‚¹è€Œä¿æŒæŠ•å½±ä¸å˜ï¼Œæ­¤æ—¶<span class="math inline">\(b=0\)</span>ï¼‰ï¼Œå…¶ä¸­<span class="math inline">\(\stackrel{\rightarrow}{w}={(w^{(1)},w^{(2)},â€¦,w^{(n)})}^{T}\)</span>,<span class="math inline">\(\stackrel{\rightarrow}{x}={(x^{(1)},x^{(2)},â€¦,x^{(n)})}^{T}\)</span></p><p>å°†æ•°æ®æŠ•å½±åˆ°ç›´çº¿ä¸Šï¼Œåˆ™</p><ul><li>ä¸¤ç±»æ ·æœ¬çš„ä¸­å¿ƒåœ¨ç›´çº¿ä¸Šçš„æŠ•å½±åˆ†åˆ«ä¸º<span class="math inline">\(\vec{w}^T\vec{\mu}_0\)</span>å’Œ<span class="math inline">\(\vec{w}^T\vec{\mu}_1\)</span>ã€‚</li><li>ä¸¤ç±»æ ·æœ¬æŠ•å½±çš„æ–¹å·®åˆ†åˆ«ä¸º<span class="math inline">\(\vec{w}^T\sum_0\vec{w}\)</span>å’Œ<span class="math inline">\(\vec{w}^T\sum_1\vec{w}\)</span>ã€‚</li></ul><p>æˆ‘ä»¬çš„ç›®æ ‡æ˜¯ï¼šåŒç±»æ ·æœ¬çš„æŠ•å½±ç‚¹å°½å¯èƒ½åœ°æ¥è¿‘ã€å¼‚ç±»æ ·æœ¬ç‚¹æŠ•å½±ç‚¹å°½å¯èƒ½åœ°è¿œç¦»ã€‚é‚£ä¹ˆå¯ä»¥ä½¿åŒç±»æ ·ä¾‹æŠ•å½±ç‚¹ç‚¹æ–¹å·®å°½å¯èƒ½åœ°å°ï¼Œå³<span class="math inline">\(\vec{w}^T\sum_0\vec{w}+\vec{w}^T\sum_1\vec{w}\)</span>å°½å¯èƒ½åœ°å°ï¼›å¯ä»¥ä½¿å¼‚ç±»æ ·ä¾‹çš„ä¸­å¿ƒçš„æŠ•å½±ç‚¹å°½å¯èƒ½åœ°è¿œï¼Œå³<span class="math inline">\(||\vec{w}^T\vec{\mu}_0-\vec{w}^T\vec{\mu}_1||_2^2\)</span>å°½å¯èƒ½åœ°å¤§ã€‚äºæ˜¯å¾—åˆ°æœ€å¤§åŒ–çš„ç›®æ ‡ï¼š<span class="math display">\[J=\frac{||\vec{w}^T\vec{\mu}_0-\vec{w}^T\vec{\mu}_1||_2^2}{\vec{w}^T\sum_0\vec{w}+\vec{w}^T\sum_1\vec{w}}=\frac{\vec{w}^T(\vec{\mu}_0-\vec{\mu}_1)(\vec{\mu}_0-\vec{\mu}_1)^T\vec{w}}{\vec{w}^T(\sum_0+\sum_1)\vec{w}}\]</span></p><p>å®šä¹‰ç±»å†…æ•£åº¦çŸ©é˜µ(within-class scatter matrix)ï¼š<span class="math display">\[S_w={\sum}_0+{\sum}_1=\sum_{\vec{x}\in T_0}(\vec{x}-\vec{\mu}_0)(\vec{x}-\vec{\mu}_0)^T+\sum_{\vec{x}\in T_1}(\vec{x}-\vec{\mu}_1)(\vec{x}-\vec{\mu}_1)^T\]</span></p><p>å®šä¹‰ç±»é—´æ•£åº¦çŸ©é˜µ(between-class scatter matrix)ï¼š<span class="math inline">\(S_b=(\vec{\mu}_0-\vec{\mu}_1)(\vec{\mu}_0-\vec{\mu}_1)^T\)</span>ï¼Œå®ƒæ˜¯å‘é‡<span class="math inline">\((\vec{\mu}_0-\vec{\mu}_1)\)</span>ä¸å®ƒè‡ªèº«çš„å¤–ç§¯ï¼Œåˆ™LDAæœ€å¤§åŒ–çš„ç›®æ ‡ä¸ºï¼š<span class="math display">\[J=\frac{\vec{w}^TS_b\vec{w}}{\vec{w}^TS_w\vec{w}}\]</span></p><p><span class="math inline">\(J\)</span>ä¹Ÿç§°ä¸º<span class="math inline">\(S_b\)</span>ä¸<span class="math inline">\(S_w\)</span>çš„å¹¿ä¹‰ç‘åˆ©å•†ã€‚ç°åœ¨æ±‚è§£æœ€ä¼˜åŒ–é—®é¢˜ï¼š<span class="math display">\[\vec{w}^*=\arg \max_{\vec{w}}\frac{\vec{w}^TS_b\vec{w}}{\vec{w}^TS_w\vec{w}}\]</span></p><p>ç”±äºåˆ†å­ä¸åˆ†æ¯éƒ½æ˜¯å…³äº<span class="math inline">\(\vec{w}\)</span>çš„äºŒæ¬¡é¡¹ï¼Œå› æ­¤ä¸Šå¼çš„è§£ä¸<span class="math inline">\(\vec{w}\)</span>çš„é•¿åº¦æ— å…³ã€‚ä»¤<span class="math inline">\(\vec{w}^TS_w\vec{w}=1\)</span>ï¼Œåˆ™æœ€ä¼˜åŒ–é—®é¢˜æ”¹å†™ä¸ºï¼š<span class="math display">\[\vec{w}^*=\arg \min_{\vec{w}}-\vec{w}^TS_b\vec{w}\\s.t.\vec{w}^TS_w\vec{w}=1\]</span></p><p>åº”ç”¨æ‹‰æ ¼æœ—æ—¥ä¹˜å­æ³•ï¼š<span class="math display">\[S_b\vec{w}=\lambda S_w\vec{w}\]</span></p><p>ä»¤<span class="math inline">\((\vec{\mu}_0-\vec{\mu}_1)^T\vec{w}=\lambda_{\vec{w}}\)</span>ï¼Œå…¶ä¸­<span class="math inline">\(\lambda_{\vec{w}}\)</span>ä¸ºå®æ•°ã€‚åˆ™<span class="math display">\[S_b\vec{w}=(\vec{\mu}_0-\vec{\mu}_1)(\vec{\mu}_0-\vec{\mu}_1)^T\vec{w}=\lambda_{\vec{w}}(\vec{\mu}_0-\vec{\mu}_1)=\lambda S_w\vec{w}\]</span></p><p>ç”±äºä¸<span class="math inline">\(\vec{w}\)</span>çš„é•¿åº¦æ— å…³ï¼Œå¯ä»¥ä»¤<span class="math inline">\(\lambda_{\vec{w}}=\lambda\)</span>ï¼Œåˆ™æœ‰ï¼š<span class="math display">\[(\vec{\mu}_0-\vec{\mu}_1)=S_w\vec{w}\Longrightarrow \vec{w}=S_w^{-1}(\vec{\mu}_0-\vec{\mu}_1)\]</span></p><p>ä¸Šè¿°è®¨è®ºçš„æ˜¯äºŒç±»åˆ†ç±»LDAç®—æ³•ã€‚å¯ä»¥å°†å®ƒæ¨å¹¿åˆ°å¤šåˆ†ç±»ä»»åŠ¡ä¸­ï¼šå‡å®šå­˜åœ¨<span class="math inline">\(M\)</span>ä¸ªç±»ï¼Œå±äºç¬¬<span class="math inline">\(i\)</span>ä¸ªç±»çš„æ ·æœ¬çš„é›†åˆä¸º<span class="math inline">\(T_i\)</span>ï¼Œ<span class="math inline">\(T_i\)</span>ä¸­çš„æ ·ä¾‹æ•°ä¸º<span class="math inline">\(m_i\)</span>ï¼Œåˆ™æœ‰ï¼š<span class="math inline">\(\sum_{i=1}^Mm_i=N\)</span>ï¼Œå…¶ä¸­<span class="math inline">\(N\)</span>ä¸ºæ ·æœ¬æ€»æ•°ã€‚è®¾<span class="math inline">\(T_i\)</span>è¡¨ç¤ºç±»åˆ«ä¸º<span class="math inline">\(iï¼Œi=1,2,â€¦,M\)</span>çš„æ ·ä¾‹çš„é›†åˆï¼Œè¿™äº›æ ·ä¾‹çš„å‡å€¼å‘é‡ä¸ºï¼š<span class="math display">\[\vec{\mu}_i=(\mu_i^{(1)},\mu_i^{(2)},â€¦,\mu_i^{(n)})^T=\frac{1}{m_i}\sum_{\vec{x}_i\in T_i}\vec{x}_i\]</span></p><p>è¿™äº›æ ·ä¾‹çš„ç‰¹å¾ä¹‹é—´åæ–¹å·®çŸ©é˜µä¸º<span class="math inline">\(\sum_i\)</span>ï¼ˆåæ–¹å·®çŸ©é˜µå¤§å°ä¸º<span class="math inline">\(n\times n\)</span>ï¼‰ã€‚å®šä¹‰<span class="math inline">\(\vec{\mu}=(\mu^{(1)},\mu^{(2)},â€¦,\mu^{(n)})^T=\frac{1}{N}\sum_{i=1}^N\vec{x}_i\)</span>æ˜¯æ‰€æœ‰æ ·ä¾‹çš„å‡å€¼å‘é‡ã€‚</p><ul><li><p>è¦ä½¿å¾—åŒç±»æ ·ä¾‹çš„æŠ•å½±ç‚¹å°½å¯èƒ½åœ°æ¥è¿‘ï¼Œåˆ™å¯ä»¥ä½¿åŒç±»æ ·ä¾‹æŠ•å½±ç‚¹çš„æ–¹å·®å°½å¯èƒ½åœ°å°ï¼Œå› æ­¤å®šä¹‰ç±»åˆ«çš„ç±»å†…æ•£åº¦çŸ©é˜µä¸º<span class="math inline">\(S_{wi}=\sum_{\vec{x}\in T_i}(\vec{x}-\vec{\mu}_i)(\vec{x}-\vec{\mu}_i)^T\)</span>ï¼›å®šä¹‰ç±»å†…æ•£åº¦çŸ©é˜µä¸º<span class="math inline">\(S_w=\sum_{i=1}^MS_{wi}\)</span>ã€‚</p><blockquote><p>ç±»åˆ«çš„ç±»å†…æ•£åº¦çŸ©é˜µä¸º<span class="math inline">\(S_{wi}=\sum_{\vec{x}\in T_i}(\vec{x}-\vec{\mu}_i)(\vec{x}-\vec{\mu}_i)^T\)</span>ï¼Œå®é™…ä¸Šå°±ç­‰äºæ ·æœ¬é›†<span class="math inline">\(T_i\)</span>çš„åæ–¹å·®çŸ©é˜µ<span class="math inline">\(\sum_i\)</span>ã€‚</p></blockquote></li><li><p>è¦ä½¿å¼‚ç±»æ ·ä¾‹çš„æŠ•å½±ç‚¹å°½å¯èƒ½åœ°è¿œï¼Œåˆ™å¯ä»¥ä½¿å¼‚ç±»æ ·ä¾‹ä¸­å¿ƒçš„æŠ•å½±ç‚¹å°½å¯èƒ½åœ°è¿œï¼Œç”±äºè¿™é‡Œä¸æ­¢ä¸¤ä¸ªä¸­å¿ƒç‚¹ï¼Œå› æ­¤ä¸èƒ½ç®€å•åœ°å¥—ç”¨äºŒç±»LDAçš„åšæ³•ï¼ˆå³ä¸¤ä¸ªä¸­å¿ƒç‚¹çš„è·ç¦»ï¼‰ã€‚è¿™é‡Œç”¨æ¯ä¸€ç±»æ ·æœ¬é›†çš„ä¸­å¿ƒç‚¹è·å’Œæ€»çš„ä¸­å¿ƒç‚¹çš„è·ç¦»ä½œä¸ºåº¦é‡ã€‚è€ƒè™‘åˆ°æ¯ä¸€ç±»æ ·æœ¬é›†çš„å¤§å°å¯èƒ½ä¸åŒï¼ˆå¯†åº¦åˆ†å¸ƒä¸å‡ï¼‰ï¼Œæ•…æˆ‘ä»¬å¯¹è¿™ä¸ªè·ç¦»åŠ ä»¥æƒé‡ï¼Œå› æ­¤å®šä¹‰ç±»é—´æ•£åº¦çŸ©é˜µ<span class="math inline">\(S_b=\sum_{i=1}^Mm_i(\vec{\mu}_i-\vec{\mu})(\vec{\mu}_i-\vec{\mu})^T\)</span>ã€‚</p><blockquote><p><span class="math inline">\((\vec{\mu}_i-\vec{\mu})(\vec{\mu}_i-\vec{\mu})^T\)</span>ä¹Ÿæ˜¯ä¸€ä¸ªåæ–¹å·®çŸ©é˜µï¼Œå®ƒåˆ»ç”»çš„æ˜¯ç¬¬<span class="math inline">\(i\)</span>ç±»ä¸æ€»ä½“ä¹‹é—´çš„å…³ç³»ã€‚</p></blockquote></li></ul><p>è®¾<span class="math inline">\(W\in R^{n\times (M-1)}\)</span>æ˜¯æŠ•å½±çŸ©é˜µã€‚ç»è¿‡æ¨å¯¼å¯ä»¥å¾—åˆ°æœ€å¤§åŒ–çš„ç›®æ ‡ï¼š<span class="math display">\[J=\frac{tr(W^TS_bW)}{tr(W^TS_wW)}\]</span></p><p>å…¶ä¸­<span class="math inline">\(tr(.)\)</span>è¡¨ç¤ºçŸ©é˜µçš„è¿¹ã€‚ä¸€ä¸ªçŸ©é˜µçš„è¿¹æ˜¯çŸ©é˜µå¯¹è§’çº¿çš„å…ƒç´ ä¹‹å’Œï¼Œå®ƒæ˜¯ä¸€ä¸ªçŸ©é˜µçš„ä¸å˜é‡ï¼Œä¹Ÿç­‰äºæ‰€æœ‰ç‰¹å¾å€¼ä¹‹å’Œã€‚</p><blockquote><p>è¿˜æœ‰ä¸€ä¸ªå¸¸ç”¨çš„çŸ©é˜µä¸å˜é‡æ˜¯çŸ©é˜µçš„è¡Œåˆ—å¼ï¼Œå®ƒç­‰äºçŸ©é˜µçš„æ‰€æœ‰ç‰¹å¾å€¼ä¹‹ç§¯ã€‚</p></blockquote><p>å¤šåˆ†ç±»LDAå°†æ ·æœ¬æŠ•å½±åˆ°<span class="math inline">\(M-1\)</span>ç»´ç©ºé—´ï¼Œå› æ­¤å®ƒæ˜¯ä¸€ç§ç»å…¸çš„ç›‘ç£é™ç»´æŠ€æœ¯ã€‚</p><h1 id="pythonå®æˆ˜">Pythonå®æˆ˜</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">import numpy as np</span><br><span class="line">from sklearn import datasets, linear_model, discriminant_analysis, model_selection</span><br></pre></td></tr></table></figure><p>åœ¨çº¿æ€§å›å½’é—®é¢˜ä¸­ï¼Œæ•°æ®é›†ä½¿ç”¨äº†scikit-learnè‡ªå¸¦çš„ä¸€ä¸ªæ•°æ®é›†ã€‚è¯¥æ•°æ®é›†æœ‰442ä¸ªæ ·æœ¬ï¼›æ¯ä¸ªæ ·æœ¬æœ‰10ä¸ªç‰¹å¾ï¼›æ¯ä¸ªç‰¹å¾éƒ½æ˜¯æµ®ç‚¹æ•°ï¼Œæ•°æ®éƒ½åœ¨-0.2ï½0.2ä¹‹é—´ï¼›æ ·æœ¬çš„ç›®æ ‡åœ¨æ•´æ•°25ï½346ä¹‹é—´ã€‚</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">def load_data():</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    åŠ è½½æ•°æ®é›†å¹¶éšæœºåˆ‡åˆ†æ•°æ®é›†ä¸ºä¸¤ä¸ªéƒ¨åˆ†ï¼Œå…¶ä¸­test_sizeæŒ‡å®šäº†æµ‹è¯•é›†ä¸ºåŸå§‹æ•°æ®é›†çš„å¤§å°/æ¯”ä¾‹</span><br><span class="line">    :return: listï¼šè®­ç»ƒæ ·æœ¬é›†ã€æµ‹è¯•æ ·æœ¬é›†ã€è®­ç»ƒæ ·æœ¬é›†å¯¹åº”çš„æ ‡ç­¾å€¼ã€æµ‹è¯•æ ·æœ¬é›†å¯¹åº”çš„æ ‡ç­¾å€¼</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    diabetes = datasets.load_diabetes()</span><br><span class="line">    return model_selection.train_test_split(diabetes.data, diabetes.target,</span><br><span class="line">                                            test_size=0.25, random_state=0)</span><br></pre></td></tr></table></figure><h2 id="çº¿æ€§å›å½’æ¨¡å‹">çº¿æ€§å›å½’æ¨¡å‹</h2><p>LinearRegressionæ˜¯scikit-learnæä¾›çš„çº¿æ€§å›å½’æ¨¡å‹ <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">class sklearn.linear_model.LinearRegression(fit_intercept=True, normalize=Fasle, copy_X=True, n_jobs=1)</span><br></pre></td></tr></table></figure></p><ul><li>å‚æ•°<ul><li>fit_intercept : boolean, optional, default True. æŒ‡å®šæ˜¯å¦éœ€è¦è®¡ç®—bå€¼, å¦‚æœä¸ºFalseåˆ™ä¸è®¡ç®—bå€¼ã€‚</li><li>normalize : boolean, optional, default False. å¦‚æœä¸ºTrueï¼Œé‚£ä¹ˆè®­ç»ƒæ ·æœ¬ä¼šåœ¨å›å½’ä¹‹å‰è¢«å½’ä¸€åŒ–ã€‚</li><li>copy_X : boolean, optional, default True. å¦‚æœä¸ºTrueï¼Œåˆ™ä¼šå¤åˆ¶Xã€‚</li><li>n_jobs : int or None, optional (default=None). ä»»åŠ¡å¹¶è¡Œæ—¶æŒ‡å®šçš„CPUæ•°é‡ï¼Œå¦‚æœä¸º-1åˆ™ä½¿ç”¨æ‰€æœ‰å¯ç”¨çš„CPUã€‚</li></ul></li><li>å±æ€§<ul><li>coef_ : æƒé‡å‘é‡</li><li>intercept_ : bå€¼</li></ul></li><li>æ–¹æ³•<ul><li>fit(X, y[, sample_weight]): è®­ç»ƒæ¨¡å‹</li><li>predict(X): ç”¨æ¨¡å‹è¿›è¡Œé¢„æµ‹ï¼Œè¿”å›é¢„æµ‹å€¼</li><li>score(X, y[, sample_weight]): è¿”å›é¢„æµ‹æ€§èƒ½å¾—åˆ†<ul><li>è®¾é¢„æµ‹é›†ä¸º<span class="math inline">\(T_{test}\)</span>ï¼ŒçœŸå®å€¼ä¸º<span class="math inline">\(y_i\)</span>ï¼ŒçœŸå®å€¼çš„å‡å€¼ä¸º<span class="math inline">\(\overline{y}\)</span>ï¼Œé¢„æµ‹å€¼ä¸º<span class="math inline">\(\hat{y}_i\)</span>ï¼Œåˆ™ï¼š<span class="math display">\[score=1-\frac{\sum_{T_{test}}(y_i-\hat{y}_i)^2}{(y_i-\overline{y})^2}\]</span><ul><li>scoreä¸è¶…è¿‡1ï¼Œä½†æ˜¯å¯èƒ½ä¸ºè´Ÿå€¼ï¼ˆé¢„æµ‹æ•ˆæœå¤ªå·®ï¼‰ã€‚</li><li>scoreè¶Šå¤§ï¼Œé¢„æµ‹æ€§èƒ½è¶Šå¥½ã€‚</li></ul></li></ul></li></ul></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">def demo_LinearRegression(*data):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    ä½¿ç”¨LinearRegressionå‡½æ•°</span><br><span class="line">    :param data: è®­ç»ƒæ ·æœ¬é›†ã€æµ‹è¯•æ ·æœ¬é›†ã€è®­ç»ƒæ ·æœ¬é›†å¯¹åº”çš„æ ‡ç­¾å€¼ã€æµ‹è¯•æ ·æœ¬é›†å¯¹åº”çš„æ ‡ç­¾å€¼</span><br><span class="line">    :return: æƒé‡å‘é‡ã€bå€¼ï¼Œé¢„æµ‹ç»“æœçš„å‡æ–¹è¯¯å·®ï¼Œé¢„æµ‹æ€§èƒ½å¾—åˆ†</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    X_train, X_test, y_train, y_test = data</span><br><span class="line">    regr = linear_model.LinearRegression()</span><br><span class="line">    regr.fit(X_train, y_train)</span><br><span class="line">    print(&apos;Coefficients: %s&apos; % regr.coef_)</span><br><span class="line">    print(&apos;Intercept: %.2f&apos; % regr.intercept_)</span><br><span class="line">    print(&apos;Residual sum of squares: %.2f&apos; % np.mean((regr.predict(X_test) - y_test) ** 2))</span><br><span class="line">    print(&apos;Score: %.2f&apos; % regr.score(X_test, y_test))</span><br></pre></td></tr></table></figure><p>è¯¥å‡½æ•°ç®€å•åœ°ä»è®­ç»ƒæ•°æ®é›†ä¸­å­¦ä¹ ï¼Œç„¶åä»æµ‹è¯•æ•°æ®ä¸­é¢„æµ‹ã€‚è°ƒç”¨è¯¥å‡½æ•°ï¼š</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">X_train, X_test, y_train, y_test = load_data()</span><br><span class="line">demo_LinearRegression(X_train, X_test, y_train, y_test)</span><br></pre></td></tr></table></figure><p>è¾“å‡ºç»“æœå¦‚ä¸‹ï¼š <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Coefficients: [ -43.26774487 -208.67053951  593.39797213  302.89814903 -560.27689824</span><br><span class="line">  261.47657106   -8.83343952  135.93715156  703.22658427   28.34844354]</span><br><span class="line">Intercept: 153.07</span><br><span class="line">Residual sum of squares: 3180.20</span><br><span class="line">Score: 0.36</span><br></pre></td></tr></table></figure></p><p>å¯ä»¥çœ‹åˆ°æµ‹è¯•é›†ä¸­é¢„æµ‹ç»“æœçš„å‡æ–¹è¯¯å·®ä¸º3180.20ï¼Œé¢„æµ‹æ€§èƒ½å¾—åˆ†ä»…ä¸º0.36ã€‚</p><h2 id="çº¿æ€§å›å½’æ¨¡å‹çš„æ­£åˆ™åŒ–">çº¿æ€§å›å½’æ¨¡å‹çš„æ­£åˆ™åŒ–</h2><p>å‰é¢ç†è®ºéƒ¨åˆ†æåˆ°å¯¹äºå¤šå…ƒçº¿æ€§å›å½’ï¼Œå½“<span class="math inline">\(\vec{x}^T\vec{x}\)</span>ä¸æ˜¯æ»¡ç§©çŸ©é˜µæ—¶å­˜åœ¨å¤šä¸ªè§£æè§£ï¼Œå®ƒä»¬éƒ½èƒ½ä½¿å¾—å‡æ–¹è¯¯å·®æœ€å°åŒ–ï¼Œå¸¸è§çš„åšæ³•æ˜¯å¼•å…¥æ­£åˆ™åŒ–é¡¹ã€‚æ‰€è°“æ­£åˆ™åŒ–ï¼Œå°±æ˜¯å¯¹æ¨¡å‹çš„å‚æ•°æ·»åŠ ä¸€äº›å…ˆéªŒå‡è®¾ï¼Œæ§åˆ¶æ¨¡å‹ç©ºé—´ï¼Œä»¥è¾¾åˆ°ä½¿å¾—æ¨¡å‹å¤æ‚åº¦è¾ƒå°çš„ç›®çš„ã€‚å²­å›å½’å’ŒLASSOæ˜¯ç›®å‰æœ€æµè¡Œçš„ä¸¤ç§çº¿æ€§å›å½’æ­£åˆ™åŒ–æ–¹æ³•ã€‚æ ¹æ®ä¸åŒçš„æ­£åˆ™åŒ–æ–¹å¼ï¼Œæœ‰ä¸åŒçš„æ–¹æ³•ï¼š</p><ul><li>Ridge Regression: æ­£åˆ™åŒ–é¡¹ä¸ºï¼š<span class="math inline">\(\alpha ||\vec{w}||_2^2,\alpha &gt;0\)</span>ã€‚</li><li>Lasso Regression: æ­£åˆ™åŒ–é¡¹ä¸ºï¼š<span class="math inline">\(\alpha ||\vec{w}||_1, \alpha &gt;0\)</span>ã€‚</li><li>Elastic Net: æ­£åˆ™åŒ–é¡¹ä¸ºï¼š<span class="math inline">\(\alpha \rho ||\vec{w}||_1+\frac{\alpha (1-\rho )}{2}||\vec{w}||_2^2,\alpha &gt;0,1\ge\rho \ge 0\)</span>ã€‚</li></ul><p>å…¶ä¸­ï¼Œæ­£åˆ™é¡¹ç³»æ•°<span class="math inline">\(\alpha\)</span>çš„é€‰æ‹©å¾ˆå…³é”®ï¼Œåˆå§‹å€¼å»ºè®®ä¸€å¼€å§‹è®¾ç½®ä¸º0ï¼Œå…ˆç¡®å®šä¸€ä¸ªæ¯”è¾ƒå¥½çš„learning rateï¼Œç„¶åå›ºå®šè¯¥learning rateï¼Œç»™<span class="math inline">\(\alpha\)</span>ä¸€ä¸ªå€¼ï¼ˆæ¯”å¦‚1.0ï¼‰ï¼Œç„¶åæ ¹æ®validation accuracyå°†<span class="math inline">\(\alpha\)</span>å¢å¤§æˆ–è€…ç¼©å°10å€ï¼ˆå¢å‡10å€ä¸ºç²—è°ƒèŠ‚ï¼Œå½“ä½ ç¡®å®šäº†<span class="math inline">\(\alpha\)</span>åˆé€‚çš„æ•°é‡çº§åï¼Œæ¯”å¦‚<span class="math inline">\(\alpha=0.01\)</span>ï¼Œå†è¿›ä¸€æ­¥ç»†è°ƒèŠ‚ä¸º0.02ã€0.03ã€0.0009ç­‰ï¼‰ã€‚</p><h3 id="å²­å›å½’">å²­å›å½’</h3><p>å²­å›å½’(Ridge Regression)æ˜¯ä¸€ç§æ­£åˆ™åŒ–æ–¹æ³•ï¼Œé€šè¿‡å€¼æŸå¤±å‡½æ•°ä¸­åŠ å…¥<span class="math inline">\(L_2\)</span>èŒƒæ•°æƒ©ç½šé¡¹ï¼Œæ¥æ§åˆ¶çº¿æ€§æ¨¡å‹çš„å¤æ‚ç¨‹åº¦ï¼Œä»è€Œä½¿å¾—æ¨¡å‹æ›´ç¨³å¥ã€‚Ridgeç±»å®ç°äº†å²­å›å½’æ¨¡å‹ï¼Œå…¶åŸå‹ä¸ºï¼š <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">class sklearn.linear_model.Ridge(alpha=1.0, fit_intercept=True, normalize=False, </span><br><span class="line">copy_X=True, max_iter=None, tol=0.001, solver=&apos;auto, random_state=None)</span><br></pre></td></tr></table></figure></p><ul><li>å‚æ•°<ul><li>alpha: <span class="math inline">\(\alpha\)</span>å€¼ï¼Œå…¶å€¼è¶Šå¤§åˆ™æ­£åˆ™åŒ–é¡¹çš„å æ¯”è¶Šå¤§ã€‚</li><li>fit_intercept: booleanï¼ŒæŒ‡å®šæ˜¯å¦éœ€è¦è®¡ç®—bå€¼ã€‚</li><li>max_iter: ä¸€ä¸ªæ•´æ•°ï¼ŒæŒ‡å®šæœ€å¤§è¿­ä»£æ¬¡æ•°ã€‚å¦‚æœä¸ºNoneåˆ™ä¸ºé»˜è®¤å€¼ï¼Œä¸åŒsolverçš„é»˜è®¤å€¼ä¸åŒã€‚</li><li>normalize: booleanï¼Œå¦‚æœä¸ºTrueï¼Œé‚£ä¹ˆè®­ç»ƒæ ·æœ¬ä¼šåœ¨å›å½’ä¹‹å‰è¢«å½’ä¸€åŒ–ã€‚</li><li>copy_X: booleanï¼Œå¦‚æœä¸ºTrueï¼Œåˆ™ä¼šå¤åˆ¶Xã€‚</li><li>solver: ä¸€ä¸ªå­—ç¬¦ä¸²ï¼ŒæŒ‡å®šæ±‚è§£æœ€ä¼˜åŒ–é—®é¢˜çš„ç®—æ³•ã€‚<ul><li>auto: æ ¹æ®æ•°æ®é›†è‡ªåŠ¨é€‰æ‹©ç®—æ³•</li><li>svd: ä½¿ç”¨å¥‡å¼‚å€¼åˆ†è§£æ¥è®¡ç®—å›å½’ç³»æ•°</li><li>cholesky: ä½¿ç”¨scipy.linalg.solveå‡½æ•°æ¥æ±‚è§£</li><li>sparse_cg: ä½¿ç”¨scipy.sparse.linalg.cgå‡½æ•°æ¥æ±‚è§£</li><li>lsqr: ä½¿ç”¨scipy.sparse.linalg.lsqrå‡½æ•°æ¥æ±‚è§£ï¼Œè¿ç®—é€Ÿåº¦æœ€å¿«</li><li>sag: ä½¿ç”¨Stochastic Average Gradient descentç®—æ³•æ±‚è§£æœ€ä¼˜åŒ–é—®é¢˜</li></ul></li><li>tol: ä¸€ä¸ªæµ®ç‚¹æ•°ï¼ŒæŒ‡å®šåˆ¤æ–­è¿­ä»£æ”¶æ•›ä¸å¦çš„é˜ˆå€¼ã€‚</li><li>random_state: ä¸€ä¸ªæ•´æ•°æˆ–è€…ä¸€ä¸ªRandomStateå®ä¾‹ï¼Œæˆ–è€…Noneï¼›åœ¨solver=sagæ—¶ä½¿ç”¨<ul><li>å¦‚æœä¸ºæ•´æ•°ï¼Œåˆ™å®ƒæŒ‡å®šäº†éšæœºæ•°ç”Ÿæˆå™¨çš„ç§å­</li><li>å¦‚æœä¸ºRandomStateå®ä¾‹ï¼Œåˆ™æŒ‡å®šä¾‹éšæœºæ•°ç”Ÿæˆå™¨</li><li>å¦‚æœä¸ºNoneï¼Œåˆ™ä½¿ç”¨é»˜è®¤çš„éšæœºæ•°ç”Ÿæˆå™¨</li></ul></li></ul></li><li>å±æ€§<ul><li>coef_: æƒé‡å‘é‡</li><li>intercept_: bå€¼</li><li>n_iter_: å®é™…è¿­ä»£æ¬¡æ•°</li></ul></li><li>æ–¹æ³•<ul><li>fit(X, y[, sample_weight]): è®­ç»ƒæ¨¡å‹</li><li>predict(X): ç”¨æ¨¡å‹è¿›è¡Œé¢„æµ‹ï¼Œè¿”å›é¢„æµ‹å€¼</li><li>score(X, y[, sample_weight]): è¿”å›é¢„æµ‹æ€§èƒ½å¾—åˆ†<ul><li>è®¾é¢„æµ‹é›†ä¸º<span class="math inline">\(T_{test}\)</span>ï¼ŒçœŸå®å€¼ä¸º<span class="math inline">\(y_i\)</span>ï¼ŒçœŸå®å€¼çš„å‡å€¼ä¸º<span class="math inline">\(\overline{y}\)</span>ï¼Œé¢„æµ‹å€¼ä¸º<span class="math inline">\(\hat{y}_i\)</span>ï¼Œåˆ™ï¼š<span class="math display">\[score=1-\frac{\sum_{T_{test}}(y_i-\hat{y}_i)^2}{(y_i-\overline{y})^2}\]</span><ul><li>scoreä¸è¶…è¿‡1ï¼Œä½†æ˜¯å¯èƒ½ä¸ºè´Ÿå€¼ï¼ˆé¢„æµ‹æ•ˆæœå¤ªå·®ï¼‰ã€‚</li><li>scoreè¶Šå¤§ï¼Œé¢„æµ‹æ€§èƒ½è¶Šå¥½ã€‚</li></ul></li></ul></li></ul></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">def demo_Ridge(*data):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    ä½¿ç”¨Ridgeå‡½æ•°</span><br><span class="line">    :param data: è®­ç»ƒæ ·æœ¬é›†ã€æµ‹è¯•æ ·æœ¬é›†ã€è®­ç»ƒæ ·æœ¬é›†å¯¹åº”çš„æ ‡ç­¾å€¼ã€æµ‹è¯•æ ·æœ¬é›†å¯¹åº”çš„æ ‡ç­¾å€¼</span><br><span class="line">    :return: æƒé‡å‘é‡ã€bå€¼ï¼Œé¢„æµ‹ç»“æœçš„å‡æ–¹è¯¯å·®ï¼Œé¢„æµ‹æ€§èƒ½å¾—åˆ†</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    X_train, X_test, y_train, y_test = data</span><br><span class="line">    regr = linear_model.Ridge()</span><br><span class="line">    regr.fit(X_train, y_train)</span><br><span class="line">    print(&apos;Coefficients: %s&apos; % regr.coef_)</span><br><span class="line">    print(&apos;Intercept: %.2f&apos; % regr.intercept_)</span><br><span class="line">    print(&apos;Residual sum of squares: %.2f&apos; % np.mean((regr.predict(X_test) - y_test) ** 2))</span><br><span class="line">    print(&apos;Score: %.2f&apos; % regr.score(X_test, y_test))</span><br></pre></td></tr></table></figure><p>è¯¥å‡½æ•°ç®€å•åœ°ä»è®­ç»ƒæ•°æ®é›†ä¸­å­¦ä¹ ï¼Œç„¶åä»æµ‹è¯•æ•°æ®é›†ä¸­é¢„æµ‹ã€‚è¿™é‡Œçš„Ridgeçš„æ‰€æœ‰å‚æ•°éƒ½é‡‡ç”¨é»˜è®¤å€¼ã€‚è°ƒç”¨è¯¥å‡½æ•°ï¼š</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">X_train, X_test, y_train, y_test = load_data()</span><br><span class="line">demo_Ridge(X_train, X_test, y_train, y_test)</span><br></pre></td></tr></table></figure><p>è¾“å‡ºç»“æœå¦‚ä¸‹ï¼š <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Coefficients: [  21.19927911  -60.47711393  302.87575204  179.41206395    8.90911449</span><br><span class="line">  -28.8080548  -149.30722541  112.67185758  250.53760873   99.57749017]</span><br><span class="line">Intercept: 152.45</span><br><span class="line">Residual sum of squares: 3192.33</span><br><span class="line">Score: 0.36</span><br></pre></td></tr></table></figure></p><p>å¯ä»¥çœ‹åˆ°æµ‹è¯•é›†ä¸­é¢„æµ‹ç»“æœçš„å‡æ–¹è¯¯å·®ä¸º3192.33ï¼Œé¢„æµ‹æ€§èƒ½å¾—åˆ†ä»…ä¸º0.36ã€‚</p><p>ä¸‹é¢æ£€éªŒä¸åŒçš„<span class="math inline">\(\alpha\)</span>å€¼å¯¹äºé¢„æµ‹æ€§èƒ½çš„å½±å“ï¼Œç»™å‡ºæµ‹è¯•å‡½æ•°ï¼š</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">def demo_Ridge_alpha(*data):</span><br><span class="line">    X_train, X_test, y_train, y_test = data</span><br><span class="line">    alphas = [0.01, 0.02, 0.05, 0.1, 0.2, 0.5, 1, 2, 5, 10, 20, 50, 100, 200, 500, 1000]</span><br><span class="line">    scores = []</span><br><span class="line">    for i, alpha in enumerate(alphas):</span><br><span class="line">        regr = linear_model.Ridge(alpha=alpha)</span><br><span class="line">        regr.fit(X_train, y_train)</span><br><span class="line">        scores.append(regr.score(X_test, y_test))</span><br><span class="line">    ## ç»˜å›¾</span><br><span class="line">    fig = plt.figure()</span><br><span class="line">    ax = fig.add_subplot(1, 1, 1)</span><br><span class="line">    ax.plot(alphas, scores)</span><br><span class="line">    ax.set_xlabel(r&quot;$\alpha$&quot;)</span><br><span class="line">    ax.set_ylabel(r&quot;score&quot;)</span><br><span class="line">    ax.set_xscale(&apos;log&apos;)</span><br><span class="line">    ax.set_title(&quot;Ridge&quot;)</span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure><p>ä¸ºäº†ä¾¿äºè§‚å¯Ÿç»“æœï¼Œå°†<span class="math inline">\(x\)</span>è½´è®¾ç½®ä¸ºäº†å¯¹æ•°åæ ‡ã€‚è°ƒç”¨è¯¥å‡½æ•°ï¼š <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">X_train, X_test, y_train, y_test = load_data()</span><br><span class="line">demo_Ridge_alpha(X_train, X_test, y_train, y_test)</span><br></pre></td></tr></table></figure></p><p>è¾“å‡ºç»“æœå¦‚ä¸‹å›¾æ‰€ç¤ºï¼š <img src="/images/MachineLearning/LinearModel/20190724_ML_Ridge.png"></p><p>å¯ä»¥çœ‹åˆ°ï¼Œå½“<span class="math inline">\(\alpha\)</span>è¶…è¿‡1ä¹‹åï¼Œéšç€<span class="math inline">\(\alpha\)</span>çš„å¢é•¿ï¼Œé¢„æµ‹æ€§èƒ½æ€¥å‰§ä¸‹é™ã€‚è¿™æ˜¯å› ä¸º<span class="math inline">\(\alpha\)</span>è¾ƒå¤§æ—¶ï¼Œæ­£åˆ™åŒ–é¡¹å½±å“è¾ƒå¤§ï¼Œæ¨¡å‹è¶‹äºç®€å•ã€‚</p><h3 id="lassoå›å½’">Lassoå›å½’</h3><p>Lassoå›å½’å’Œå²­å›å½’çš„åŒºåˆ«å°±åœ¨äºå®ƒçš„æƒ©ç½šé¡¹æ˜¯åŸºäºL1èŒƒæ•°ï¼Œå› æ­¤å®ƒå¯ä»¥å°†ç³»æ•°æ§åˆ¶æ”¶ç¼©åˆ°0ï¼Œä»è€Œè¾¾åˆ°å˜é‡é€‰æ‹©çš„æ•ˆæœã€‚Lassoç±»å®ç°äº†Lassoå›å½’æ¨¡å‹ï¼š <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">class sklearn.linear_model.Lasso(alpha=1.0, fit_intercept=True, normalize=False,</span><br><span class="line">                 precompute=False, copy_X=True, max_iter=1000,</span><br><span class="line">                 tol=1e-4, warm_start=False, positive=False,</span><br><span class="line">                 random_state=None, selection=&apos;cyclic&apos;)</span><br></pre></td></tr></table></figure></p><ul><li>å‚æ•°<ul><li>alpha: <span class="math inline">\(\alpha\)</span>å€¼ï¼Œå…¶å€¼è¶Šå¤§åˆ™æ­£åˆ™åŒ–é¡¹çš„å æ¯”è¶Šå¤§ã€‚</li><li>fit_intercept: booleanï¼ŒæŒ‡å®šæ˜¯å¦éœ€è¦è®¡ç®—bå€¼ã€‚</li><li>max_iter: ä¸€ä¸ªæ•´æ•°ï¼ŒæŒ‡å®šæœ€å¤§è¿­ä»£æ¬¡æ•°ã€‚å¦‚æœä¸ºNoneåˆ™ä¸ºé»˜è®¤å€¼ï¼Œä¸åŒsolverçš„é»˜è®¤å€¼ä¸åŒã€‚</li><li>normalize: booleanï¼Œå¦‚æœä¸ºTrueï¼Œé‚£ä¹ˆè®­ç»ƒæ ·æœ¬ä¼šåœ¨å›å½’ä¹‹å‰è¢«å½’ä¸€åŒ–ã€‚</li><li>copy_X: booleanï¼Œå¦‚æœä¸ºTrueï¼Œåˆ™ä¼šå¤åˆ¶Xã€‚</li><li>precompute: boolean/åºåˆ—ã€‚å†³å®šæ˜¯å¦æå‰è®¡ç®—GramçŸ©é˜µæ¥åŠ é€Ÿè®¡ç®—ã€‚</li><li>tol: ä¸€ä¸ªæµ®ç‚¹æ•°ï¼ŒæŒ‡å®šåˆ¤æ–­è¿­ä»£æ”¶æ•›ä¸å¦çš„é˜ˆå€¼ã€‚</li><li>warm_start: booleanï¼Œå¦‚æœä¸ºTrueï¼Œé‚£ä¹ˆä½¿ç”¨å‰ä¸€æ¬¡è®­ç»ƒç»“æœç»§ç»­è®­ç»ƒã€‚å¦åˆ™ä»å¤´å¼€å§‹è®­ç»ƒã€‚</li><li>positive: booleanï¼Œå¦‚æœä¸ºTrueï¼Œé‚£ä¹ˆå¼ºåˆ¶è¦æ±‚æƒé‡å‘é‡çš„åˆ†é‡éƒ½ä¸ºæ­£æ•°ã€‚</li><li>selection: ä¸€ä¸ªå­—ç¬¦ä¸²ï¼ŒæŒ‡å®šäº†æ¯è½®è¿­ä»£æ—¶é€‰æ‹©æƒé‡å‘é‡çš„å“ªä¸ªåˆ†é‡æ¥æ›´æ–°ã€‚<ul><li>random: éšæœºé€‰æ‹©æƒé‡å‘é‡çš„ä¸€ä¸ªåˆ†é‡æ¥æ›´æ–°</li><li>cyclic: ä»å‰å‘åä¾æ¬¡é€‰æ‹©æƒé‡å‘é‡çš„ä¸€ä¸ªåˆ†é‡æ¥æ›´æ–°</li></ul></li><li>random_state: ä¸€ä¸ªæ•´æ•°æˆ–è€…ä¸€ä¸ªRandomStateå®ä¾‹ï¼Œæˆ–è€…Noneï¼›åœ¨solver=sagæ—¶ä½¿ç”¨<ul><li>å¦‚æœä¸ºæ•´æ•°ï¼Œåˆ™å®ƒæŒ‡å®šäº†éšæœºæ•°ç”Ÿæˆå™¨çš„ç§å­</li><li>å¦‚æœä¸ºRandomStateå®ä¾‹ï¼Œåˆ™æŒ‡å®šä¾‹éšæœºæ•°ç”Ÿæˆå™¨</li><li>å¦‚æœä¸ºNoneï¼Œåˆ™ä½¿ç”¨é»˜è®¤çš„éšæœºæ•°ç”Ÿæˆå™¨</li></ul></li></ul></li><li>å±æ€§<ul><li>coef_: æƒé‡å‘é‡</li><li>intercept_: bå€¼</li><li>n_iter_: å®é™…è¿­ä»£æ¬¡æ•°</li></ul></li><li>æ–¹æ³•<ul><li>fit(X, y[, sample_weight]): è®­ç»ƒæ¨¡å‹</li><li>predict(X): ç”¨æ¨¡å‹è¿›è¡Œé¢„æµ‹ï¼Œè¿”å›é¢„æµ‹å€¼</li><li>score(X, y[, sample_weight]): è¿”å›é¢„æµ‹æ€§èƒ½å¾—åˆ†<ul><li>è®¾é¢„æµ‹é›†ä¸º<span class="math inline">\(T_{test}\)</span>ï¼ŒçœŸå®å€¼ä¸º<span class="math inline">\(y_i\)</span>ï¼ŒçœŸå®å€¼çš„å‡å€¼ä¸º<span class="math inline">\(\overline{y}\)</span>ï¼Œé¢„æµ‹å€¼ä¸º<span class="math inline">\(\hat{y}_i\)</span>ï¼Œåˆ™ï¼š<span class="math display">\[score=1-\frac{\sum_{T_{test}}(y_i-\hat{y}_i)^2}{(y_i-\overline{y})^2}\]</span><ul><li>scoreä¸è¶…è¿‡1ï¼Œä½†æ˜¯å¯èƒ½ä¸ºè´Ÿå€¼ï¼ˆé¢„æµ‹æ•ˆæœå¤ªå·®ï¼‰ã€‚</li><li>scoreè¶Šå¤§ï¼Œé¢„æµ‹æ€§èƒ½è¶Šå¥½ã€‚</li></ul></li></ul></li></ul></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">def demo_Lasso(*data):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    ä½¿ç”¨Lassoå‡½æ•°</span><br><span class="line">    :param data: è®­ç»ƒæ ·æœ¬é›†ã€æµ‹è¯•æ ·æœ¬é›†ã€è®­ç»ƒæ ·æœ¬é›†å¯¹åº”çš„æ ‡ç­¾å€¼ã€æµ‹è¯•æ ·æœ¬é›†å¯¹åº”çš„æ ‡ç­¾å€¼</span><br><span class="line">    :return: æƒé‡å‘é‡ã€bå€¼ï¼Œé¢„æµ‹ç»“æœçš„å‡æ–¹è¯¯å·®ï¼Œé¢„æµ‹æ€§èƒ½å¾—åˆ†</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    X_train, X_test, y_train, y_test = data</span><br><span class="line">    regr = linear_model.Lasso()</span><br><span class="line">    regr.fit(X_train, y_train)</span><br><span class="line">    print(&apos;Coefficients: %s&apos; % regr.coef_)</span><br><span class="line">    print(&apos;Intercept: %.2f&apos; % regr.intercept_)</span><br><span class="line">    print(&apos;Residual sum of squares: %.2f&apos; % np.mean((regr.predict(X_test) - y_test) ** 2))</span><br><span class="line">    print(&apos;Score: %.2f&apos; % regr.score(X_test, y_test))</span><br></pre></td></tr></table></figure><p>è°ƒç”¨è¯¥å‡½æ•°ï¼š <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">X_train, X_test, y_train, y_test = load_data()</span><br><span class="line">demo_Lasso(X_train, X_test, y_train, y_test)</span><br></pre></td></tr></table></figure></p><p>è¾“å‡ºç»“æœï¼š <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Coefficients: [  0.          -0.         442.67992538   0.           0.</span><br><span class="line">   0.          -0.           0.         330.76014648   0.        ]</span><br><span class="line">Intercept: 152.52</span><br><span class="line">Residual sum of squares: 3583.42</span><br><span class="line">Score: 0.28</span><br></pre></td></tr></table></figure></p><p>ä¸‹é¢æ£€éªŒä¸åŒçš„<span class="math inline">\(\alpha\)</span>å€¼å¯¹äºé¢„æµ‹æ€§èƒ½çš„å½±å“ï¼š <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">def demo_Lasso_alpha(*data):</span><br><span class="line">    X_train, X_test, y_train, y_test = data</span><br><span class="line">    alphas = [0.01, 0.02, 0.05, 0.1, 0.2, 0.5, 1, 2, 5, 10, 20, 50, 100, 200, 500, 1000]</span><br><span class="line">    scores = []</span><br><span class="line">    for i, alpha in enumerate(alphas):</span><br><span class="line">        regr = linear_model.Lasso(alpha=alpha)</span><br><span class="line">        regr.fit(X_train, y_train)</span><br><span class="line">        scores.append(regr.score(X_test, y_test))</span><br><span class="line">    ## ç»˜å›¾</span><br><span class="line">    fig = plt.figure()</span><br><span class="line">    ax = fig.add_subplot(1, 1, 1)</span><br><span class="line">    ax.plot(alphas, scores)</span><br><span class="line">    ax.set_xlabel(r&quot;$\alpha$&quot;)</span><br><span class="line">    ax.set_ylabel(r&quot;score&quot;)</span><br><span class="line">    ax.set_xscale(&apos;log&apos;)</span><br><span class="line">    ax.set_title(&quot;Lasso&quot;)</span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure></p><p>è°ƒç”¨è¯¥å‡½æ•°ï¼š <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">X_train, X_test, y_train, y_test = load_data()</span><br><span class="line">demo_Lasso_alpha(X_train, X_test, y_train, y_test)</span><br></pre></td></tr></table></figure></p><p>è¾“å‡ºç»“æœå¦‚ä¸‹ï¼š <img src="/images/MachineLearning/LinearModel/20190725_ML_Lasso.png"></p><p>å¯ä»¥çœ‹å‡ºï¼Œå½“<span class="math inline">\(\alpha\)</span>è¶…è¿‡1ä¹‹åï¼Œéšç€<span class="math inline">\(\alpha\)</span>çš„å¢é•¿ï¼Œé¢„æµ‹æ€§èƒ½æ€¥å‰§ä¸‹é™ã€‚</p><h3 id="elasticnetå›å½’">ElasticNetå›å½’</h3><p>ElasticNetå›å½’æ˜¯å¯¹Lassoå›å½’å’Œå²­å›å½’çš„èåˆï¼Œå…¶æƒ©ç½šé¡¹æ˜¯L1èŒƒæ•°å’ŒL2èŒƒæ•°çš„ä¸€ä¸ªæƒè¡¡ã€‚ElasticNetç±»å®ç°äº†ElasticNetå›å½’ï¼š</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">class sklearn.linear_model.ElasticNet(alpha=1.0, l1_ratio=0.5, fit_intercept=True,</span><br><span class="line">                 normalize=False, precompute=False, max_iter=1000,</span><br><span class="line">                 copy_X=True, tol=1e-4, warm_start=False, positive=False,</span><br><span class="line">                 random_state=None, selection=&apos;cyclic&apos;)</span><br></pre></td></tr></table></figure><ul><li>å‚æ•°<ul><li>alpha: <span class="math inline">\(\alpha\)</span>å€¼ã€‚</li><li>l1_ratio: <span class="math inline">\(\rho\)</span>å€¼ã€‚</li><li>fit_intercept: booleanï¼ŒæŒ‡å®šæ˜¯å¦éœ€è¦è®¡ç®—bå€¼ã€‚</li><li>max_iter: ä¸€ä¸ªæ•´æ•°ï¼ŒæŒ‡å®šæœ€å¤§è¿­ä»£æ¬¡æ•°ã€‚å¦‚æœä¸ºNoneåˆ™ä¸ºé»˜è®¤å€¼ï¼Œä¸åŒsolverçš„é»˜è®¤å€¼ä¸åŒã€‚</li><li>normalize: booleanï¼Œå¦‚æœä¸ºTrueï¼Œé‚£ä¹ˆè®­ç»ƒæ ·æœ¬ä¼šåœ¨å›å½’ä¹‹å‰è¢«å½’ä¸€åŒ–ã€‚</li><li>copy_X: booleanï¼Œå¦‚æœä¸ºTrueï¼Œåˆ™ä¼šå¤åˆ¶Xã€‚</li><li>precompute: boolean/åºåˆ—ã€‚å†³å®šæ˜¯å¦æå‰è®¡ç®—GramçŸ©é˜µæ¥åŠ é€Ÿè®¡ç®—ã€‚</li><li>tol: ä¸€ä¸ªæµ®ç‚¹æ•°ï¼ŒæŒ‡å®šåˆ¤æ–­è¿­ä»£æ”¶æ•›ä¸å¦çš„é˜ˆå€¼ã€‚</li><li>warm_start: booleanï¼Œå¦‚æœä¸ºTrueï¼Œé‚£ä¹ˆä½¿ç”¨å‰ä¸€æ¬¡è®­ç»ƒç»“æœç»§ç»­è®­ç»ƒã€‚å¦åˆ™ä»å¤´å¼€å§‹è®­ç»ƒã€‚</li><li>positive: booleanï¼Œå¦‚æœä¸ºTrueï¼Œé‚£ä¹ˆå¼ºåˆ¶è¦æ±‚æƒé‡å‘é‡çš„åˆ†é‡éƒ½ä¸ºæ­£æ•°ã€‚</li><li>selection: ä¸€ä¸ªå­—ç¬¦ä¸²ï¼ŒæŒ‡å®šäº†æ¯è½®è¿­ä»£æ—¶é€‰æ‹©æƒé‡å‘é‡çš„å“ªä¸ªåˆ†é‡æ¥æ›´æ–°ã€‚<ul><li>random: éšæœºé€‰æ‹©æƒé‡å‘é‡çš„ä¸€ä¸ªåˆ†é‡æ¥æ›´æ–°</li><li>cyclic: ä»å‰å‘åä¾æ¬¡é€‰æ‹©æƒé‡å‘é‡çš„ä¸€ä¸ªåˆ†é‡æ¥æ›´æ–°</li></ul></li><li>random_state: ä¸€ä¸ªæ•´æ•°æˆ–è€…ä¸€ä¸ªRandomStateå®ä¾‹ï¼Œæˆ–è€…Noneï¼›åœ¨solver=sagæ—¶ä½¿ç”¨<ul><li>å¦‚æœä¸ºæ•´æ•°ï¼Œåˆ™å®ƒæŒ‡å®šäº†éšæœºæ•°ç”Ÿæˆå™¨çš„ç§å­</li><li>å¦‚æœä¸ºRandomStateå®ä¾‹ï¼Œåˆ™æŒ‡å®šä¾‹éšæœºæ•°ç”Ÿæˆå™¨</li><li>å¦‚æœä¸ºNoneï¼Œåˆ™ä½¿ç”¨é»˜è®¤çš„éšæœºæ•°ç”Ÿæˆå™¨</li></ul></li></ul></li><li>å±æ€§<ul><li>coef_: æƒé‡å‘é‡</li><li>intercept_: bå€¼</li><li>n_iter_: å®é™…è¿­ä»£æ¬¡æ•°</li></ul></li><li>æ–¹æ³•<ul><li>fit(X, y[, sample_weight]): è®­ç»ƒæ¨¡å‹</li><li>predict(X): ç”¨æ¨¡å‹è¿›è¡Œé¢„æµ‹ï¼Œè¿”å›é¢„æµ‹å€¼</li><li>score(X, y[, sample_weight]): è¿”å›é¢„æµ‹æ€§èƒ½å¾—åˆ†<ul><li>è®¾é¢„æµ‹é›†ä¸º<span class="math inline">\(T_{test}\)</span>ï¼ŒçœŸå®å€¼ä¸º<span class="math inline">\(y_i\)</span>ï¼ŒçœŸå®å€¼çš„å‡å€¼ä¸º<span class="math inline">\(\overline{y}\)</span>ï¼Œé¢„æµ‹å€¼ä¸º<span class="math inline">\(\hat{y}_i\)</span>ï¼Œåˆ™ï¼š<span class="math display">\[score=1-\frac{\sum_{T_{test}}(y_i-\hat{y}_i)^2}{(y_i-\overline{y})^2}\]</span><ul><li>scoreä¸è¶…è¿‡1ï¼Œä½†æ˜¯å¯èƒ½ä¸ºè´Ÿå€¼ï¼ˆé¢„æµ‹æ•ˆæœå¤ªå·®ï¼‰ã€‚</li><li>scoreè¶Šå¤§ï¼Œé¢„æµ‹æ€§èƒ½è¶Šå¥½ã€‚</li></ul></li></ul></li></ul></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">def demo_ElasticNet(*data):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    ä½¿ç”¨ElasticNetå‡½æ•°</span><br><span class="line">    :param data: è®­ç»ƒæ ·æœ¬é›†ã€æµ‹è¯•æ ·æœ¬é›†ã€è®­ç»ƒæ ·æœ¬é›†å¯¹åº”çš„æ ‡ç­¾å€¼ã€æµ‹è¯•æ ·æœ¬é›†å¯¹åº”çš„æ ‡ç­¾å€¼</span><br><span class="line">    :return: æƒé‡å‘é‡ã€bå€¼ï¼Œé¢„æµ‹ç»“æœçš„å‡æ–¹è¯¯å·®ï¼Œé¢„æµ‹æ€§èƒ½å¾—åˆ†</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    X_train, X_test, y_train, y_test = data</span><br><span class="line">    regr = linear_model.ElasticNet()</span><br><span class="line">    regr.fit(X_train, y_train)</span><br><span class="line">    print(&apos;Coefficients: %s&apos; % regr.coef_)</span><br><span class="line">    print(&apos;Intercept: %.2f&apos; % regr.intercept_)</span><br><span class="line">    print(&apos;Residual sum of squares: %.2f&apos; % np.mean((regr.predict(X_test) - y_test) ** 2))</span><br><span class="line">    print(&apos;Score: %.2f&apos; % regr.score(X_test, y_test))</span><br></pre></td></tr></table></figure><p>è°ƒç”¨è¯¥å‡½æ•°ï¼š <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">X_train, X_test, y_train, y_test = load_data()</span><br><span class="line">demo_ElasticNet(X_train, X_test, y_train, y_test)</span><br></pre></td></tr></table></figure></p><p>è¾“å‡ºç»“æœå¦‚ä¸‹ï¼š <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Coefficients: [ 0.40560736  0.          3.76542456  2.38531508  0.58677945  0.22891647</span><br><span class="line"> -2.15858149  2.33867566  3.49846121  1.98299707]</span><br><span class="line">Intercept: 151.93</span><br><span class="line">Residual sum of squares: 4922.36</span><br><span class="line">Score: 0.01</span><br></pre></td></tr></table></figure></p><p>ä¸‹é¢æ£€éªŒä¸åŒ$,$å€¼å¯¹é¢„æµ‹æ€§èƒ½çš„å½±å“ï¼š <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">from mpl_toolkits.mplot3d import Axes3D</span><br><span class="line">from matplotlib import cm</span><br></pre></td></tr></table></figure></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">def demo_ElasticNet_alpha_rho(*data):</span><br><span class="line">    X_train, X_test, y_train, y_test = data</span><br><span class="line">    alphas = np.logspace(-2, 2)</span><br><span class="line">    rhos = np.linspace(0.01, 1)</span><br><span class="line">    scores = []</span><br><span class="line">    for alpha in alphas:</span><br><span class="line">        for rho in rhos:</span><br><span class="line">            regr = linear_model.ElasticNet(alpha=alpha, l1_ratio=rho)</span><br><span class="line">            regr.fit(X_train, y_train)</span><br><span class="line">            scores.append(regr.score(X_test, y_test))</span><br><span class="line">    ## ç»˜å›¾</span><br><span class="line">    alphas, rhos = np.meshgrid(alphas, rhos)</span><br><span class="line">    scores = np.array(scores).reshape(alphas.shape)</span><br><span class="line">    fig = plt.figure()</span><br><span class="line">    ax = Axes3D(fig)</span><br><span class="line">    surf = ax.plot_surface(alphas, rhos, scores, rstride=1, cstride=1, cmap=cm.jet, linewidth=0, antialiased=False)</span><br><span class="line">    fig.colorbar(surf, shrink=0.5, aspect=5)</span><br><span class="line">    ax.set_xlabel(r&quot;$\alpha$&quot;)</span><br><span class="line">    ax.set_ylabel(r&quot;$\rho$&quot;)</span><br><span class="line">    ax.set_zlabel(&quot;score&quot;)</span><br><span class="line">    ax.set_title(&quot;ElasticNet&quot;)</span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure><p>è°ƒç”¨è¯¥å‡½æ•°ï¼š <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">X_train, X_test, y_train, y_test = load_data()</span><br><span class="line">demo_ElasticNet_alpha_rho(X_train, X_test, y_train, y_test)</span><br></pre></td></tr></table></figure></p><p>è¾“å‡ºç»“æœå¦‚ä¸‹ï¼š <img src="/images/MachineLearning/LinearModel/20190725_ML_ElasticNet.png"></p><p>å¯ä»¥çœ‹åˆ°éšç€<span class="math inline">\(\alpha\)</span>çš„å¢å¤§ï¼Œé¢„æµ‹æ€§èƒ½ä¸‹é™ï¼Œè€Œ<span class="math inline">\(\rho\)</span>å½±å“çš„æ˜¯æ€§èƒ½ä¸‹é™çš„é€Ÿåº¦ã€‚</p><h2 id="é€»è¾‘å›å½’-1">é€»è¾‘å›å½’</h2><p>åœ¨scikit-learnä¸­ï¼ŒLogisticRegressionå®ç°äº†é€»è¾‘å›å½’åŠŸèƒ½ï¼š <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">class sklearn.linear_model.LogisticRegression(penalty=&apos;l2&apos;, dual=False, tol=0.0001, C=1.0,</span><br><span class="line">                 fit_intercept=True, intercept_scaling=1, class_weight=None,</span><br><span class="line">                 random_state=None, solver=&apos;warn&apos;, max_iter=100,</span><br><span class="line">                 multi_class=&apos;warn&apos;, verbose=0, warm_start=False, n_jobs=None,</span><br><span class="line">                 l1_ratio=None)</span><br></pre></td></tr></table></figure></p><ul><li>å‚æ•°<ul><li>penalty: ä¸€ä¸ªå­—ç¬¦ä¸²ï¼ŒæŒ‡å®šäº†æ­£åˆ™åŒ–ç­–ç•¥<ul><li>l2: åˆ™ä¼˜åŒ–ç›®æ ‡å‡½æ•°ä¸ºï¼š<span class="math inline">\(\frac{1}{2}||\vec{w}||_2^2+CL(\vec{w}),C&gt;0\)</span>ï¼Œ<span class="math inline">\(L(\vec{w})\)</span>ä¸ºæå¤§ä¼¼ç„¶å‡½æ•°</li><li>l1: åˆ™ä¼˜åŒ–ç›®æ ‡å‡½æ•°ä¸ºï¼š<span class="math inline">\(||\vec{w}||_1 +CL(\vec{w}),C&gt;0\)</span>ï¼Œ<span class="math inline">\(L(\vec{w})\)</span>ä¸ºæå¤§ä¼¼ç„¶å‡½æ•°</li></ul></li><li>dual: booleanï¼Œå¦‚æœä¸ºTrueï¼Œåˆ™æ±‚è§£å¯¹å¶å½¢å¼ï¼ˆåªåœ¨penalty='l2'ä¸”solver='liblinear'æœ‰å¯¹å¶å½¢å¼ï¼‰ï¼›å¦‚æœä¸ºFalseï¼Œåˆ™æ±‚è§£åŸå§‹å½¢å¼ã€‚</li><li>C: ä¸€ä¸ªæµ®ç‚¹æ•°ï¼ŒæŒ‡å®šäº†ç½šé¡¹ç³»æ•°çš„å€’æ•°ï¼Œå€¼è¶Šå°æ­£åˆ™åŒ–é¡¹è¶Šå¤§ã€‚</li><li>fit_intercept: booleanï¼ŒæŒ‡å®šæ˜¯å¦éœ€è¦è®¡ç®—bå€¼ã€‚</li><li>intercept_scaling: ä¸€ä¸ªæµ®ç‚¹æ•°ï¼Œåªå½“solver='liblinear'æ—¶æœ‰æ„ä¹‰ã€‚å½“é‡‡ç”¨fit_interceptæ—¶ï¼Œç›¸å½“äºäººé€ ä¸€ä¸ªç‰¹å¾å‡ºæ¥ï¼Œè¯¥ç‰¹å¾æ’ä¸º1ï¼Œå…¶æƒé‡ä¸ºbã€‚åœ¨è®¡ç®—æ­£åˆ™åŒ–é¡¹æ—¶ï¼Œè¯¥äººé€ ç‰¹å¾ä¹Ÿè¢«è€ƒè™‘äº†ï¼Œå› æ­¤ä¸ºäº†é™ä½è¿™ä¸ªäººé€ ç‰¹å¾çš„å½±å“ï¼Œéœ€è¦æä¾›intercept_scalingã€‚</li><li>class_weight: ä¸€ä¸ªå­—å…¸æˆ–è€…å­—ç¬¦ä¸²<ul><li>å­—å…¸ï¼šå­—å…¸ç»™å‡ºæ¯ä¸ªåˆ†ç±»çš„æƒé‡ï¼Œå¦‚{class_label: weight}</li><li>â€˜balanced'ï¼šæ¯ä¸ªåˆ†ç±»çš„æƒé‡ä¸è¯¥åˆ†ç±»åœ¨æ ·æœ¬é›†ä¸­å‡ºç°çš„é¢‘ç‡æˆåæ¯”</li><li>æœªæŒ‡å®šï¼šæ¯ä¸ªåˆ†ç±»çš„æƒé‡éƒ½ä¸º1</li></ul></li><li>max_iter: ä¸€ä¸ªæ•´æ•°ï¼ŒæŒ‡å®šæœ€å¤§è¿­ä»£æ¬¡æ•°ã€‚</li><li>random_state: ä¸€ä¸ªæ•´æ•°æˆ–è€…ä¸€ä¸ªRandomStateå®ä¾‹ï¼Œæˆ–è€…Noneï¼›åœ¨solver=sagæ—¶ä½¿ç”¨<ul><li>å¦‚æœä¸ºæ•´æ•°ï¼Œåˆ™å®ƒæŒ‡å®šäº†éšæœºæ•°ç”Ÿæˆå™¨çš„ç§å­</li><li>å¦‚æœä¸ºRandomStateå®ä¾‹ï¼Œåˆ™æŒ‡å®šä¾‹éšæœºæ•°ç”Ÿæˆå™¨</li><li>å¦‚æœä¸ºNoneï¼Œåˆ™ä½¿ç”¨é»˜è®¤çš„éšæœºæ•°ç”Ÿæˆå™¨</li></ul></li><li>solver: ä¸€ä¸ªå­—ç¬¦ä¸²ï¼ŒæŒ‡å®šäº†æ±‚è§£æœ€ä¼˜åŒ–é—®é¢˜çš„ç®—æ³•<ul><li>newton-cg: ä½¿ç”¨ç‰›é¡¿æ³•ï¼Œåªå¤„ç†penalty='l2'çš„æƒ…å†µ</li><li>lbfgs: ä½¿ç”¨L-BFGSæ‹Ÿç‰›é¡¿æ³•ï¼Œåªå¤„ç†penalty='l2'çš„æƒ…å†µ</li><li>liblinear: ä½¿ç”¨liblinearï¼Œé€‚ç”¨è§„æ¨¡å°çš„æ•°æ®é›†</li><li>sag: ä½¿ç”¨Stochastic Average Gradient descentç®—æ³•ï¼Œé€‚ç”¨è§„æ¨¡å¤§çš„æ•°æ®é›†ï¼Œåªå¤„ç†penalty='l2'çš„æƒ…å†µ</li></ul></li><li>tol: ä¸€ä¸ªæµ®ç‚¹æ•°ï¼ŒæŒ‡å®šåˆ¤æ–­è¿­ä»£æ”¶æ•›ä¸å¦çš„é˜ˆå€¼ã€‚</li><li>multi_class: ä¸€ä¸ªå­—ç¬¦ä¸²ï¼ŒæŒ‡å®šå¯¹äºå¤šåˆ†ç±»é—®é¢˜çš„ç­–ç•¥<ul><li>ovr: é‡‡ç”¨one-vs-restç­–ç•¥</li><li>multinomial: ç›´æ¥é‡‡ç”¨å¤šåˆ†ç±»é€»è¾‘å›å½’ç­–ç•¥</li></ul></li><li>verbose: ä¸€ä¸ªæ­£æ•°ï¼Œç”¨äºå¼€å¯/å…³é—­è¿­ä»£ä¸­é—´è¾“å‡ºæ—¥å¿—åŠŸèƒ½ã€‚</li><li>warm_start: booleanï¼Œå¦‚æœä¸ºTrueï¼Œé‚£ä¹ˆä½¿ç”¨å‰ä¸€æ¬¡è®­ç»ƒç»“æœç»§ç»­è®­ç»ƒã€‚å¦åˆ™ä»å¤´å¼€å§‹è®­ç»ƒã€‚</li><li>n_jobs: ä¸€ä¸ªæ­£æ•°ï¼ŒæŒ‡å®šä»»åŠ¡å¹¶è¡Œæ—¶çš„CPUæ•°é‡ã€‚å¦‚æœä¸º-1åˆ™ä½¿ç”¨æ‰€æœ‰å¯ç”¨çš„CPUã€‚</li></ul></li><li>å±æ€§<ul><li>coef_: æƒé‡å‘é‡</li><li>intercept_: bå€¼</li><li>n_iter_: å®é™…è¿­ä»£æ¬¡æ•°</li></ul></li><li>æ–¹æ³•<ul><li>fit(X, y[, sample_weight]): è®­ç»ƒæ¨¡å‹</li><li>predict(X): ç”¨æ¨¡å‹è¿›è¡Œé¢„æµ‹ï¼Œè¿”å›é¢„æµ‹å€¼</li><li>predict_log_proba(X): è¿”å›ä¸€ä¸ªæ•°ç»„ï¼Œæ•°ç»„çš„å…ƒç´ ä¾æ¬¡æ˜¯Xé¢„æµ‹ä¸ºå„ä¸ªç±»åˆ«çš„æ¦‚ç‡çš„å¯¹æ•°å€¼</li><li>predict_proba(X): è¿”å›ä¸€ä¸ªæ•°ç»„ï¼Œæ•°ç»„çš„å…ƒç´ ä¾æ¬¡æ˜¯Xé¢„æµ‹ä¸ºå„ä¸ªç±»åˆ«çš„æ¦‚ç‡å€¼</li><li>score(X, y[, sample_weight]): è¿”å›åœ¨(X, y)ä¸Šé¢„æµ‹çš„å‡†ç¡®ç‡</li></ul></li></ul><p>ä¸ºäº†ä½¿ç”¨é€»è¾‘å›å½’æ¨¡å‹ï¼Œæˆ‘ä»¬å¯¹é¸¢å°¾èŠ±è¿›è¡Œåˆ†ç±»ã€‚è¯¥æ•°æ®é›†ä¸€å…±æœ‰150ä¸ªæ•°æ®ï¼Œè¿™äº›æ•°æ®åˆ†ä¸º3ç±»(setosa, versicolor, virginica)ï¼Œæ¯ç±»50ä¸ªæ•°æ®ã€‚æ¯ä¸ªæ•°æ®åŒ…å«4ä¸ªå±æ€§ï¼šsepalé•¿åº¦ã€sepalå®½åº¦ã€petalé•¿åº¦ã€petalå®½åº¦</p><p>é¦–å…ˆåŠ è½½æ•°æ®ï¼š <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">def load_data():</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    é‡‡ç”¨åˆ†å±‚é‡‡æ ·</span><br><span class="line">    :return: </span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    iris = datasets.load_iris()</span><br><span class="line">    X_train = iris.data</span><br><span class="line">    y_train = iris.target</span><br><span class="line">    return model_selection.train_test_split(X_train, y_train, test_size=0.25, random_state=0, stratify=y_train)</span><br></pre></td></tr></table></figure></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">def demo_LogisticRegression(*data):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    ä½¿ç”¨LogisticRegressionå‡½æ•°</span><br><span class="line">    :param data: è®­ç»ƒæ ·æœ¬é›†ã€æµ‹è¯•æ ·æœ¬é›†ã€è®­ç»ƒæ ·æœ¬é›†å¯¹åº”çš„æ ‡ç­¾å€¼ã€æµ‹è¯•æ ·æœ¬é›†å¯¹åº”çš„æ ‡ç­¾å€¼</span><br><span class="line">    :return: æƒé‡å‘é‡ã€bå€¼ï¼Œé¢„æµ‹æ€§èƒ½å¾—åˆ†</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    X_train, X_test, y_train, y_test = data</span><br><span class="line">    regr = linear_model.LogisticRegression()</span><br><span class="line">    regr.fit(X_train, y_train)</span><br><span class="line">    print(&apos;Coefficients: %s&apos; % regr.coef_)</span><br><span class="line">    print(&apos;Intercept: %s&apos; % regr.intercept_)</span><br><span class="line">    print(&apos;Score: %.2f&apos; % regr.score(X_test, y_test))</span><br></pre></td></tr></table></figure><p>è°ƒç”¨è¯¥å‡½æ•°ï¼š <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">X_train, X_test, y_train, y_test = load_data()</span><br><span class="line">demo_LogisticRegression(X_train, X_test, y_train, y_test)</span><br></pre></td></tr></table></figure></p><p>è¾“å‡ºç»“æœï¼š <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Coefficients: [[ 0.38705175  1.35839989 -2.12059692 -0.95444452]</span><br><span class="line"> [ 0.23787852 -1.36235758  0.5982662  -1.26506299]</span><br><span class="line"> [-1.50915807 -1.29436243  2.14148142  2.29611791]]</span><br><span class="line">Intercept: [ 0.23950369  1.14559506 -1.0941717 ]</span><br><span class="line">Score: 0.97</span><br></pre></td></tr></table></figure></p><p>å¯ä»¥çœ‹åˆ°æµ‹è¯•é›†ä¸­çš„é¢„æµ‹ç»“æœæ€§èƒ½å¾—åˆ†ä¸º0.97ï¼ˆå³é¢„æµ‹å‡†ç¡®ç‡ä¸º97%ï¼‰ã€‚</p><p>ä¸‹é¢è€ƒå¯Ÿmulti_classå‚æ•°å¯¹åˆ†ç±»ç»“æœçš„å½±å“ã€‚é»˜è®¤é‡‡ç”¨çš„æ˜¯one-vs-restç­–ç•¥ï¼Œä½†æ˜¯é€»è¾‘å›å½’æ¨¡å‹åŸç”Ÿå°±æ”¯æŒå¤šç±»åˆ†ç±»ï¼š</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">def demo_LogisticRegression_multinomial(*data):</span><br><span class="line">    X_train, X_test, y_train, y_test = data</span><br><span class="line">    regr = linear_model.LogisticRegression(multi_class=&apos;multinomial&apos;, solver=&apos;lbfgs&apos;)</span><br><span class="line">    regr.fit(X_train, y_train)</span><br><span class="line">    print(&apos;Coefficients: %s&apos; % regr.coef_)</span><br><span class="line">    print(&apos;Intercept: %s&apos; % regr.intercept_)</span><br><span class="line">    print(&apos;Score: %.2f&apos; % regr.score(X_test, y_test))</span><br></pre></td></tr></table></figure><blockquote><p>åªæœ‰solverä¸ºç‰›é¡¿æ³•æˆ–è€…æ‹Ÿç‰›é¡¿æ³•æ‰èƒ½é…åˆ<code>multi_class='multinomial'</code></p></blockquote><p>è°ƒç”¨è¯¥å‡½æ•°ï¼š <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">X_train, X_test, y_train, y_test = load_data()</span><br><span class="line">demo_LogisticRegression_multinomial(X_train, X_test, y_train, y_test)</span><br></pre></td></tr></table></figure></p><p>ç»“æœå¦‚ä¸‹ï¼š <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Coefficients: [[-0.38350833  0.86199769 -2.26970401 -0.97473472]</span><br><span class="line"> [ 0.34381965 -0.37903699 -0.03117965 -0.86837866]</span><br><span class="line"> [ 0.03968868 -0.4829607   2.30088366  1.84311338]]</span><br><span class="line">Intercept: [  8.75772577   2.49369071 -11.25141648]</span><br><span class="line">Score: 1.00</span><br></pre></td></tr></table></figure></p><p>å¯ä»¥çœ‹åˆ°åœ¨è¿™ä¸ªé—®é¢˜ä¸­ï¼Œå¤šåˆ†ç±»ç­–ç•¥è¿›ä¸€æ­¥æå‡äº†é¢„æµ‹å‡†ç¡®ç‡ã€‚</p><p>æœ€åï¼Œè€ƒå¯Ÿå‚æ•°Cå¯¹åˆ†ç±»æ¨¡å‹çš„é¢„æµ‹æ€§èƒ½çš„å½±å“ï¼š <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">def demo_LogisticRegression_C(*data):</span><br><span class="line">    X_train, X_test, y_train, y_test = data</span><br><span class="line">    Cs = np.logspace(-2, 4, num=100)</span><br><span class="line">    scores = []</span><br><span class="line">    for C in Cs:</span><br><span class="line">        regr = linear_model.LogisticRegression(C=C)</span><br><span class="line">        regr.fit(X_train, y_train)</span><br><span class="line">        scores.append(regr.score(X_test, y_test))</span><br><span class="line">    # ç»˜å›¾</span><br><span class="line">    fig = plt.figure()</span><br><span class="line">    ax = fig.add_subplot(1, 1, 1)</span><br><span class="line">    ax.plot(Cs, scores)</span><br><span class="line">    ax.set_xlabel(r&quot;C&quot;)</span><br><span class="line">    ax.set_ylabel(r&quot;score&quot;)</span><br><span class="line">    ax.set_xscale(&apos;log&apos;)</span><br><span class="line">    ax.set_title(&quot;LogisticRegression&quot;)</span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure></p><p>æµ‹è¯•ç»“æœå¦‚ä¸‹å›¾ï¼š <img src="/images/MachineLearning/LinearModel/20190725_ML_Logistic.png"></p><p>å¯ä»¥çœ‹åˆ°éšç€Cçš„å¢å¤§ï¼ˆå³æ­£åˆ™åŒ–é¡¹çš„å‡å°ï¼‰ï¼Œé¢„æµ‹å‡†ç¡®ç‡ä¸Šå‡ã€‚å½“Cå¢å¤§åˆ°ä¸€å®šç¨‹åº¦ï¼Œé¢„æµ‹å‡†ç¡®ç‡ç»´æŒåœ¨è¾ƒé«˜çš„æ°´å‡†ä¸å˜ã€‚</p><h2 id="çº¿æ€§åˆ¤åˆ«åˆ†æ-1">çº¿æ€§åˆ¤åˆ«åˆ†æ</h2><p>åœ¨scikit-learnä¸­ï¼ŒLinearDiscriminantAnalysiså®ç°äº†çº¿æ€§åˆ¤åˆ«åˆ†ææ¨¡å‹ï¼š <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">class sklearn.discriminant_analysis.LinearDiscriminantAnalysis(</span><br><span class="line">                 solver=&apos;svd&apos;, shrinkage=None, priors=None,</span><br><span class="line">                 n_components=None, store_covariance=False, tol=0.0001)</span><br></pre></td></tr></table></figure></p><ul><li>å‚æ•°<ul><li>solver: ä¸€ä¸ªå­—ç¬¦ä¸²ï¼ŒæŒ‡å®šæ±‚è§£æœ€ä¼˜åŒ–é—®é¢˜çš„ç®—æ³•<ul><li>svd: å¥‡å¼‚å€¼åˆ†è§£ï¼Œå¯¹äºæœ‰å¤§è§„æ¨¡ç‰¹å¾çš„æ•°æ®ï¼Œæ¨èä½¿ç”¨</li><li>lsqr: æœ€å°å¹³æ–¹å·®ç®—æ³•ï¼Œå¯ä»¥ç»“åˆshrinkageå‚æ•°</li><li>eigen: ç‰¹å¾å€¼åˆ†è§£ç®—æ³•ï¼Œå¯ä»¥ç»“åˆshrinkageå‚æ•°</li></ul></li><li>shrinkage: é€šå¸¸åœ¨è®­ç»ƒæ ·æœ¬æ•°é‡å°äºç‰¹å¾æ•°é‡åœºåˆä¸‹ä½¿ç”¨ï¼Œåªæœ‰åœ¨solver=lsqræˆ–è€…eigenä¸‹æœ‰æ„ä¹‰<ul><li>'auto': æ ¹æ®Ledoit-Wolfå¼•ç†æ¥è‡ªåŠ¨å†³å®šshrinkageå‚æ•°å¤§å°</li><li>None: ä¸ä½¿ç”¨è¯¥å‚æ•°</li><li>æµ®ç‚¹æ•°(0~1): æŒ‡å®šå‚æ•°</li></ul></li><li>priors: ä¸€ä¸ªæ•°ç»„ï¼Œæ•°ç»„ä¸­å…ƒç´ ä¾æ¬¡æŒ‡å®šäº†æ¯ä¸ªç±»åˆ«çš„å…ˆéªŒæ¦‚ç‡ã€‚å¦‚æœä¸ºNoneï¼Œåˆ™è®¤ä¸ºæ¯ä¸ªç±»çš„å…ˆéªŒæ¦‚ç‡éƒ½æ˜¯ç­‰å¯èƒ½çš„ã€‚</li><li>n_components: ä¸€ä¸ªæ•´æ•°ï¼ŒæŒ‡å®šäº†æ•°æ®é™ç»´åçš„ç»´åº¦(å¿…é¡»å°äºn_classes-1)ã€‚</li><li>store_covariance: booleanï¼Œå¦‚æœä¸ºTrueï¼Œåˆ™éœ€è¦é¢å¤–è®¡ç®—æ¯ä¸ªç±»åˆ«çš„åæ–¹å·®çŸ©é˜µ<span class="math inline">\(\sum_i\)</span>ã€‚</li><li>tol: ä¸€ä¸ªæµ®ç‚¹æ•°ï¼ŒæŒ‡å®šäº†ç”¨äºSVDç®—æ³•ä¸­åˆ¤æ–­è¿­ä»£æ”¶æ•›çš„é˜ˆå€¼ã€‚</li></ul></li><li>å±æ€§<ul><li>coef_: æƒé‡å‘é‡</li><li>intercept_: bå€¼</li><li>covariance_: ä¸€ä¸ªæ•°ç»„ï¼Œä¾æ¬¡ç»™å‡ºäº†æ¯ä¸ªç±»åˆ«çš„åæ–¹å·®çŸ©é˜µ</li><li>means_: ä¸€ä¸ªæ•°ç»„ï¼Œä¾æ¬¡ç»™å‡ºäº†æ¯ä¸ªç±»åˆ«çš„å‡å€¼å‘é‡</li><li>xbar_: ç»™å‡ºæ•´ä½“æ ·æœ¬çš„å‡å€¼å‘é‡</li><li>n_iter_: å®é™…è¿­ä»£æ¬¡æ•°</li></ul></li><li>æ–¹æ³•<ul><li>fit(X, y): è®­ç»ƒæ¨¡å‹</li><li>predict(X): ç”¨æ¨¡å‹è¿›è¡Œé¢„æµ‹ï¼Œè¿”å›é¢„æµ‹å€¼</li><li>predict_log_proba(X): è¿”å›ä¸€ä¸ªæ•°ç»„ï¼Œæ•°ç»„çš„å…ƒç´ ä¾æ¬¡æ˜¯Xé¢„æµ‹ä¸ºå„ä¸ªç±»åˆ«çš„æ¦‚ç‡çš„å¯¹æ•°å€¼</li><li>predict_proba(X): è¿”å›ä¸€ä¸ªæ•°ç»„ï¼Œæ•°ç»„çš„å…ƒç´ ä¾æ¬¡æ˜¯Xé¢„æµ‹ä¸ºå„ä¸ªç±»åˆ«çš„æ¦‚ç‡å€¼</li><li>score(X, y[, sample_weight]): è¿”å›åœ¨(X, y)ä¸Šé¢„æµ‹çš„å‡†ç¡®ç‡</li></ul></li></ul><p>ä¾æ—§ä½¿ç”¨é¸¢å°¾èŠ±æ•°æ®é›†ï¼š <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">def demo_LinearDiscriminantAnalysis(*data):</span><br><span class="line">    X_train, X_test, y_train, y_test = data</span><br><span class="line">    lda = discriminant_analysis.LinearDiscriminantAnalysis()</span><br><span class="line">    lda.fit(X_train, y_train)</span><br><span class="line">    print(&apos;Coefficients: %s&apos; % lda.coef_)</span><br><span class="line">    print(&apos;Intercept: %s&apos; % lda.intercept_)</span><br><span class="line">    print(&apos;Score: %.2f&apos; % lda.score(X_test, y_test))</span><br></pre></td></tr></table></figure></p><p>ç»“æœå¦‚ä¸‹ï¼š <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Coefficients: [[  6.66775427   9.63817442 -14.4828516  -20.9501241 ]</span><br><span class="line"> [ -2.00416487  -3.51569814   4.27687513   2.44146469]</span><br><span class="line"> [ -4.54086336  -5.96135848   9.93739814  18.02158943]]</span><br><span class="line">Intercept: [-15.46769144   0.60345075 -30.41543234]</span><br><span class="line">Score: 1.00</span><br></pre></td></tr></table></figure></p><p>ç°åœ¨æ¥æ£€æŸ¥ä¸€ä¸‹åŸå§‹æ•°æ®é›†åœ¨ç»è¿‡çº¿æ€§åˆ¤åˆ«åˆ†æLDAä¹‹åçš„æ•°æ®é›†æƒ…å†µï¼Œç»˜åˆ¶LDAé™ç»´ä¹‹åçš„æ•°æ®é›†ï¼š <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">def plot_LDA(converted_X, y):</span><br><span class="line">    fig = plt.figure()</span><br><span class="line">    ax = Axes3D(fig)</span><br><span class="line">    colors = &apos;rgb&apos;</span><br><span class="line">    markers = &apos;o*s&apos;</span><br><span class="line">    for target, color, marker in zip([0, 1, 2], colors, markers):</span><br><span class="line">        pos = (y == target).ravel()</span><br><span class="line">        X = converted_X[pos, :]</span><br><span class="line">        ax.scatter(X[:, 0], X[:, 1], X[:, 2], color=color, marker=marker, label=&quot;Label %d&quot; % target)</span><br><span class="line">    ax.legend(loc=&quot;best&quot;)</span><br><span class="line">    fig.suptitle(&quot;Iris After LDA&quot;)</span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure></p><p>è°ƒç”¨ï¼š <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">X_train, X_test, y_train, y_test = load_data()</span><br><span class="line">X = np.vstack((X_train, X_test))</span><br><span class="line">Y = np.vstack((y_train.reshape(y_train.size, 1), y_test.reshape(y_test.size, 1)))</span><br><span class="line">lda = discriminant_analysis.LinearDiscriminantAnalysis()</span><br><span class="line">lda.fit(X, Y)</span><br><span class="line">converted_X = np.dot(X, np.transpose(lda.coef_)) + lda.intercept_</span><br><span class="line">plot_LDA(converted_X, Y)</span><br></pre></td></tr></table></figure></p><p>ç»“æœå¦‚ä¸‹ï¼š <img src="/images/MachineLearning/LinearModel/20190725_LinearDiscriminantAnalysis_LDA.png"></p><p>å¯ä»¥çœ‹åˆ°ç»è¿‡çº¿æ€§åˆ¤åˆ«åˆ†æåï¼Œä¸åŒç§ç±»çš„é¸¢å°¾èŠ±ä¹‹é—´çš„é—´éš”è¾ƒè¿œï¼Œç›¸åŒç§ç±»çš„é¸¢å°¾èŠ±ä¹‹é—´å·²ç»ç›¸äº’èšé›†ã€‚</p><p>æ¥ä¸‹æ¥è€ƒå¯Ÿä¸åŒçš„solverå¯¹é¢„æµ‹æ€§èƒ½çš„å½±å“ï¼š <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">def demo_LinearDiscriminantAnalysis_solver(*data):</span><br><span class="line">    X_train, X_test, y_train, y_test = data</span><br><span class="line">    solvers = [&apos;svd&apos;, &apos;lsqr&apos;, &apos;eigen&apos;]</span><br><span class="line">    for solver in solvers:</span><br><span class="line">        if solver == &apos;svd&apos;:</span><br><span class="line">            lda = discriminant_analysis.LinearDiscriminantAnalysis(solver=solver)</span><br><span class="line">        else:</span><br><span class="line">            lda = discriminant_analysis.LinearDiscriminantAnalysis(solver=solver, shrinkage=None)</span><br><span class="line">        lda.fit(X_train, y_train)</span><br><span class="line">        print(&apos;Score at solver = %s: %.2f&apos; % (solver, lda.score(X_test, y_test)))</span><br></pre></td></tr></table></figure></p><p>ç»“æœå¦‚ä¸‹ï¼Œå¯ä»¥çœ‹å‡ºä¸‰è€…æ²¡æœ‰å·®åˆ«ï¼š <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">runfile(&apos;/Users/rian/Evil/LEARN/AI/blog/linear model/LinearDiscriminantAnalysis.py&apos;, wdir=&apos;/Users/rian/Evil/LEARN/AI/blog/linear model&apos;)</span><br><span class="line">Score at solver = svd: 1.00</span><br><span class="line">Score at solver = lsqr: 1.00</span><br><span class="line">Score at solver = eigen: 1.00</span><br></pre></td></tr></table></figure></p><p>æœ€åè€ƒå¯Ÿä¸­solver=lsqrä¸­å¼•å…¥æŠ–åŠ¨(ç›¸å½“äºå¼•å…¥æ­£åˆ™åŒ–é¡¹)ï¼š <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">def demo_LinearDiscriminantAnalysis_shrinkage(*data):</span><br><span class="line">    X_train, X_test, y_train, y_test = data</span><br><span class="line">    shrinkages = np.linspace(0.0, 1.0, num=20)</span><br><span class="line">    scores = []</span><br><span class="line">    for shrinkage in shrinkages:</span><br><span class="line">        lda = discriminant_analysis.LinearDiscriminantAnalysis(solver=&apos;lsqr&apos;, shrinkage=shrinkage)</span><br><span class="line">        lda.fit(X_train, y_train)</span><br><span class="line">        scores.append(lda.score(X_test, y_test))</span><br><span class="line">    # ç»˜å›¾</span><br><span class="line">    fig = plt.figure()</span><br><span class="line">    ax = fig.add_subplot(1, 1, 1)</span><br><span class="line">    ax.plot(shrinkages, scores)</span><br><span class="line">    ax.set_xlabel(r&quot;shrinkage&quot;)</span><br><span class="line">    ax.set_ylabel(r&quot;score&quot;)</span><br><span class="line">    ax.set_ylim(0, 1.05)</span><br><span class="line">    ax.set_title(&quot;LinearDiscriminantAnalysis&quot;)</span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure></p><p>ç»“æœï¼š</p><p><img src="/images/MachineLearning/LinearModel/20190725_LinearDiscriminantAnalysis_shrinkage.png"></p><p>å¯ä»¥å‘ç°éšç€shrinkageçš„å¢å¤§ï¼Œæ¨¡å‹çš„å‡†ç¡®ç‡ä¼šéšä¹‹ä¸‹é™</p>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;æ¦‚è¿°&quot;&gt;æ¦‚è¿°&lt;/h1&gt;
&lt;p&gt;å¯¹äºæ ·æœ¬&lt;span class=&quot;math inline&quot;&gt;\(\stackrel{\rightarrow}{x}\)&lt;/span&gt;ï¼Œç”¨åˆ—å‘é‡è¡¨ç¤ºè¯¥æ ·æœ¬&lt;span class=&quot;math inline&quot;&gt;\(\stackrel{\rightarrow}{x}={(x^{(1)},x^{(2)},â€¦,x^{(n)})}^{T}\)&lt;/span&gt;ã€‚æ ·æœ¬æœ‰&lt;span class=&quot;math inline&quot;&gt;\(n\)&lt;/span&gt;ç§ç‰¹å¾ï¼Œç”¨&lt;span class=&quot;math inline&quot;&gt;\(x^{(i)}\)&lt;/span&gt;æ¥è¡¨ç¤ºæ ·æœ¬çš„ç¬¬&lt;span class=&quot;math inline&quot;&gt;\(i\)&lt;/span&gt;ä¸ªç‰¹å¾ã€‚&lt;/p&gt;
&lt;p&gt;çº¿æ€§æ¨¡å‹(linear model)çš„å½¢å¼ä¸ºï¼š &lt;span class=&quot;math display&quot;&gt;\[f(\stackrel{\rightarrow}{x})=\stackrel{\rightarrow}{w}Â·\stackrel{\rightarrow}{x}+b\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;å…¶ä¸­&lt;span class=&quot;math inline&quot;&gt;\(\stackrel{\rightarrow}{w}={(w^{(1)},w^{(2)},â€¦,w^{(n)})}^{T}\)&lt;/span&gt;ä¸ºæ¯ä¸ªç‰¹å¾å¯¹åº”çš„æƒé‡ç”Ÿæˆçš„æƒé‡å‘é‡ã€‚æƒé‡å‘é‡ç›´è§‚åœ°è¡¨è¾¾äº†æ¯ä¸ªç‰¹å¾åœ¨é¢„æµ‹ä¸­çš„é‡è¦æ€§ã€‚&lt;/p&gt;
&lt;p&gt;çº¿æ€§æ¨¡å‹å…¶å®å°±æ˜¯ä¸€ç³»åˆ—ä¸€æ¬¡ç‰¹å¾çš„çº¿æ€§ç»„åˆï¼Œåœ¨äºŒç»´å±‚é¢æ˜¯ä¸€æ¡ç›´çº¿ï¼Œä¸‰ç»´å±‚é¢åˆ™æ˜¯ä¸€ä¸ªå¹³é¢ï¼Œä»¥æ­¤ç±»æ¨åˆ°&lt;span class=&quot;math inline&quot;&gt;\(n\)&lt;/span&gt;ç»´ç©ºé—´ï¼Œè¿™æ ·å¯ä»¥ç†è§£ä¸ºå¹¿ä¹‰çº¿æ€§æ¨¡å‹ã€‚&lt;/p&gt;
&lt;p&gt;å¸¸è§çš„å¹¿ä¹‰çº¿æ€§æ¨¡å‹åŒ…æ‹¬å²­å›å½’ã€lassoå›å½’ã€Elastic Netã€é€»è¾‘å›å½’ã€çº¿æ€§åˆ¤åˆ«åˆ†æç­‰ã€‚
    
    </summary>
    
      <category term="Machine Learning" scheme="http://yoursite.com/categories/Machine-Learning/"/>
    
    
      <category term="machine learning" scheme="http://yoursite.com/tags/machine-learning/"/>
    
      <category term="python" scheme="http://yoursite.com/tags/python/"/>
    
      <category term="sklearn" scheme="http://yoursite.com/tags/sklearn/"/>
    
      <category term="linear model" scheme="http://yoursite.com/tags/linear-model/"/>
    
  </entry>
  
  <entry>
    <title>My blog building experience</title>
    <link href="http://yoursite.com/2019/07/19/My-blog-building-experience/"/>
    <id>http://yoursite.com/2019/07/19/My-blog-building-experience/</id>
    <published>2019-07-19T10:05:29.000Z</published>
    <updated>2019-07-28T06:27:25.939Z</updated>
    
    <content type="html"><![CDATA[<p>It's my first time to build a blog, maybe my experience can help the green hands.</p><p>Operation System: macOS</p><p>2019.7.19 update, Github+hexo <a id="more"></a></p><h1 id="preparatory-work">preparatory work</h1><h2 id="install-git">install git</h2><p>download URL: https://git-scm.com/download</p><p>After installing git successfully, we need to bind git and our Github account.</p><ul><li><p>open iTerm</p></li><li><p>set the configuration information</p><p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">git config --global user.name &quot;name&quot;</span><br><span class="line">git config --global user.email &quot;email&quot;</span><br></pre></td></tr></table></figure></p></li><li><p>create ssh key file (the email should be the same as one above), copy the content of id_rsa.pub</p><p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh-keygen -t rsa -C &quot;email&quot;</span><br></pre></td></tr></table></figure></p></li><li><p>open https://github.com/settings/keys, new ssh key. Paste the content of id_rsa.pub into the key, and then click "add ssh key".</p></li><li><p>check Github public key, open iTerm</p></li></ul><p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh git@github.com</span><br></pre></td></tr></table></figure></p><h2 id="install-node.js">install node.js</h2><p>download url: https://nodejs.org/en/download/</p><h2 id="install-hexo">install hexo</h2><p>Hexo is the framework of our blog site.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npm install -g hexo-cli</span><br></pre></td></tr></table></figure><h1 id="build-a-blog">build a blog</h1><h2 id="build-locally">build locally</h2><ul><li><p>create a new folder named "blog"</p></li><li><p>generate a hexo template</p><p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd blog</span><br><span class="line">hexo init</span><br></pre></td></tr></table></figure></p></li><li><p>run <code>hexo server</code>, we can see the blog have been built successfully through localhost:4000</p></li></ul><h2 id="link-blog-to-github">link blog to Github</h2><ul><li><p>create a new project named "github_name.github.io"</p></li><li><p>open _config.yml, update deploy</p><p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">deploy:</span><br><span class="line">    type: git</span><br><span class="line">    repository: https://github.com/github_name/github_name.github.io.git</span><br><span class="line">    branch: master</span><br></pre></td></tr></table></figure></p></li><li><p>install plugin</p><p><code>npm install hexo-deployer-git --save</code></p></li><li><p>generate static files locally</p><p><code>hexo g</code></p></li><li><p>push to Github</p><p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hexo d</span><br></pre></td></tr></table></figure></p></li><li><p>now we can visit https://github_name.github.io</p></li></ul><h1 id="update-blog-content">update blog content</h1><h2 id="update-article">update article</h2><ul><li><p>run <code>hexo new "my first blog"</code>, then we can find a .md file in the source/_posts folder</p></li><li><p>edit the file (Markdown)</p></li><li><p>push to Github</p><p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hexo clean</span><br><span class="line">hexo g</span><br><span class="line">hexo d</span><br></pre></td></tr></table></figure></p></li></ul><h2 id="add-menu">add menu</h2><ul><li><p>edit /theme/XXX/_config.yml, find "menu:", add the menu you want</p></li><li><p>add pages</p><p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hexo new pages &quot;menu_name&quot;</span><br></pre></td></tr></table></figure></p></li></ul><h2 id="add-pictures-in-the-article">add pictures in the article</h2><p>create a folder, "/theme/XXX/source/upload_image", and save the pictures here</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">![](/upload_image/a.jpg)</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;It&#39;s my first time to build a blog, maybe my experience can help the green hands.&lt;/p&gt;
&lt;p&gt;Operation System: macOS&lt;/p&gt;
&lt;p&gt;2019.7.19 update, Github+hexo
    
    </summary>
    
      <category term="Web" scheme="http://yoursite.com/categories/Web/"/>
    
    
      <category term="web" scheme="http://yoursite.com/tags/web/"/>
    
      <category term="hexo" scheme="http://yoursite.com/tags/hexo/"/>
    
      <category term="Github" scheme="http://yoursite.com/tags/Github/"/>
    
  </entry>
  
</feed>
